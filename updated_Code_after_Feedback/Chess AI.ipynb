{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b3de98d6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#initializing node structure\n",
    "import chess\n",
    "import chess.pgn\n",
    "import chess.engine\n",
    "import random\n",
    "import time\n",
    "import numpy as np\n",
    "from math import log,sqrt,e,inf\n",
    "from IPython.display import display, HTML, clear_output\n",
    "engine = chess.engine.SimpleEngine.popen_uci(r'stockfish-11-win/Windows/stockfish_20011801_x64.exe')\n",
    "\n",
    "#engine = chess.engine.SimpleEngine.popen_uci(\"stockfish\")\n",
    "\n",
    "\n",
    "class node:\n",
    "    def __init__(self,*board):\n",
    "        if(len(board)>0):\n",
    "            self.state = board\n",
    "        else:\n",
    "            self.state = chess.Board()\n",
    "        self.action = ''\n",
    "        self.children = set()\n",
    "        self.parent = None\n",
    "        self.N = 0\n",
    "        self.n = 0\n",
    "        self.v = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "10c2f1b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#method for ucb and AI rollout\n",
    "def ucb1(curr_node):\n",
    "    ans = curr_node.v+2*(sqrt(log(curr_node.N+e+(10**-6))/(curr_node.n+(10**-10))))\n",
    "    return ans\n",
    "\n",
    "def rollout(board,curr_node):\n",
    "    global engine\n",
    "    if(curr_node.state.is_game_over()):\n",
    "        board1 = curr_node.state\n",
    "        if(board1.result()=='1-0'):\n",
    "            return (1,curr_node)\n",
    "        elif(board1.result()=='0-1'):\n",
    "            return (-1,curr_node)\n",
    "        else:\n",
    "            return (0.5,curr_node)\n",
    "    \n",
    "    all_moves = [curr_node.state.san(i) for i in list(curr_node.state.legal_moves)]\n",
    "    result = engine.play(curr_node.state, chess.engine.Limit(time=0.001))\n",
    "    move = curr_node.state.san(result.move)\n",
    "    tmp_state = chess.Board(curr_node.state.fen())\n",
    "    tmp_state.push_san(move)\n",
    "\n",
    "    to_use = None\n",
    "    \n",
    "    for i in all_moves:\n",
    "        tmp_state1 = chess.Board(curr_node.state.fen())\n",
    "        tmp_state1.push_san(i)\n",
    "        child = node()\n",
    "        child.state = tmp_state1\n",
    "        child.parent = curr_node\n",
    "        curr_node.children.add(child)\n",
    "        if(child.state==tmp_state):\n",
    "            to_use = child\n",
    "            break\n",
    "            \n",
    "    return rollout(board,to_use)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ba7c68c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#method for baseline tree rollout\n",
    "def rolloutTree(board,curr_node):\n",
    "    \n",
    "    if(curr_node.state.is_game_over()):\n",
    "        board1 = curr_node.state\n",
    "        if(board1.result()=='1-0'):\n",
    "            return (1,curr_node)\n",
    "        elif(board1.result()=='0-1'):\n",
    "            return (-1,curr_node)\n",
    "        else:\n",
    "            return (0.5,curr_node)\n",
    "    \n",
    "    all_moves = [curr_node.state.san(i) for i in list(curr_node.state.legal_moves)]\n",
    "    \n",
    "    for i in all_moves:\n",
    "        tmp_state = chess.Board(curr_node.state.fen())\n",
    "        tmp_state.push_san(i)\n",
    "        child = node(board)\n",
    "        child.state = tmp_state\n",
    "        child.parent = curr_node\n",
    "        curr_node.children.add(child)\n",
    "    rnd_state = random.choice(list(curr_node.children))\n",
    "\n",
    "    return rolloutTree(board,rnd_state)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1a3e1c65",
   "metadata": {},
   "outputs": [],
   "source": [
    "def expand(curr_node,white):\n",
    "    if(len(curr_node.children)==0):\n",
    "        return curr_node\n",
    "    max_ucb = -inf\n",
    "    if(white):\n",
    "        idx = -1\n",
    "        max_ucb = -inf\n",
    "        sel_child = None\n",
    "        for i in curr_node.children:\n",
    "            tmp = ucb1(i)\n",
    "            if(tmp>max_ucb):\n",
    "                idx = i\n",
    "                max_ucb = tmp\n",
    "                sel_child = i\n",
    "\n",
    "        return(expand(sel_child,0))\n",
    "\n",
    "    else:\n",
    "        idx = -1\n",
    "        min_ucb = inf\n",
    "        sel_child = None\n",
    "        for i in curr_node.children:\n",
    "            tmp = ucb1(i)\n",
    "            if(tmp<min_ucb):\n",
    "                idx = i\n",
    "                min_ucb = tmp\n",
    "                sel_child = i\n",
    "\n",
    "        return expand(sel_child,1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fa8bfe15",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rollback(curr_node,reward):\n",
    "    curr_node.n+=1\n",
    "    curr_node.v+=reward\n",
    "    while(curr_node.parent!=None):\n",
    "        curr_node.N+=1\n",
    "        curr_node = curr_node.parent\n",
    "    return curr_node\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "76d209fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mcts_pred(board,curr_node,over,white,choice,base1,base2,iterations=10):\n",
    "    if(over):\n",
    "        return -1\n",
    "    all_moves = [curr_node.state.san(i) for i in list(curr_node.state.legal_moves)]\n",
    "    map_state_move = dict()\n",
    "    \n",
    "    for i in all_moves:\n",
    "        tmp_state = chess.Board(curr_node.state.fen())\n",
    "        tmp_state.push_san(i)\n",
    "        child = node(board)\n",
    "        child.state = tmp_state\n",
    "        child.parent = curr_node\n",
    "        curr_node.children.add(child)\n",
    "        map_state_move[child] = i\n",
    "        \n",
    "    while(iterations>0):\n",
    "        if(white):\n",
    "            idx = -1\n",
    "            max_ucb = -inf\n",
    "            sel_child = None\n",
    "            for i in curr_node.children:\n",
    "                tmp = ucb1(i)\n",
    "                if(tmp>max_ucb):\n",
    "                    idx = i\n",
    "                    max_ucb = tmp\n",
    "                    sel_child = i\n",
    "            ex_child = expand(sel_child,0)\n",
    "            if(base1==\"Tree\"):\n",
    "                reward,state = rolloutTree(board,ex_child)\n",
    "            elif(base1==\"AI\"):\n",
    "                reward,state = rollout(board,ex_child)\n",
    "            curr_node = rollback(state,reward)\n",
    "            iterations-=1\n",
    "        else:\n",
    "            idx = -1\n",
    "            min_ucb = inf\n",
    "            sel_child = None\n",
    "            for i in curr_node.children:\n",
    "                tmp = ucb1(i)\n",
    "                if(tmp<min_ucb):\n",
    "                    idx = i\n",
    "                    min_ucb = tmp\n",
    "                    sel_child = i\n",
    "\n",
    "            ex_child = expand(sel_child,1)\n",
    "\n",
    "            if(base2==\"Tree\"):\n",
    "                reward,state = rolloutTree(board,ex_child)\n",
    "            elif(base2==\"AI\"):\n",
    "                reward,state = rollout(board,ex_child)\n",
    "\n",
    "            curr_node = rollback(state,reward)\n",
    "            iterations-=1\n",
    "\n",
    "    if(white):\n",
    "        \n",
    "        mx = -inf\n",
    "        idx = -1\n",
    "        selected_move = ''\n",
    "        for i in (curr_node.children):\n",
    "            tmp = ucb1(i)\n",
    "            if(tmp>mx):\n",
    "                mx = tmp\n",
    "                selected_move = map_state_move[i]\n",
    "        return selected_move\n",
    "    else:\n",
    "        mn = inf\n",
    "        idx = -1\n",
    "        selected_move = ''\n",
    "        for i in (curr_node.children):\n",
    "            tmp = ucb1(i)\n",
    "            if(tmp<mn):\n",
    "                mn = tmp\n",
    "                selected_move = map_state_move[i]\n",
    "        return selected_move\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "05e0a738",
   "metadata": {},
   "outputs": [],
   "source": [
    "def staticAnalysis(board, color):\n",
    "    score = random.random()\n",
    "\n",
    "    ## Check some things about this move:\n",
    "    # score += 10 if board.is_capture(move) else 0\n",
    "    # Now check some other things:\n",
    "    for (piece, value) in [(chess.PAWN, 1), \n",
    "                           (chess.BISHOP, 4), \n",
    "                           (chess.KING, 0), \n",
    "                           (chess.QUEEN, 10), \n",
    "                           (chess.KNIGHT, 5),\n",
    "                           (chess.ROOK, 3)]:\n",
    "        score += len(board.pieces(piece, color)) * value\n",
    "        score -= len(board.pieces(piece, not color)) * value\n",
    "        # can also check things about the pieces position here\n",
    "    # Check global things about the board\n",
    "    score += 100 if board.is_checkmate() else 0\n",
    "    return score\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d995a6cf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import chess\n",
    "import numpy as np\n",
    "os.getcwd()\n",
    "os.chdir(os.path.dirname(os.path.abspath(\"__file__\")))\n",
    "#os.chdir('C:\\Users\\User\\Downloads\\stockfish-11-win')\n",
    "import chess.pgn\n",
    "import pandas as pd\n",
    "#https://www.kaggle.com/code/gabrielhaselhurst/chess-dataset/data\n",
    "chess_dict = {\n",
    "    'p' : [1,0,0,0,0,0,0,0,0,0,0,0],\n",
    "    'P' : [0,0,0,0,0,0,1,0,0,0,0,0],\n",
    "    'n' : [0,1,0,0,0,0,0,0,0,0,0,0],\n",
    "    'N' : [0,0,0,0,0,0,0,1,0,0,0,0],\n",
    "    'b' : [0,0,1,0,0,0,0,0,0,0,0,0],\n",
    "    'B' : [0,0,0,0,0,0,0,0,1,0,0,0],\n",
    "    'r' : [0,0,0,1,0,0,0,0,0,0,0,0],\n",
    "    'R' : [0,0,0,0,0,0,0,0,0,1,0,0],\n",
    "    'q' : [0,0,0,0,1,0,0,0,0,0,0,0],\n",
    "    'Q' : [0,0,0,0,0,0,0,0,0,0,1,0],\n",
    "    'k' : [0,0,0,0,0,1,0,0,0,0,0,0],\n",
    "    'K' : [0,0,0,0,0,0,0,0,0,0,0,1],\n",
    "    '.' : [0,0,0,0,0,0,0,0,0,0,0,0],\n",
    "}\n",
    "csv = pd.read_csv('chessData.csv')\n",
    "\n",
    "def make_matrix(board): \n",
    "    pgn = board.epd()\n",
    "    foo = []  \n",
    "    pieces = pgn.split(\" \", 1)[0]\n",
    "    rows = pieces.split(\"/\")\n",
    "    for row in rows:\n",
    "        foo2 = []  \n",
    "        for thing in row:\n",
    "            if thing.isdigit():\n",
    "                for i in range(0, int(thing)):\n",
    "                    foo2.append('.')\n",
    "            else:\n",
    "                foo2.append(thing)\n",
    "        foo.append(foo2)\n",
    "    return foo\n",
    "def translate(matrix,chess_dict):\n",
    "    rows = []\n",
    "    for row in matrix:\n",
    "        terms = []\n",
    "        for term in row:\n",
    "            terms.append(chess_dict[term])\n",
    "        rows.append(terms)\n",
    "    return rows\n",
    "\n",
    "import chess\n",
    "import numpy as np\n",
    "fen = csv['FEN'].values\n",
    "values = csv['Evaluation'].values\n",
    "length = 10000\n",
    "X =[]\n",
    "y= values[:length]\n",
    "defects = []\n",
    "for i in range(length):\n",
    "    board = chess.Board(fen[i])\n",
    "    matrix = make_matrix(board.copy())\n",
    "    translated = translate(matrix,chess_dict)\n",
    "    X.append(translated)\n",
    "for i in range(length):\n",
    "    if '#' in y[i]:\n",
    "        y[i] = float(y[i][-1]) * 1000\n",
    "y = y.astype('float32')\n",
    "\n",
    "minimum = min(y)\n",
    "maximum = max(y)\n",
    "for i in range(len(y)):\n",
    "    y[i] = (y[i]-minimum)/(maximum-minimum)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2ceb8a08",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-17 06:18:28.823963: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-12-17 06:18:41.731693: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-12-17 06:18:41.731805: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2022-12-17 06:18:42.360789: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2022-12-17 06:19:13.099131: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2022-12-17 06:19:13.099745: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2022-12-17 06:19:13.099791: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "2022-12-17 06:19:54.369918: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2022-12-17 06:19:54.381111: W tensorflow/stream_executor/cuda/cuda_driver.cc:263] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-12-17 06:19:54.381297: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (LAPTOP-DBN1AV7C): /proc/driver/nvidia/version does not exist\n",
      "2022-12-17 06:19:54.477185: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Training Network...\n",
      "Epoch 1/1000\n",
      "282/282 - 4s - loss: 0.0176 - val_loss: 0.0038 - 4s/epoch - 13ms/step\n",
      "Epoch 2/1000\n",
      "282/282 - 1s - loss: 0.0040 - val_loss: 0.0040 - 705ms/epoch - 2ms/step\n",
      "Epoch 3/1000\n",
      "282/282 - 1s - loss: 0.0030 - val_loss: 0.0028 - 839ms/epoch - 3ms/step\n",
      "Epoch 4/1000\n",
      "282/282 - 1s - loss: 0.0026 - val_loss: 0.0032 - 707ms/epoch - 3ms/step\n",
      "Epoch 5/1000\n",
      "282/282 - 1s - loss: 0.0025 - val_loss: 0.0030 - 690ms/epoch - 2ms/step\n",
      "Epoch 6/1000\n",
      "282/282 - 1s - loss: 0.0024 - val_loss: 0.0028 - 715ms/epoch - 3ms/step\n",
      "Epoch 7/1000\n",
      "282/282 - 1s - loss: 0.0024 - val_loss: 0.0024 - 719ms/epoch - 3ms/step\n",
      "Epoch 8/1000\n",
      "282/282 - 1s - loss: 0.0023 - val_loss: 0.0025 - 696ms/epoch - 2ms/step\n",
      "Epoch 9/1000\n",
      "282/282 - 1s - loss: 0.0023 - val_loss: 0.0026 - 671ms/epoch - 2ms/step\n",
      "Epoch 10/1000\n",
      "282/282 - 1s - loss: 0.0023 - val_loss: 0.0023 - 747ms/epoch - 3ms/step\n",
      "Epoch 11/1000\n",
      "282/282 - 1s - loss: 0.0023 - val_loss: 0.0023 - 721ms/epoch - 3ms/step\n",
      "Epoch 12/1000\n",
      "282/282 - 1s - loss: 0.0023 - val_loss: 0.0024 - 708ms/epoch - 3ms/step\n",
      "Epoch 13/1000\n",
      "282/282 - 1s - loss: 0.0023 - val_loss: 0.0023 - 755ms/epoch - 3ms/step\n",
      "Epoch 14/1000\n",
      "282/282 - 1s - loss: 0.0023 - val_loss: 0.0024 - 680ms/epoch - 2ms/step\n",
      "Epoch 15/1000\n",
      "282/282 - 1s - loss: 0.0022 - val_loss: 0.0023 - 743ms/epoch - 3ms/step\n",
      "Epoch 16/1000\n",
      "282/282 - 1s - loss: 0.0022 - val_loss: 0.0022 - 801ms/epoch - 3ms/step\n",
      "Epoch 17/1000\n",
      "282/282 - 1s - loss: 0.0022 - val_loss: 0.0024 - 699ms/epoch - 2ms/step\n",
      "Epoch 18/1000\n",
      "282/282 - 1s - loss: 0.0022 - val_loss: 0.0020 - 769ms/epoch - 3ms/step\n",
      "Epoch 19/1000\n",
      "282/282 - 1s - loss: 0.0022 - val_loss: 0.0022 - 710ms/epoch - 3ms/step\n",
      "Epoch 20/1000\n",
      "282/282 - 1s - loss: 0.0022 - val_loss: 0.0020 - 737ms/epoch - 3ms/step\n",
      "Epoch 21/1000\n",
      "282/282 - 1s - loss: 0.0022 - val_loss: 0.0023 - 681ms/epoch - 2ms/step\n",
      "Epoch 22/1000\n",
      "282/282 - 1s - loss: 0.0022 - val_loss: 0.0024 - 686ms/epoch - 2ms/step\n",
      "Epoch 23/1000\n",
      "282/282 - 1s - loss: 0.0022 - val_loss: 0.0023 - 665ms/epoch - 2ms/step\n",
      "Epoch 24/1000\n",
      "282/282 - 1s - loss: 0.0022 - val_loss: 0.0022 - 656ms/epoch - 2ms/step\n",
      "Epoch 25/1000\n",
      "282/282 - 1s - loss: 0.0022 - val_loss: 0.0021 - 665ms/epoch - 2ms/step\n",
      "Epoch 26/1000\n",
      "282/282 - 1s - loss: 0.0022 - val_loss: 0.0024 - 662ms/epoch - 2ms/step\n",
      "Epoch 27/1000\n",
      "282/282 - 1s - loss: 0.0021 - val_loss: 0.0024 - 666ms/epoch - 2ms/step\n",
      "Epoch 28/1000\n",
      "282/282 - 1s - loss: 0.0021 - val_loss: 0.0022 - 674ms/epoch - 2ms/step\n",
      "Epoch 29/1000\n",
      "282/282 - 1s - loss: 0.0021 - val_loss: 0.0022 - 702ms/epoch - 2ms/step\n",
      "Epoch 30/1000\n",
      "282/282 - 1s - loss: 0.0022 - val_loss: 0.0021 - 692ms/epoch - 2ms/step\n",
      "Epoch 31/1000\n",
      "282/282 - 1s - loss: 0.0021 - val_loss: 0.0023 - 668ms/epoch - 2ms/step\n",
      "Epoch 32/1000\n",
      "282/282 - 1s - loss: 0.0021 - val_loss: 0.0022 - 662ms/epoch - 2ms/step\n",
      "Epoch 33/1000\n",
      "282/282 - 1s - loss: 0.0021 - val_loss: 0.0022 - 666ms/epoch - 2ms/step\n",
      "Epoch 34/1000\n",
      "282/282 - 1s - loss: 0.0021 - val_loss: 0.0023 - 668ms/epoch - 2ms/step\n",
      "Epoch 35/1000\n",
      "282/282 - 1s - loss: 0.0021 - val_loss: 0.0023 - 675ms/epoch - 2ms/step\n",
      "Epoch 36/1000\n",
      "282/282 - 1s - loss: 0.0021 - val_loss: 0.0022 - 668ms/epoch - 2ms/step\n",
      "Epoch 37/1000\n",
      "282/282 - 1s - loss: 0.0021 - val_loss: 0.0022 - 665ms/epoch - 2ms/step\n",
      "Epoch 38/1000\n",
      "282/282 - 1s - loss: 0.0021 - val_loss: 0.0024 - 671ms/epoch - 2ms/step\n",
      "Epoch 39/1000\n",
      "282/282 - 1s - loss: 0.0021 - val_loss: 0.0022 - 669ms/epoch - 2ms/step\n",
      "Epoch 40/1000\n",
      "282/282 - 1s - loss: 0.0021 - val_loss: 0.0024 - 697ms/epoch - 2ms/step\n",
      "Epoch 41/1000\n",
      "282/282 - 1s - loss: 0.0021 - val_loss: 0.0022 - 707ms/epoch - 3ms/step\n",
      "Epoch 42/1000\n",
      "282/282 - 1s - loss: 0.0021 - val_loss: 0.0022 - 689ms/epoch - 2ms/step\n",
      "Epoch 43/1000\n",
      "282/282 - 1s - loss: 0.0021 - val_loss: 0.0023 - 683ms/epoch - 2ms/step\n",
      "Epoch 44/1000\n",
      "282/282 - 1s - loss: 0.0021 - val_loss: 0.0023 - 680ms/epoch - 2ms/step\n",
      "Epoch 45/1000\n",
      "282/282 - 1s - loss: 0.0021 - val_loss: 0.0024 - 667ms/epoch - 2ms/step\n",
      "Epoch 46/1000\n",
      "282/282 - 1s - loss: 0.0021 - val_loss: 0.0024 - 661ms/epoch - 2ms/step\n",
      "Epoch 47/1000\n",
      "282/282 - 1s - loss: 0.0021 - val_loss: 0.0021 - 666ms/epoch - 2ms/step\n",
      "Epoch 48/1000\n",
      "282/282 - 1s - loss: 0.0021 - val_loss: 0.0021 - 672ms/epoch - 2ms/step\n",
      "Epoch 49/1000\n",
      "282/282 - 1s - loss: 0.0021 - val_loss: 0.0022 - 699ms/epoch - 2ms/step\n",
      "Epoch 50/1000\n",
      "282/282 - 1s - loss: 0.0021 - val_loss: 0.0022 - 709ms/epoch - 3ms/step\n",
      "Epoch 51/1000\n",
      "282/282 - 1s - loss: 0.0021 - val_loss: 0.0021 - 676ms/epoch - 2ms/step\n",
      "Epoch 52/1000\n",
      "282/282 - 1s - loss: 0.0021 - val_loss: 0.0022 - 664ms/epoch - 2ms/step\n",
      "Epoch 53/1000\n",
      "282/282 - 1s - loss: 0.0021 - val_loss: 0.0022 - 669ms/epoch - 2ms/step\n",
      "Epoch 54/1000\n",
      "282/282 - 1s - loss: 0.0021 - val_loss: 0.0021 - 671ms/epoch - 2ms/step\n",
      "Epoch 55/1000\n",
      "282/282 - 1s - loss: 0.0021 - val_loss: 0.0025 - 665ms/epoch - 2ms/step\n",
      "Epoch 56/1000\n",
      "282/282 - 1s - loss: 0.0021 - val_loss: 0.0021 - 671ms/epoch - 2ms/step\n",
      "Epoch 57/1000\n",
      "282/282 - 1s - loss: 0.0021 - val_loss: 0.0024 - 667ms/epoch - 2ms/step\n",
      "Epoch 58/1000\n",
      "282/282 - 1s - loss: 0.0021 - val_loss: 0.0023 - 670ms/epoch - 2ms/step\n",
      "Epoch 59/1000\n",
      "282/282 - 1s - loss: 0.0021 - val_loss: 0.0021 - 689ms/epoch - 2ms/step\n",
      "Epoch 60/1000\n",
      "282/282 - 1s - loss: 0.0021 - val_loss: 0.0024 - 707ms/epoch - 3ms/step\n",
      "Epoch 61/1000\n",
      "282/282 - 1s - loss: 0.0021 - val_loss: 0.0022 - 682ms/epoch - 2ms/step\n",
      "Epoch 62/1000\n",
      "282/282 - 1s - loss: 0.0021 - val_loss: 0.0023 - 733ms/epoch - 3ms/step\n",
      "Epoch 63/1000\n",
      "282/282 - 1s - loss: 0.0021 - val_loss: 0.0022 - 684ms/epoch - 2ms/step\n",
      "Epoch 64/1000\n",
      "282/282 - 1s - loss: 0.0021 - val_loss: 0.0021 - 718ms/epoch - 3ms/step\n",
      "Epoch 65/1000\n",
      "282/282 - 1s - loss: 0.0021 - val_loss: 0.0021 - 693ms/epoch - 2ms/step\n",
      "Epoch 66/1000\n",
      "282/282 - 1s - loss: 0.0021 - val_loss: 0.0023 - 725ms/epoch - 3ms/step\n",
      "Epoch 67/1000\n",
      "282/282 - 1s - loss: 0.0021 - val_loss: 0.0024 - 693ms/epoch - 2ms/step\n",
      "Epoch 68/1000\n",
      "282/282 - 1s - loss: 0.0021 - val_loss: 0.0022 - 695ms/epoch - 2ms/step\n",
      "Epoch 69/1000\n",
      "282/282 - 1s - loss: 0.0021 - val_loss: 0.0023 - 684ms/epoch - 2ms/step\n",
      "Epoch 70/1000\n",
      "282/282 - 1s - loss: 0.0021 - val_loss: 0.0024 - 676ms/epoch - 2ms/step\n",
      "Epoch 71/1000\n",
      "282/282 - 1s - loss: 0.0021 - val_loss: 0.0021 - 685ms/epoch - 2ms/step\n",
      "Epoch 72/1000\n",
      "282/282 - 1s - loss: 0.0021 - val_loss: 0.0023 - 683ms/epoch - 2ms/step\n",
      "Epoch 73/1000\n",
      "282/282 - 1s - loss: 0.0021 - val_loss: 0.0024 - 662ms/epoch - 2ms/step\n",
      "Epoch 74/1000\n",
      "282/282 - 1s - loss: 0.0021 - val_loss: 0.0023 - 696ms/epoch - 2ms/step\n",
      "Epoch 75/1000\n",
      "282/282 - 1s - loss: 0.0021 - val_loss: 0.0024 - 706ms/epoch - 3ms/step\n",
      "Epoch 76/1000\n",
      "282/282 - 1s - loss: 0.0021 - val_loss: 0.0021 - 687ms/epoch - 2ms/step\n",
      "Epoch 77/1000\n",
      "282/282 - 1s - loss: 0.0021 - val_loss: 0.0023 - 743ms/epoch - 3ms/step\n",
      "Epoch 78/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0024 - 665ms/epoch - 2ms/step\n",
      "Epoch 79/1000\n",
      "282/282 - 1s - loss: 0.0021 - val_loss: 0.0021 - 675ms/epoch - 2ms/step\n",
      "Epoch 80/1000\n",
      "282/282 - 1s - loss: 0.0021 - val_loss: 0.0023 - 678ms/epoch - 2ms/step\n",
      "Epoch 81/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0021 - 687ms/epoch - 2ms/step\n",
      "Epoch 82/1000\n",
      "282/282 - 1s - loss: 0.0021 - val_loss: 0.0023 - 668ms/epoch - 2ms/step\n",
      "Epoch 83/1000\n",
      "282/282 - 1s - loss: 0.0021 - val_loss: 0.0021 - 673ms/epoch - 2ms/step\n",
      "Epoch 84/1000\n",
      "282/282 - 1s - loss: 0.0021 - val_loss: 0.0023 - 678ms/epoch - 2ms/step\n",
      "Epoch 85/1000\n",
      "282/282 - 1s - loss: 0.0021 - val_loss: 0.0023 - 669ms/epoch - 2ms/step\n",
      "Epoch 86/1000\n",
      "282/282 - 1s - loss: 0.0021 - val_loss: 0.0022 - 676ms/epoch - 2ms/step\n",
      "Epoch 87/1000\n",
      "282/282 - 1s - loss: 0.0021 - val_loss: 0.0024 - 679ms/epoch - 2ms/step\n",
      "Epoch 88/1000\n",
      "282/282 - 1s - loss: 0.0021 - val_loss: 0.0025 - 665ms/epoch - 2ms/step\n",
      "Epoch 89/1000\n",
      "282/282 - 1s - loss: 0.0021 - val_loss: 0.0021 - 680ms/epoch - 2ms/step\n",
      "Epoch 90/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0023 - 682ms/epoch - 2ms/step\n",
      "Epoch 91/1000\n",
      "282/282 - 1s - loss: 0.0021 - val_loss: 0.0022 - 695ms/epoch - 2ms/step\n",
      "Epoch 92/1000\n",
      "282/282 - 1s - loss: 0.0021 - val_loss: 0.0023 - 689ms/epoch - 2ms/step\n",
      "Epoch 93/1000\n",
      "282/282 - 1s - loss: 0.0021 - val_loss: 0.0023 - 733ms/epoch - 3ms/step\n",
      "Epoch 94/1000\n",
      "282/282 - 1s - loss: 0.0021 - val_loss: 0.0023 - 676ms/epoch - 2ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 95/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0021 - 688ms/epoch - 2ms/step\n",
      "Epoch 96/1000\n",
      "282/282 - 1s - loss: 0.0021 - val_loss: 0.0026 - 682ms/epoch - 2ms/step\n",
      "Epoch 97/1000\n",
      "282/282 - 1s - loss: 0.0021 - val_loss: 0.0023 - 681ms/epoch - 2ms/step\n",
      "Epoch 98/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0020 - 751ms/epoch - 3ms/step\n",
      "Epoch 99/1000\n",
      "282/282 - 1s - loss: 0.0021 - val_loss: 0.0023 - 710ms/epoch - 3ms/step\n",
      "Epoch 100/1000\n",
      "282/282 - 1s - loss: 0.0021 - val_loss: 0.0022 - 699ms/epoch - 2ms/step\n",
      "Epoch 101/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0022 - 689ms/epoch - 2ms/step\n",
      "Epoch 102/1000\n",
      "282/282 - 1s - loss: 0.0021 - val_loss: 0.0023 - 692ms/epoch - 2ms/step\n",
      "Epoch 103/1000\n",
      "282/282 - 1s - loss: 0.0021 - val_loss: 0.0021 - 712ms/epoch - 3ms/step\n",
      "Epoch 104/1000\n",
      "282/282 - 1s - loss: 0.0021 - val_loss: 0.0022 - 695ms/epoch - 2ms/step\n",
      "Epoch 105/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0022 - 679ms/epoch - 2ms/step\n",
      "Epoch 106/1000\n",
      "282/282 - 1s - loss: 0.0021 - val_loss: 0.0022 - 667ms/epoch - 2ms/step\n",
      "Epoch 107/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0023 - 681ms/epoch - 2ms/step\n",
      "Epoch 108/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0021 - 674ms/epoch - 2ms/step\n",
      "Epoch 109/1000\n",
      "282/282 - 1s - loss: 0.0021 - val_loss: 0.0022 - 681ms/epoch - 2ms/step\n",
      "Epoch 110/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0024 - 676ms/epoch - 2ms/step\n",
      "Epoch 111/1000\n",
      "282/282 - 1s - loss: 0.0021 - val_loss: 0.0023 - 671ms/epoch - 2ms/step\n",
      "Epoch 112/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0024 - 670ms/epoch - 2ms/step\n",
      "Epoch 113/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0023 - 712ms/epoch - 3ms/step\n",
      "Epoch 114/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0021 - 727ms/epoch - 3ms/step\n",
      "Epoch 115/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0022 - 707ms/epoch - 3ms/step\n",
      "Epoch 116/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0025 - 691ms/epoch - 2ms/step\n",
      "Epoch 117/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0022 - 671ms/epoch - 2ms/step\n",
      "Epoch 118/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0022 - 692ms/epoch - 2ms/step\n",
      "Epoch 119/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0022 - 681ms/epoch - 2ms/step\n",
      "Epoch 120/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0022 - 707ms/epoch - 3ms/step\n",
      "Epoch 121/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0021 - 677ms/epoch - 2ms/step\n",
      "Epoch 122/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0022 - 687ms/epoch - 2ms/step\n",
      "Epoch 123/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0023 - 681ms/epoch - 2ms/step\n",
      "Epoch 124/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0021 - 701ms/epoch - 2ms/step\n",
      "Epoch 125/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0021 - 678ms/epoch - 2ms/step\n",
      "Epoch 126/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0023 - 673ms/epoch - 2ms/step\n",
      "Epoch 127/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0021 - 673ms/epoch - 2ms/step\n",
      "Epoch 128/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0023 - 702ms/epoch - 2ms/step\n",
      "Epoch 129/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0024 - 675ms/epoch - 2ms/step\n",
      "Epoch 130/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0022 - 667ms/epoch - 2ms/step\n",
      "Epoch 131/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0023 - 676ms/epoch - 2ms/step\n",
      "Epoch 132/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0022 - 707ms/epoch - 3ms/step\n",
      "Epoch 133/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0022 - 665ms/epoch - 2ms/step\n",
      "Epoch 134/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0022 - 680ms/epoch - 2ms/step\n",
      "Epoch 135/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0021 - 687ms/epoch - 2ms/step\n",
      "Epoch 136/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0021 - 681ms/epoch - 2ms/step\n",
      "Epoch 137/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0021 - 714ms/epoch - 3ms/step\n",
      "Epoch 138/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0023 - 684ms/epoch - 2ms/step\n",
      "Epoch 139/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0022 - 684ms/epoch - 2ms/step\n",
      "Epoch 140/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0022 - 687ms/epoch - 2ms/step\n",
      "Epoch 141/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0022 - 673ms/epoch - 2ms/step\n",
      "Epoch 142/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0021 - 688ms/epoch - 2ms/step\n",
      "Epoch 143/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0021 - 669ms/epoch - 2ms/step\n",
      "Epoch 144/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0022 - 666ms/epoch - 2ms/step\n",
      "Epoch 145/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0021 - 682ms/epoch - 2ms/step\n",
      "Epoch 146/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0022 - 674ms/epoch - 2ms/step\n",
      "Epoch 147/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0020 - 774ms/epoch - 3ms/step\n",
      "Epoch 148/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0021 - 693ms/epoch - 2ms/step\n",
      "Epoch 149/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0022 - 701ms/epoch - 2ms/step\n",
      "Epoch 150/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0020 - 792ms/epoch - 3ms/step\n",
      "Epoch 151/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0022 - 799ms/epoch - 3ms/step\n",
      "Epoch 152/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0023 - 764ms/epoch - 3ms/step\n",
      "Epoch 153/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0023 - 757ms/epoch - 3ms/step\n",
      "Epoch 154/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0022 - 771ms/epoch - 3ms/step\n",
      "Epoch 155/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0023 - 696ms/epoch - 2ms/step\n",
      "Epoch 156/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0022 - 683ms/epoch - 2ms/step\n",
      "Epoch 157/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0021 - 709ms/epoch - 3ms/step\n",
      "Epoch 158/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0021 - 703ms/epoch - 2ms/step\n",
      "Epoch 159/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0022 - 692ms/epoch - 2ms/step\n",
      "Epoch 160/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0022 - 712ms/epoch - 3ms/step\n",
      "Epoch 161/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0022 - 671ms/epoch - 2ms/step\n",
      "Epoch 162/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0021 - 677ms/epoch - 2ms/step\n",
      "Epoch 163/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0023 - 688ms/epoch - 2ms/step\n",
      "Epoch 164/1000\n",
      "282/282 - 1s - loss: 0.0021 - val_loss: 0.0021 - 676ms/epoch - 2ms/step\n",
      "Epoch 165/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0022 - 685ms/epoch - 2ms/step\n",
      "Epoch 166/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0021 - 692ms/epoch - 2ms/step\n",
      "Epoch 167/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0021 - 656ms/epoch - 2ms/step\n",
      "Epoch 168/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0021 - 666ms/epoch - 2ms/step\n",
      "Epoch 169/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0021 - 675ms/epoch - 2ms/step\n",
      "Epoch 170/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0022 - 670ms/epoch - 2ms/step\n",
      "Epoch 171/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0020 - 670ms/epoch - 2ms/step\n",
      "Epoch 172/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0022 - 672ms/epoch - 2ms/step\n",
      "Epoch 173/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0021 - 670ms/epoch - 2ms/step\n",
      "Epoch 174/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0021 - 681ms/epoch - 2ms/step\n",
      "Epoch 175/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0024 - 664ms/epoch - 2ms/step\n",
      "Epoch 176/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0020 - 690ms/epoch - 2ms/step\n",
      "Epoch 177/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0021 - 689ms/epoch - 2ms/step\n",
      "Epoch 178/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0021 - 668ms/epoch - 2ms/step\n",
      "Epoch 179/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0022 - 671ms/epoch - 2ms/step\n",
      "Epoch 180/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0021 - 689ms/epoch - 2ms/step\n",
      "Epoch 181/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0021 - 688ms/epoch - 2ms/step\n",
      "Epoch 182/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0021 - 682ms/epoch - 2ms/step\n",
      "Epoch 183/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0019 - 759ms/epoch - 3ms/step\n",
      "Epoch 184/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0022 - 711ms/epoch - 3ms/step\n",
      "Epoch 185/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0019 - 710ms/epoch - 3ms/step\n",
      "Epoch 186/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0021 - 669ms/epoch - 2ms/step\n",
      "Epoch 187/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0020 - 669ms/epoch - 2ms/step\n",
      "Epoch 188/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0019 - 752ms/epoch - 3ms/step\n",
      "Epoch 189/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0022 - 675ms/epoch - 2ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 190/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0023 - 680ms/epoch - 2ms/step\n",
      "Epoch 191/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0023 - 676ms/epoch - 2ms/step\n",
      "Epoch 192/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0020 - 666ms/epoch - 2ms/step\n",
      "Epoch 193/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0024 - 663ms/epoch - 2ms/step\n",
      "Epoch 194/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0023 - 668ms/epoch - 2ms/step\n",
      "Epoch 195/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0021 - 673ms/epoch - 2ms/step\n",
      "Epoch 196/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0019 - 674ms/epoch - 2ms/step\n",
      "Epoch 197/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0020 - 666ms/epoch - 2ms/step\n",
      "Epoch 198/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0019 - 701ms/epoch - 2ms/step\n",
      "Epoch 199/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0021 - 699ms/epoch - 2ms/step\n",
      "Epoch 200/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0020 - 716ms/epoch - 3ms/step\n",
      "Epoch 201/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0019 - 741ms/epoch - 3ms/step\n",
      "Epoch 202/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0021 - 655ms/epoch - 2ms/step\n",
      "Epoch 203/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0019 - 688ms/epoch - 2ms/step\n",
      "Epoch 204/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0021 - 674ms/epoch - 2ms/step\n",
      "Epoch 205/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0020 - 674ms/epoch - 2ms/step\n",
      "Epoch 206/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0020 - 685ms/epoch - 2ms/step\n",
      "Epoch 207/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0020 - 701ms/epoch - 2ms/step\n",
      "Epoch 208/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0019 - 672ms/epoch - 2ms/step\n",
      "Epoch 209/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0022 - 671ms/epoch - 2ms/step\n",
      "Epoch 210/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0020 - 690ms/epoch - 2ms/step\n",
      "Epoch 211/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0020 - 683ms/epoch - 2ms/step\n",
      "Epoch 212/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0020 - 670ms/epoch - 2ms/step\n",
      "Epoch 213/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0021 - 685ms/epoch - 2ms/step\n",
      "Epoch 214/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0020 - 721ms/epoch - 3ms/step\n",
      "Epoch 215/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0020 - 704ms/epoch - 2ms/step\n",
      "Epoch 216/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0020 - 680ms/epoch - 2ms/step\n",
      "Epoch 217/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0019 - 713ms/epoch - 3ms/step\n",
      "Epoch 218/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0020 - 693ms/epoch - 2ms/step\n",
      "Epoch 219/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0020 - 697ms/epoch - 2ms/step\n",
      "Epoch 220/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0019 - 675ms/epoch - 2ms/step\n",
      "Epoch 221/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0019 - 717ms/epoch - 3ms/step\n",
      "Epoch 222/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0020 - 673ms/epoch - 2ms/step\n",
      "Epoch 223/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0020 - 693ms/epoch - 2ms/step\n",
      "Epoch 224/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0019 - 780ms/epoch - 3ms/step\n",
      "Epoch 225/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0019 - 698ms/epoch - 2ms/step\n",
      "Epoch 226/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0018 - 714ms/epoch - 3ms/step\n",
      "Epoch 227/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0020 - 693ms/epoch - 2ms/step\n",
      "Epoch 228/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0020 - 681ms/epoch - 2ms/step\n",
      "Epoch 229/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0018 - 728ms/epoch - 3ms/step\n",
      "Epoch 230/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0020 - 668ms/epoch - 2ms/step\n",
      "Epoch 231/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0021 - 683ms/epoch - 2ms/step\n",
      "Epoch 232/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0020 - 728ms/epoch - 3ms/step\n",
      "Epoch 233/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0020 - 725ms/epoch - 3ms/step\n",
      "Epoch 234/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0020 - 677ms/epoch - 2ms/step\n",
      "Epoch 235/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0019 - 753ms/epoch - 3ms/step\n",
      "Epoch 236/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0020 - 799ms/epoch - 3ms/step\n",
      "Epoch 237/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0020 - 707ms/epoch - 3ms/step\n",
      "Epoch 238/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0018 - 702ms/epoch - 2ms/step\n",
      "Epoch 239/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0018 - 701ms/epoch - 2ms/step\n",
      "Epoch 240/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0018 - 723ms/epoch - 3ms/step\n",
      "Epoch 241/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0018 - 713ms/epoch - 3ms/step\n",
      "Epoch 242/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0020 - 696ms/epoch - 2ms/step\n",
      "Epoch 243/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0019 - 746ms/epoch - 3ms/step\n",
      "Epoch 244/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0020 - 675ms/epoch - 2ms/step\n",
      "Epoch 245/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0021 - 720ms/epoch - 3ms/step\n",
      "Epoch 246/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0020 - 684ms/epoch - 2ms/step\n",
      "Epoch 247/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0019 - 679ms/epoch - 2ms/step\n",
      "Epoch 248/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0020 - 732ms/epoch - 3ms/step\n",
      "Epoch 249/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0019 - 708ms/epoch - 3ms/step\n",
      "Epoch 250/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0019 - 706ms/epoch - 3ms/step\n",
      "Epoch 251/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0018 - 809ms/epoch - 3ms/step\n",
      "Epoch 252/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0019 - 722ms/epoch - 3ms/step\n",
      "Epoch 253/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0021 - 758ms/epoch - 3ms/step\n",
      "Epoch 254/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0018 - 679ms/epoch - 2ms/step\n",
      "Epoch 255/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0017 - 730ms/epoch - 3ms/step\n",
      "Epoch 256/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0019 - 718ms/epoch - 3ms/step\n",
      "Epoch 257/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0021 - 723ms/epoch - 3ms/step\n",
      "Epoch 258/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0019 - 667ms/epoch - 2ms/step\n",
      "Epoch 259/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0018 - 671ms/epoch - 2ms/step\n",
      "Epoch 260/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0019 - 716ms/epoch - 3ms/step\n",
      "Epoch 261/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0018 - 731ms/epoch - 3ms/step\n",
      "Epoch 262/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0019 - 724ms/epoch - 3ms/step\n",
      "Epoch 263/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0020 - 715ms/epoch - 3ms/step\n",
      "Epoch 264/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0018 - 736ms/epoch - 3ms/step\n",
      "Epoch 265/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0018 - 714ms/epoch - 3ms/step\n",
      "Epoch 266/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0019 - 689ms/epoch - 2ms/step\n",
      "Epoch 267/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0018 - 689ms/epoch - 2ms/step\n",
      "Epoch 268/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0017 - 664ms/epoch - 2ms/step\n",
      "Epoch 269/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0019 - 692ms/epoch - 2ms/step\n",
      "Epoch 270/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0019 - 680ms/epoch - 2ms/step\n",
      "Epoch 271/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0018 - 689ms/epoch - 2ms/step\n",
      "Epoch 272/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0019 - 694ms/epoch - 2ms/step\n",
      "Epoch 273/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0018 - 708ms/epoch - 3ms/step\n",
      "Epoch 274/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0018 - 714ms/epoch - 3ms/step\n",
      "Epoch 275/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0017 - 692ms/epoch - 2ms/step\n",
      "Epoch 276/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0018 - 704ms/epoch - 2ms/step\n",
      "Epoch 277/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0018 - 691ms/epoch - 2ms/step\n",
      "Epoch 278/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0019 - 677ms/epoch - 2ms/step\n",
      "Epoch 279/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0018 - 673ms/epoch - 2ms/step\n",
      "Epoch 280/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0019 - 664ms/epoch - 2ms/step\n",
      "Epoch 281/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0019 - 664ms/epoch - 2ms/step\n",
      "Epoch 282/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0018 - 669ms/epoch - 2ms/step\n",
      "Epoch 283/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0019 - 665ms/epoch - 2ms/step\n",
      "Epoch 284/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0019 - 671ms/epoch - 2ms/step\n",
      "Epoch 285/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0019 - 698ms/epoch - 2ms/step\n",
      "Epoch 286/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0019 - 711ms/epoch - 3ms/step\n",
      "Epoch 287/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0018 - 702ms/epoch - 2ms/step\n",
      "Epoch 288/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0019 - 701ms/epoch - 2ms/step\n",
      "Epoch 289/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0019 - 670ms/epoch - 2ms/step\n",
      "Epoch 290/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0020 - 682ms/epoch - 2ms/step\n",
      "Epoch 291/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0019 - 661ms/epoch - 2ms/step\n",
      "Epoch 292/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0018 - 664ms/epoch - 2ms/step\n",
      "Epoch 293/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0018 - 668ms/epoch - 2ms/step\n",
      "Epoch 294/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0018 - 666ms/epoch - 2ms/step\n",
      "Epoch 295/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0017 - 676ms/epoch - 2ms/step\n",
      "Epoch 296/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0018 - 676ms/epoch - 2ms/step\n",
      "Epoch 297/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0017 - 659ms/epoch - 2ms/step\n",
      "Epoch 298/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0018 - 663ms/epoch - 2ms/step\n",
      "Epoch 299/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0017 - 670ms/epoch - 2ms/step\n",
      "Epoch 300/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0018 - 661ms/epoch - 2ms/step\n",
      "Epoch 301/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0018 - 673ms/epoch - 2ms/step\n",
      "Epoch 302/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0019 - 666ms/epoch - 2ms/step\n",
      "Epoch 303/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0018 - 666ms/epoch - 2ms/step\n",
      "Epoch 304/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0019 - 670ms/epoch - 2ms/step\n",
      "Epoch 305/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0019 - 703ms/epoch - 2ms/step\n",
      "Epoch 306/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0017 - 793ms/epoch - 3ms/step\n",
      "Epoch 307/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0019 - 711ms/epoch - 3ms/step\n",
      "Epoch 308/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0020 - 748ms/epoch - 3ms/step\n",
      "Epoch 309/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0018 - 694ms/epoch - 2ms/step\n",
      "Epoch 310/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0018 - 696ms/epoch - 2ms/step\n",
      "Epoch 311/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0017 - 659ms/epoch - 2ms/step\n",
      "Epoch 312/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0019 - 692ms/epoch - 2ms/step\n",
      "Epoch 313/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0018 - 686ms/epoch - 2ms/step\n",
      "Epoch 314/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0018 - 689ms/epoch - 2ms/step\n",
      "Epoch 315/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0017 - 672ms/epoch - 2ms/step\n",
      "Epoch 316/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0018 - 690ms/epoch - 2ms/step\n",
      "Epoch 317/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0017 - 704ms/epoch - 2ms/step\n",
      "Epoch 318/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0019 - 706ms/epoch - 3ms/step\n",
      "Epoch 319/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0018 - 716ms/epoch - 3ms/step\n",
      "Epoch 320/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0018 - 698ms/epoch - 2ms/step\n",
      "Epoch 321/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0018 - 678ms/epoch - 2ms/step\n",
      "Epoch 322/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0018 - 711ms/epoch - 3ms/step\n",
      "Epoch 323/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0018 - 689ms/epoch - 2ms/step\n",
      "Epoch 324/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0018 - 705ms/epoch - 3ms/step\n",
      "Epoch 325/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0018 - 739ms/epoch - 3ms/step\n",
      "Epoch 326/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0019 - 698ms/epoch - 2ms/step\n",
      "Epoch 327/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0018 - 710ms/epoch - 3ms/step\n",
      "Epoch 328/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0018 - 721ms/epoch - 3ms/step\n",
      "Epoch 329/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0017 - 689ms/epoch - 2ms/step\n",
      "Epoch 330/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0018 - 680ms/epoch - 2ms/step\n",
      "Epoch 331/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0018 - 709ms/epoch - 3ms/step\n",
      "Epoch 332/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0017 - 723ms/epoch - 3ms/step\n",
      "Epoch 333/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0017 - 700ms/epoch - 2ms/step\n",
      "Epoch 334/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0017 - 740ms/epoch - 3ms/step\n",
      "Epoch 335/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0019 - 697ms/epoch - 2ms/step\n",
      "Epoch 336/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0018 - 681ms/epoch - 2ms/step\n",
      "Epoch 337/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0020 - 713ms/epoch - 3ms/step\n",
      "Epoch 338/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0017 - 781ms/epoch - 3ms/step\n",
      "Epoch 339/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0017 - 733ms/epoch - 3ms/step\n",
      "Epoch 340/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0018 - 722ms/epoch - 3ms/step\n",
      "Epoch 341/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0018 - 716ms/epoch - 3ms/step\n",
      "Epoch 342/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0017 - 775ms/epoch - 3ms/step\n",
      "Epoch 343/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0018 - 735ms/epoch - 3ms/step\n",
      "Epoch 344/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0018 - 698ms/epoch - 2ms/step\n",
      "Epoch 345/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0017 - 685ms/epoch - 2ms/step\n",
      "Epoch 346/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0020 - 684ms/epoch - 2ms/step\n",
      "Epoch 347/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0017 - 666ms/epoch - 2ms/step\n",
      "Epoch 348/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0017 - 667ms/epoch - 2ms/step\n",
      "Epoch 349/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0020 - 668ms/epoch - 2ms/step\n",
      "Epoch 350/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0018 - 666ms/epoch - 2ms/step\n",
      "Epoch 351/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0019 - 691ms/epoch - 2ms/step\n",
      "Epoch 352/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0017 - 784ms/epoch - 3ms/step\n",
      "Epoch 353/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0018 - 705ms/epoch - 2ms/step\n",
      "Epoch 354/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0018 - 762ms/epoch - 3ms/step\n",
      "Epoch 355/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0017 - 678ms/epoch - 2ms/step\n",
      "Epoch 356/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0017 - 701ms/epoch - 2ms/step\n",
      "Epoch 357/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0017 - 706ms/epoch - 3ms/step\n",
      "Epoch 358/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0018 - 705ms/epoch - 3ms/step\n",
      "Epoch 359/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0019 - 705ms/epoch - 3ms/step\n",
      "Epoch 360/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0019 - 744ms/epoch - 3ms/step\n",
      "Epoch 361/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0018 - 698ms/epoch - 2ms/step\n",
      "Epoch 362/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0019 - 704ms/epoch - 2ms/step\n",
      "Epoch 363/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0019 - 706ms/epoch - 3ms/step\n",
      "Epoch 364/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0018 - 681ms/epoch - 2ms/step\n",
      "Epoch 365/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0019 - 709ms/epoch - 3ms/step\n",
      "Epoch 366/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0018 - 717ms/epoch - 3ms/step\n",
      "Epoch 367/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0017 - 731ms/epoch - 3ms/step\n",
      "Epoch 368/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0018 - 743ms/epoch - 3ms/step\n",
      "Epoch 369/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0018 - 691ms/epoch - 2ms/step\n",
      "Epoch 370/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0019 - 690ms/epoch - 2ms/step\n",
      "Epoch 371/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0022 - 731ms/epoch - 3ms/step\n",
      "Epoch 372/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0018 - 698ms/epoch - 2ms/step\n",
      "Epoch 373/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0017 - 683ms/epoch - 2ms/step\n",
      "Epoch 374/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0018 - 693ms/epoch - 2ms/step\n",
      "Epoch 375/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0017 - 708ms/epoch - 3ms/step\n",
      "Epoch 376/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0018 - 821ms/epoch - 3ms/step\n",
      "Epoch 377/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0018 - 716ms/epoch - 3ms/step\n",
      "Epoch 378/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0018 - 678ms/epoch - 2ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 379/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0019 - 689ms/epoch - 2ms/step\n",
      "Epoch 380/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0018 - 674ms/epoch - 2ms/step\n",
      "Epoch 381/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0019 - 662ms/epoch - 2ms/step\n",
      "Epoch 382/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0017 - 674ms/epoch - 2ms/step\n",
      "Epoch 383/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0017 - 676ms/epoch - 2ms/step\n",
      "Epoch 384/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0017 - 674ms/epoch - 2ms/step\n",
      "Epoch 385/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0019 - 682ms/epoch - 2ms/step\n",
      "Epoch 386/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0017 - 674ms/epoch - 2ms/step\n",
      "Epoch 387/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0018 - 670ms/epoch - 2ms/step\n",
      "Epoch 388/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0017 - 683ms/epoch - 2ms/step\n",
      "Epoch 389/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0017 - 682ms/epoch - 2ms/step\n",
      "Epoch 390/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0018 - 690ms/epoch - 2ms/step\n",
      "Epoch 391/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0018 - 678ms/epoch - 2ms/step\n",
      "Epoch 392/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0017 - 681ms/epoch - 2ms/step\n",
      "Epoch 393/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0018 - 670ms/epoch - 2ms/step\n",
      "Epoch 394/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0017 - 755ms/epoch - 3ms/step\n",
      "Epoch 395/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0017 - 816ms/epoch - 3ms/step\n",
      "Epoch 396/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0017 - 790ms/epoch - 3ms/step\n",
      "Epoch 397/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0018 - 651ms/epoch - 2ms/step\n",
      "Epoch 398/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0018 - 743ms/epoch - 3ms/step\n",
      "Epoch 399/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0018 - 733ms/epoch - 3ms/step\n",
      "Epoch 400/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0018 - 727ms/epoch - 3ms/step\n",
      "Epoch 401/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0018 - 742ms/epoch - 3ms/step\n",
      "Epoch 402/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0018 - 885ms/epoch - 3ms/step\n",
      "Epoch 403/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0018 - 751ms/epoch - 3ms/step\n",
      "Epoch 404/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0019 - 697ms/epoch - 2ms/step\n",
      "Epoch 405/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0018 - 700ms/epoch - 2ms/step\n",
      "Epoch 406/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0017 - 702ms/epoch - 2ms/step\n",
      "Epoch 407/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0018 - 765ms/epoch - 3ms/step\n",
      "Epoch 408/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0018 - 754ms/epoch - 3ms/step\n",
      "Epoch 409/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0017 - 725ms/epoch - 3ms/step\n",
      "Epoch 410/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0018 - 724ms/epoch - 3ms/step\n",
      "Epoch 411/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0018 - 737ms/epoch - 3ms/step\n",
      "Epoch 412/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0018 - 726ms/epoch - 3ms/step\n",
      "Epoch 413/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0019 - 760ms/epoch - 3ms/step\n",
      "Epoch 414/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0017 - 746ms/epoch - 3ms/step\n",
      "Epoch 415/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0018 - 751ms/epoch - 3ms/step\n",
      "Epoch 416/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0018 - 718ms/epoch - 3ms/step\n",
      "Epoch 417/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0017 - 752ms/epoch - 3ms/step\n",
      "Epoch 418/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0017 - 725ms/epoch - 3ms/step\n",
      "Epoch 419/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0022 - 741ms/epoch - 3ms/step\n",
      "Epoch 420/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0017 - 720ms/epoch - 3ms/step\n",
      "Epoch 421/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0018 - 723ms/epoch - 3ms/step\n",
      "Epoch 422/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0018 - 767ms/epoch - 3ms/step\n",
      "Epoch 423/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0017 - 732ms/epoch - 3ms/step\n",
      "Epoch 424/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0018 - 734ms/epoch - 3ms/step\n",
      "Epoch 425/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0018 - 730ms/epoch - 3ms/step\n",
      "Epoch 426/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0020 - 737ms/epoch - 3ms/step\n",
      "Epoch 427/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0017 - 759ms/epoch - 3ms/step\n",
      "Epoch 428/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0017 - 689ms/epoch - 2ms/step\n",
      "Epoch 429/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0018 - 709ms/epoch - 3ms/step\n",
      "Epoch 430/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0018 - 757ms/epoch - 3ms/step\n",
      "Epoch 431/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0017 - 686ms/epoch - 2ms/step\n",
      "Epoch 432/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0019 - 724ms/epoch - 3ms/step\n",
      "Epoch 433/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0018 - 682ms/epoch - 2ms/step\n",
      "Epoch 434/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0017 - 669ms/epoch - 2ms/step\n",
      "Epoch 435/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0017 - 666ms/epoch - 2ms/step\n",
      "Epoch 436/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0017 - 669ms/epoch - 2ms/step\n",
      "Epoch 437/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0017 - 664ms/epoch - 2ms/step\n",
      "Epoch 438/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0019 - 722ms/epoch - 3ms/step\n",
      "Epoch 439/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0018 - 830ms/epoch - 3ms/step\n",
      "Epoch 440/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0017 - 710ms/epoch - 3ms/step\n",
      "Epoch 441/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0018 - 758ms/epoch - 3ms/step\n",
      "Epoch 442/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0018 - 784ms/epoch - 3ms/step\n",
      "Epoch 443/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0018 - 727ms/epoch - 3ms/step\n",
      "Epoch 444/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0018 - 707ms/epoch - 3ms/step\n",
      "Epoch 445/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0017 - 758ms/epoch - 3ms/step\n",
      "Epoch 446/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0017 - 934ms/epoch - 3ms/step\n",
      "Epoch 447/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0019 - 868ms/epoch - 3ms/step\n",
      "Epoch 448/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0018 - 925ms/epoch - 3ms/step\n",
      "Epoch 449/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0018 - 1s/epoch - 5ms/step\n",
      "Epoch 450/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0017 - 992ms/epoch - 4ms/step\n",
      "Epoch 451/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0018 - 1s/epoch - 4ms/step\n",
      "Epoch 452/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0019 - 804ms/epoch - 3ms/step\n",
      "Epoch 453/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0019 - 864ms/epoch - 3ms/step\n",
      "Epoch 454/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0017 - 726ms/epoch - 3ms/step\n",
      "Epoch 455/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0018 - 816ms/epoch - 3ms/step\n",
      "Epoch 456/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0017 - 822ms/epoch - 3ms/step\n",
      "Epoch 457/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0017 - 834ms/epoch - 3ms/step\n",
      "Epoch 458/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0018 - 854ms/epoch - 3ms/step\n",
      "Epoch 459/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0017 - 837ms/epoch - 3ms/step\n",
      "Epoch 460/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0017 - 830ms/epoch - 3ms/step\n",
      "Epoch 461/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0017 - 820ms/epoch - 3ms/step\n",
      "Epoch 462/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0017 - 796ms/epoch - 3ms/step\n",
      "Epoch 463/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0019 - 797ms/epoch - 3ms/step\n",
      "Epoch 464/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0018 - 798ms/epoch - 3ms/step\n",
      "Epoch 465/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0017 - 787ms/epoch - 3ms/step\n",
      "Epoch 466/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0018 - 758ms/epoch - 3ms/step\n",
      "Epoch 467/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0018 - 703ms/epoch - 2ms/step\n",
      "Epoch 468/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0017 - 725ms/epoch - 3ms/step\n",
      "Epoch 469/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0018 - 759ms/epoch - 3ms/step\n",
      "Epoch 470/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0018 - 759ms/epoch - 3ms/step\n",
      "Epoch 471/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0018 - 1s/epoch - 4ms/step\n",
      "Epoch 472/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0020 - 819ms/epoch - 3ms/step\n",
      "Epoch 473/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0018 - 946ms/epoch - 3ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 474/1000\n",
      "282/282 - 2s - loss: 0.0020 - val_loss: 0.0018 - 2s/epoch - 6ms/step\n",
      "Epoch 475/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0017 - 1s/epoch - 4ms/step\n",
      "Epoch 476/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0018 - 961ms/epoch - 3ms/step\n",
      "Epoch 477/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0018 - 947ms/epoch - 3ms/step\n",
      "Epoch 478/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0017 - 840ms/epoch - 3ms/step\n",
      "Epoch 479/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0018 - 842ms/epoch - 3ms/step\n",
      "Epoch 480/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0018 - 852ms/epoch - 3ms/step\n",
      "Epoch 481/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0017 - 861ms/epoch - 3ms/step\n",
      "Epoch 482/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0017 - 790ms/epoch - 3ms/step\n",
      "Epoch 483/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0017 - 678ms/epoch - 2ms/step\n",
      "Epoch 484/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0017 - 725ms/epoch - 3ms/step\n",
      "Epoch 485/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0018 - 748ms/epoch - 3ms/step\n",
      "Epoch 486/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0017 - 775ms/epoch - 3ms/step\n",
      "Epoch 487/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0018 - 738ms/epoch - 3ms/step\n",
      "Epoch 488/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0018 - 765ms/epoch - 3ms/step\n",
      "Epoch 489/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0018 - 719ms/epoch - 3ms/step\n",
      "Epoch 490/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0017 - 712ms/epoch - 3ms/step\n",
      "Epoch 491/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0018 - 703ms/epoch - 2ms/step\n",
      "Epoch 492/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0018 - 729ms/epoch - 3ms/step\n",
      "Epoch 493/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0019 - 709ms/epoch - 3ms/step\n",
      "Epoch 494/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0019 - 722ms/epoch - 3ms/step\n",
      "Epoch 495/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0017 - 699ms/epoch - 2ms/step\n",
      "Epoch 496/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0017 - 698ms/epoch - 2ms/step\n",
      "Epoch 497/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0017 - 727ms/epoch - 3ms/step\n",
      "Epoch 498/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0017 - 674ms/epoch - 2ms/step\n",
      "Epoch 499/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0018 - 698ms/epoch - 2ms/step\n",
      "Epoch 500/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0017 - 761ms/epoch - 3ms/step\n",
      "Epoch 501/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0017 - 746ms/epoch - 3ms/step\n",
      "Epoch 502/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0017 - 732ms/epoch - 3ms/step\n",
      "Epoch 503/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0017 - 700ms/epoch - 2ms/step\n",
      "Epoch 504/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0017 - 727ms/epoch - 3ms/step\n",
      "Epoch 505/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0017 - 703ms/epoch - 2ms/step\n",
      "Epoch 506/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0018 - 726ms/epoch - 3ms/step\n",
      "Epoch 507/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0017 - 714ms/epoch - 3ms/step\n",
      "Epoch 508/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0018 - 702ms/epoch - 2ms/step\n",
      "Epoch 509/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0017 - 690ms/epoch - 2ms/step\n",
      "Epoch 510/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0019 - 701ms/epoch - 2ms/step\n",
      "Epoch 511/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0018 - 671ms/epoch - 2ms/step\n",
      "Epoch 512/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0017 - 697ms/epoch - 2ms/step\n",
      "Epoch 513/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0017 - 707ms/epoch - 3ms/step\n",
      "Epoch 514/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0017 - 689ms/epoch - 2ms/step\n",
      "Epoch 515/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0018 - 690ms/epoch - 2ms/step\n",
      "Epoch 516/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0017 - 688ms/epoch - 2ms/step\n",
      "Epoch 517/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0018 - 672ms/epoch - 2ms/step\n",
      "Epoch 518/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0018 - 679ms/epoch - 2ms/step\n",
      "Epoch 519/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0016 - 745ms/epoch - 3ms/step\n",
      "Epoch 520/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0017 - 710ms/epoch - 3ms/step\n",
      "Epoch 521/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0018 - 708ms/epoch - 3ms/step\n",
      "Epoch 522/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0017 - 678ms/epoch - 2ms/step\n",
      "Epoch 523/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0017 - 675ms/epoch - 2ms/step\n",
      "Epoch 524/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0018 - 685ms/epoch - 2ms/step\n",
      "Epoch 525/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0019 - 706ms/epoch - 3ms/step\n",
      "Epoch 526/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0017 - 672ms/epoch - 2ms/step\n",
      "Epoch 527/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0018 - 689ms/epoch - 2ms/step\n",
      "Epoch 528/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0017 - 711ms/epoch - 3ms/step\n",
      "Epoch 529/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0018 - 673ms/epoch - 2ms/step\n",
      "Epoch 530/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0019 - 679ms/epoch - 2ms/step\n",
      "Epoch 531/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0017 - 687ms/epoch - 2ms/step\n",
      "Epoch 532/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0018 - 673ms/epoch - 2ms/step\n",
      "Epoch 533/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0017 - 679ms/epoch - 2ms/step\n",
      "Epoch 534/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0016 - 773ms/epoch - 3ms/step\n",
      "Epoch 535/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0017 - 709ms/epoch - 3ms/step\n",
      "Epoch 536/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0016 - 740ms/epoch - 3ms/step\n",
      "Epoch 537/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0016 - 725ms/epoch - 3ms/step\n",
      "Epoch 538/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0017 - 692ms/epoch - 2ms/step\n",
      "Epoch 539/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0018 - 675ms/epoch - 2ms/step\n",
      "Epoch 540/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0017 - 679ms/epoch - 2ms/step\n",
      "Epoch 541/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0018 - 672ms/epoch - 2ms/step\n",
      "Epoch 542/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0017 - 679ms/epoch - 2ms/step\n",
      "Epoch 543/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0017 - 682ms/epoch - 2ms/step\n",
      "Epoch 544/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0017 - 672ms/epoch - 2ms/step\n",
      "Epoch 545/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0018 - 675ms/epoch - 2ms/step\n",
      "Epoch 546/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0017 - 683ms/epoch - 2ms/step\n",
      "Epoch 547/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0018 - 674ms/epoch - 2ms/step\n",
      "Epoch 548/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0017 - 676ms/epoch - 2ms/step\n",
      "Epoch 549/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0017 - 685ms/epoch - 2ms/step\n",
      "Epoch 550/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0018 - 678ms/epoch - 2ms/step\n",
      "Epoch 551/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0018 - 681ms/epoch - 2ms/step\n",
      "Epoch 552/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0017 - 681ms/epoch - 2ms/step\n",
      "Epoch 553/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0017 - 671ms/epoch - 2ms/step\n",
      "Epoch 554/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0018 - 674ms/epoch - 2ms/step\n",
      "Epoch 555/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0018 - 677ms/epoch - 2ms/step\n",
      "Epoch 556/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0019 - 672ms/epoch - 2ms/step\n",
      "Epoch 557/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0018 - 676ms/epoch - 2ms/step\n",
      "Epoch 558/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0020 - 678ms/epoch - 2ms/step\n",
      "Epoch 559/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0019 - 674ms/epoch - 2ms/step\n",
      "Epoch 560/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0019 - 675ms/epoch - 2ms/step\n",
      "Epoch 561/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0017 - 688ms/epoch - 2ms/step\n",
      "Epoch 562/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0016 - 676ms/epoch - 2ms/step\n",
      "Epoch 563/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0018 - 674ms/epoch - 2ms/step\n",
      "Epoch 564/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0017 - 684ms/epoch - 2ms/step\n",
      "Epoch 565/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0017 - 664ms/epoch - 2ms/step\n",
      "Epoch 566/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0017 - 710ms/epoch - 3ms/step\n",
      "Epoch 567/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0017 - 686ms/epoch - 2ms/step\n",
      "Epoch 568/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0018 - 671ms/epoch - 2ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 569/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0018 - 683ms/epoch - 2ms/step\n",
      "Epoch 570/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0018 - 670ms/epoch - 2ms/step\n",
      "Epoch 571/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0019 - 684ms/epoch - 2ms/step\n",
      "Epoch 572/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0017 - 735ms/epoch - 3ms/step\n",
      "Epoch 573/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0017 - 661ms/epoch - 2ms/step\n",
      "Epoch 574/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0017 - 652ms/epoch - 2ms/step\n",
      "Epoch 575/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0017 - 682ms/epoch - 2ms/step\n",
      "Epoch 576/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0018 - 669ms/epoch - 2ms/step\n",
      "Epoch 577/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0019 - 685ms/epoch - 2ms/step\n",
      "Epoch 578/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0018 - 703ms/epoch - 2ms/step\n",
      "Epoch 579/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0018 - 690ms/epoch - 2ms/step\n",
      "Epoch 580/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0018 - 690ms/epoch - 2ms/step\n",
      "Epoch 581/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0018 - 686ms/epoch - 2ms/step\n",
      "Epoch 582/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0017 - 704ms/epoch - 2ms/step\n",
      "Epoch 583/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0017 - 681ms/epoch - 2ms/step\n",
      "Epoch 584/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0018 - 677ms/epoch - 2ms/step\n",
      "Epoch 585/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0017 - 671ms/epoch - 2ms/step\n",
      "Epoch 586/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0018 - 679ms/epoch - 2ms/step\n",
      "Epoch 587/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0018 - 681ms/epoch - 2ms/step\n",
      "Epoch 588/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0017 - 671ms/epoch - 2ms/step\n",
      "Epoch 589/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0019 - 676ms/epoch - 2ms/step\n",
      "Epoch 590/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0018 - 678ms/epoch - 2ms/step\n",
      "Epoch 591/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0018 - 707ms/epoch - 3ms/step\n",
      "Epoch 592/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0017 - 683ms/epoch - 2ms/step\n",
      "Epoch 593/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0017 - 679ms/epoch - 2ms/step\n",
      "Epoch 594/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0017 - 672ms/epoch - 2ms/step\n",
      "Epoch 595/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0018 - 689ms/epoch - 2ms/step\n",
      "Epoch 596/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0017 - 675ms/epoch - 2ms/step\n",
      "Epoch 597/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0017 - 674ms/epoch - 2ms/step\n",
      "Epoch 598/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0018 - 677ms/epoch - 2ms/step\n",
      "Epoch 599/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0019 - 680ms/epoch - 2ms/step\n",
      "Epoch 600/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0017 - 709ms/epoch - 3ms/step\n",
      "Epoch 601/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0017 - 692ms/epoch - 2ms/step\n",
      "Epoch 602/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0017 - 677ms/epoch - 2ms/step\n",
      "Epoch 603/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0018 - 673ms/epoch - 2ms/step\n",
      "Epoch 604/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0018 - 676ms/epoch - 2ms/step\n",
      "Epoch 605/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0018 - 677ms/epoch - 2ms/step\n",
      "Epoch 606/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0018 - 671ms/epoch - 2ms/step\n",
      "Epoch 607/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0019 - 675ms/epoch - 2ms/step\n",
      "Epoch 608/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0018 - 686ms/epoch - 2ms/step\n",
      "Epoch 609/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0018 - 672ms/epoch - 2ms/step\n",
      "Epoch 610/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0017 - 681ms/epoch - 2ms/step\n",
      "Epoch 611/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0020 - 679ms/epoch - 2ms/step\n",
      "Epoch 612/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0017 - 715ms/epoch - 3ms/step\n",
      "Epoch 613/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0018 - 683ms/epoch - 2ms/step\n",
      "Epoch 614/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0018 - 678ms/epoch - 2ms/step\n",
      "Epoch 615/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0017 - 672ms/epoch - 2ms/step\n",
      "Epoch 616/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0017 - 688ms/epoch - 2ms/step\n",
      "Epoch 617/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0017 - 671ms/epoch - 2ms/step\n",
      "Epoch 618/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0017 - 684ms/epoch - 2ms/step\n",
      "Epoch 619/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0018 - 684ms/epoch - 2ms/step\n",
      "Epoch 620/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0017 - 673ms/epoch - 2ms/step\n",
      "Epoch 621/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0018 - 689ms/epoch - 2ms/step\n",
      "Epoch 622/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0019 - 692ms/epoch - 2ms/step\n",
      "Epoch 623/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0018 - 677ms/epoch - 2ms/step\n",
      "Epoch 624/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0018 - 683ms/epoch - 2ms/step\n",
      "Epoch 625/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0018 - 713ms/epoch - 3ms/step\n",
      "Epoch 626/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0018 - 712ms/epoch - 3ms/step\n",
      "Epoch 627/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0017 - 709ms/epoch - 3ms/step\n",
      "Epoch 628/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0017 - 680ms/epoch - 2ms/step\n",
      "Epoch 629/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0017 - 674ms/epoch - 2ms/step\n",
      "Epoch 630/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0018 - 681ms/epoch - 2ms/step\n",
      "Epoch 631/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0017 - 681ms/epoch - 2ms/step\n",
      "Epoch 632/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0017 - 676ms/epoch - 2ms/step\n",
      "Epoch 633/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0017 - 677ms/epoch - 2ms/step\n",
      "Epoch 634/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0018 - 678ms/epoch - 2ms/step\n",
      "Epoch 635/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0018 - 681ms/epoch - 2ms/step\n",
      "Epoch 636/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0017 - 679ms/epoch - 2ms/step\n",
      "Epoch 637/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0018 - 680ms/epoch - 2ms/step\n",
      "Epoch 638/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0019 - 677ms/epoch - 2ms/step\n",
      "Epoch 639/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0018 - 713ms/epoch - 3ms/step\n",
      "Epoch 640/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0017 - 710ms/epoch - 3ms/step\n",
      "Epoch 641/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0017 - 673ms/epoch - 2ms/step\n",
      "Epoch 642/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0017 - 695ms/epoch - 2ms/step\n",
      "Epoch 643/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0018 - 674ms/epoch - 2ms/step\n",
      "Epoch 644/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0017 - 671ms/epoch - 2ms/step\n",
      "Epoch 645/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0017 - 702ms/epoch - 2ms/step\n",
      "Epoch 646/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0017 - 654ms/epoch - 2ms/step\n",
      "Epoch 647/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0017 - 675ms/epoch - 2ms/step\n",
      "Epoch 648/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0017 - 677ms/epoch - 2ms/step\n",
      "Epoch 649/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0017 - 675ms/epoch - 2ms/step\n",
      "Epoch 650/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0018 - 674ms/epoch - 2ms/step\n",
      "Epoch 651/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0017 - 692ms/epoch - 2ms/step\n",
      "Epoch 652/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0018 - 681ms/epoch - 2ms/step\n",
      "Epoch 653/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0018 - 671ms/epoch - 2ms/step\n",
      "Epoch 654/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0017 - 673ms/epoch - 2ms/step\n",
      "Epoch 655/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0018 - 679ms/epoch - 2ms/step\n",
      "Epoch 656/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0018 - 673ms/epoch - 2ms/step\n",
      "Epoch 657/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0018 - 676ms/epoch - 2ms/step\n",
      "Epoch 658/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0017 - 673ms/epoch - 2ms/step\n",
      "Epoch 659/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0017 - 707ms/epoch - 3ms/step\n",
      "Epoch 660/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0017 - 688ms/epoch - 2ms/step\n",
      "Epoch 661/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0017 - 681ms/epoch - 2ms/step\n",
      "Epoch 662/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0017 - 657ms/epoch - 2ms/step\n",
      "Epoch 663/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0017 - 682ms/epoch - 2ms/step\n",
      "Epoch 664/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0018 - 706ms/epoch - 3ms/step\n",
      "Epoch 665/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0018 - 676ms/epoch - 2ms/step\n",
      "Epoch 666/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0017 - 674ms/epoch - 2ms/step\n",
      "Epoch 667/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0017 - 680ms/epoch - 2ms/step\n",
      "Epoch 668/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0017 - 674ms/epoch - 2ms/step\n",
      "Epoch 669/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0017 - 674ms/epoch - 2ms/step\n",
      "Epoch 670/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0017 - 667ms/epoch - 2ms/step\n",
      "Epoch 671/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0018 - 675ms/epoch - 2ms/step\n",
      "Epoch 672/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0018 - 712ms/epoch - 3ms/step\n",
      "Epoch 673/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0018 - 707ms/epoch - 3ms/step\n",
      "Epoch 674/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0018 - 786ms/epoch - 3ms/step\n",
      "Epoch 675/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0017 - 695ms/epoch - 2ms/step\n",
      "Epoch 676/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0017 - 677ms/epoch - 2ms/step\n",
      "Epoch 677/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0017 - 654ms/epoch - 2ms/step\n",
      "Epoch 678/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0017 - 676ms/epoch - 2ms/step\n",
      "Epoch 679/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0018 - 669ms/epoch - 2ms/step\n",
      "Epoch 680/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0017 - 676ms/epoch - 2ms/step\n",
      "Epoch 681/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0017 - 683ms/epoch - 2ms/step\n",
      "Epoch 682/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0018 - 654ms/epoch - 2ms/step\n",
      "Epoch 683/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0017 - 676ms/epoch - 2ms/step\n",
      "Epoch 684/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0017 - 677ms/epoch - 2ms/step\n",
      "Epoch 685/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0018 - 670ms/epoch - 2ms/step\n",
      "Epoch 686/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0017 - 678ms/epoch - 2ms/step\n",
      "Epoch 687/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0017 - 679ms/epoch - 2ms/step\n",
      "Epoch 688/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0018 - 669ms/epoch - 2ms/step\n",
      "Epoch 689/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0017 - 680ms/epoch - 2ms/step\n",
      "Epoch 690/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0017 - 676ms/epoch - 2ms/step\n",
      "Epoch 691/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0018 - 667ms/epoch - 2ms/step\n",
      "Epoch 692/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0017 - 673ms/epoch - 2ms/step\n",
      "Epoch 693/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0017 - 670ms/epoch - 2ms/step\n",
      "Epoch 694/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0018 - 677ms/epoch - 2ms/step\n",
      "Epoch 695/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0017 - 677ms/epoch - 2ms/step\n",
      "Epoch 696/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0017 - 672ms/epoch - 2ms/step\n",
      "Epoch 697/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0018 - 675ms/epoch - 2ms/step\n",
      "Epoch 698/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0018 - 674ms/epoch - 2ms/step\n",
      "Epoch 699/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0018 - 665ms/epoch - 2ms/step\n",
      "Epoch 700/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0017 - 675ms/epoch - 2ms/step\n",
      "Epoch 701/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0017 - 704ms/epoch - 2ms/step\n",
      "Epoch 702/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0018 - 708ms/epoch - 3ms/step\n",
      "Epoch 703/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0017 - 681ms/epoch - 2ms/step\n",
      "Epoch 704/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0018 - 682ms/epoch - 2ms/step\n",
      "Epoch 705/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0018 - 669ms/epoch - 2ms/step\n",
      "Epoch 706/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0017 - 677ms/epoch - 2ms/step\n",
      "Epoch 707/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0018 - 678ms/epoch - 2ms/step\n",
      "Epoch 708/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0017 - 716ms/epoch - 3ms/step\n",
      "Epoch 709/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0019 - 739ms/epoch - 3ms/step\n",
      "Epoch 710/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0019 - 747ms/epoch - 3ms/step\n",
      "Epoch 711/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0018 - 723ms/epoch - 3ms/step\n",
      "Epoch 712/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0018 - 692ms/epoch - 2ms/step\n",
      "Epoch 713/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0018 - 717ms/epoch - 3ms/step\n",
      "Epoch 714/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0017 - 707ms/epoch - 3ms/step\n",
      "Epoch 715/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0018 - 686ms/epoch - 2ms/step\n",
      "Epoch 716/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0017 - 678ms/epoch - 2ms/step\n",
      "Epoch 717/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0017 - 674ms/epoch - 2ms/step\n",
      "Epoch 718/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0018 - 680ms/epoch - 2ms/step\n",
      "Epoch 719/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0017 - 678ms/epoch - 2ms/step\n",
      "Epoch 720/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0017 - 675ms/epoch - 2ms/step\n",
      "Epoch 721/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0017 - 679ms/epoch - 2ms/step\n",
      "Epoch 722/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0016 - 676ms/epoch - 2ms/step\n",
      "Epoch 723/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0017 - 669ms/epoch - 2ms/step\n",
      "Epoch 724/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0018 - 679ms/epoch - 2ms/step\n",
      "Epoch 725/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0019 - 678ms/epoch - 2ms/step\n",
      "Epoch 726/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0017 - 678ms/epoch - 2ms/step\n",
      "Epoch 727/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0017 - 677ms/epoch - 2ms/step\n",
      "Epoch 728/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0018 - 678ms/epoch - 2ms/step\n",
      "Epoch 729/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0018 - 669ms/epoch - 2ms/step\n",
      "Epoch 730/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0017 - 684ms/epoch - 2ms/step\n",
      "Epoch 731/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0017 - 691ms/epoch - 2ms/step\n",
      "Epoch 732/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0017 - 672ms/epoch - 2ms/step\n",
      "Epoch 733/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0017 - 682ms/epoch - 2ms/step\n",
      "Epoch 734/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0017 - 684ms/epoch - 2ms/step\n",
      "Epoch 735/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0017 - 647ms/epoch - 2ms/step\n",
      "Epoch 736/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0017 - 739ms/epoch - 3ms/step\n",
      "Epoch 737/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0019 - 671ms/epoch - 2ms/step\n",
      "Epoch 738/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0020 - 689ms/epoch - 2ms/step\n",
      "Epoch 739/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0018 - 676ms/epoch - 2ms/step\n",
      "Epoch 740/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0017 - 703ms/epoch - 2ms/step\n",
      "Epoch 741/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0018 - 655ms/epoch - 2ms/step\n",
      "Epoch 742/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0018 - 677ms/epoch - 2ms/step\n",
      "Epoch 743/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0017 - 683ms/epoch - 2ms/step\n",
      "Epoch 744/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0018 - 676ms/epoch - 2ms/step\n",
      "Epoch 745/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0018 - 678ms/epoch - 2ms/step\n",
      "Epoch 746/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0018 - 658ms/epoch - 2ms/step\n",
      "Epoch 747/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0017 - 680ms/epoch - 2ms/step\n",
      "Epoch 748/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0017 - 685ms/epoch - 2ms/step\n",
      "Epoch 749/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0018 - 669ms/epoch - 2ms/step\n",
      "Epoch 750/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0019 - 678ms/epoch - 2ms/step\n",
      "Epoch 751/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0018 - 677ms/epoch - 2ms/step\n",
      "Epoch 752/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0020 - 675ms/epoch - 2ms/step\n",
      "Epoch 753/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0017 - 677ms/epoch - 2ms/step\n",
      "Epoch 754/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0017 - 678ms/epoch - 2ms/step\n",
      "Epoch 755/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0017 - 700ms/epoch - 2ms/step\n",
      "Epoch 756/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0018 - 701ms/epoch - 2ms/step\n",
      "Epoch 757/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0017 - 705ms/epoch - 3ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 758/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0017 - 691ms/epoch - 2ms/step\n",
      "Epoch 759/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0018 - 707ms/epoch - 3ms/step\n",
      "Epoch 760/1000\n",
      "282/282 - 1s - loss: 0.0019 - val_loss: 0.0017 - 742ms/epoch - 3ms/step\n",
      "Epoch 761/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0017 - 694ms/epoch - 2ms/step\n",
      "Epoch 762/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0018 - 718ms/epoch - 3ms/step\n",
      "Epoch 763/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0018 - 697ms/epoch - 2ms/step\n",
      "Epoch 764/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0017 - 720ms/epoch - 3ms/step\n",
      "Epoch 765/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0017 - 692ms/epoch - 2ms/step\n",
      "Epoch 766/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0017 - 684ms/epoch - 2ms/step\n",
      "Epoch 767/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0018 - 678ms/epoch - 2ms/step\n",
      "Epoch 768/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0018 - 690ms/epoch - 2ms/step\n",
      "Epoch 769/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0017 - 676ms/epoch - 2ms/step\n",
      "Epoch 770/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0018 - 684ms/epoch - 2ms/step\n",
      "Epoch 771/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0018 - 682ms/epoch - 2ms/step\n",
      "Epoch 772/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0018 - 677ms/epoch - 2ms/step\n",
      "Epoch 773/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0017 - 675ms/epoch - 2ms/step\n",
      "Epoch 774/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0017 - 678ms/epoch - 2ms/step\n",
      "Epoch 775/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0017 - 706ms/epoch - 3ms/step\n",
      "Epoch 776/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0017 - 698ms/epoch - 2ms/step\n",
      "Epoch 777/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0018 - 689ms/epoch - 2ms/step\n",
      "Epoch 778/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0018 - 677ms/epoch - 2ms/step\n",
      "Epoch 779/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0017 - 673ms/epoch - 2ms/step\n",
      "Epoch 780/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0017 - 714ms/epoch - 3ms/step\n",
      "Epoch 781/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0017 - 700ms/epoch - 2ms/step\n",
      "Epoch 782/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0017 - 708ms/epoch - 3ms/step\n",
      "Epoch 783/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0017 - 678ms/epoch - 2ms/step\n",
      "Epoch 784/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0018 - 683ms/epoch - 2ms/step\n",
      "Epoch 785/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0018 - 673ms/epoch - 2ms/step\n",
      "Epoch 786/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0018 - 679ms/epoch - 2ms/step\n",
      "Epoch 787/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0018 - 699ms/epoch - 2ms/step\n",
      "Epoch 788/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0017 - 675ms/epoch - 2ms/step\n",
      "Epoch 789/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0018 - 676ms/epoch - 2ms/step\n",
      "Epoch 790/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0017 - 678ms/epoch - 2ms/step\n",
      "Epoch 791/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0018 - 671ms/epoch - 2ms/step\n",
      "Epoch 792/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0018 - 682ms/epoch - 2ms/step\n",
      "Epoch 793/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0017 - 678ms/epoch - 2ms/step\n",
      "Epoch 794/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0017 - 673ms/epoch - 2ms/step\n",
      "Epoch 795/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0017 - 683ms/epoch - 2ms/step\n",
      "Epoch 796/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0017 - 679ms/epoch - 2ms/step\n",
      "Epoch 797/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0018 - 671ms/epoch - 2ms/step\n",
      "Epoch 798/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0017 - 673ms/epoch - 2ms/step\n",
      "Epoch 799/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0017 - 683ms/epoch - 2ms/step\n",
      "Epoch 800/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0018 - 670ms/epoch - 2ms/step\n",
      "Epoch 801/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0019 - 689ms/epoch - 2ms/step\n",
      "Epoch 802/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0017 - 686ms/epoch - 2ms/step\n",
      "Epoch 803/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0016 - 670ms/epoch - 2ms/step\n",
      "Epoch 804/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0017 - 674ms/epoch - 2ms/step\n",
      "Epoch 805/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0017 - 681ms/epoch - 2ms/step\n",
      "Epoch 806/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0018 - 676ms/epoch - 2ms/step\n",
      "Epoch 807/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0017 - 677ms/epoch - 2ms/step\n",
      "Epoch 808/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0018 - 715ms/epoch - 3ms/step\n",
      "Epoch 809/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0018 - 673ms/epoch - 2ms/step\n",
      "Epoch 810/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0018 - 675ms/epoch - 2ms/step\n",
      "Epoch 811/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0019 - 675ms/epoch - 2ms/step\n",
      "Epoch 812/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0018 - 676ms/epoch - 2ms/step\n",
      "Epoch 813/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0018 - 676ms/epoch - 2ms/step\n",
      "Epoch 814/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0017 - 698ms/epoch - 2ms/step\n",
      "Epoch 815/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0017 - 710ms/epoch - 3ms/step\n",
      "Epoch 816/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0017 - 680ms/epoch - 2ms/step\n",
      "Epoch 817/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0017 - 706ms/epoch - 3ms/step\n",
      "Epoch 818/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0018 - 687ms/epoch - 2ms/step\n",
      "Epoch 819/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0017 - 680ms/epoch - 2ms/step\n",
      "Epoch 820/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0018 - 672ms/epoch - 2ms/step\n",
      "Epoch 821/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0018 - 680ms/epoch - 2ms/step\n",
      "Epoch 822/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0018 - 674ms/epoch - 2ms/step\n",
      "Epoch 823/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0017 - 667ms/epoch - 2ms/step\n",
      "Epoch 824/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0018 - 680ms/epoch - 2ms/step\n",
      "Epoch 825/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0017 - 674ms/epoch - 2ms/step\n",
      "Epoch 826/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0017 - 687ms/epoch - 2ms/step\n",
      "Epoch 827/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0017 - 685ms/epoch - 2ms/step\n",
      "Epoch 828/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0019 - 674ms/epoch - 2ms/step\n",
      "Epoch 829/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0017 - 645ms/epoch - 2ms/step\n",
      "Epoch 830/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0017 - 680ms/epoch - 2ms/step\n",
      "Epoch 831/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0019 - 682ms/epoch - 2ms/step\n",
      "Epoch 832/1000\n",
      "282/282 - 1s - loss: 0.0019 - val_loss: 0.0018 - 695ms/epoch - 2ms/step\n",
      "Epoch 833/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0017 - 720ms/epoch - 3ms/step\n",
      "Epoch 834/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0018 - 732ms/epoch - 3ms/step\n",
      "Epoch 835/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0017 - 707ms/epoch - 3ms/step\n",
      "Epoch 836/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0017 - 721ms/epoch - 3ms/step\n",
      "Epoch 837/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0017 - 723ms/epoch - 3ms/step\n",
      "Epoch 838/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0017 - 689ms/epoch - 2ms/step\n",
      "Epoch 839/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0017 - 699ms/epoch - 2ms/step\n",
      "Epoch 840/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0018 - 695ms/epoch - 2ms/step\n",
      "Epoch 841/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0017 - 698ms/epoch - 2ms/step\n",
      "Epoch 842/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0017 - 715ms/epoch - 3ms/step\n",
      "Epoch 843/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0018 - 715ms/epoch - 3ms/step\n",
      "Epoch 844/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0017 - 700ms/epoch - 2ms/step\n",
      "Epoch 845/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0017 - 696ms/epoch - 2ms/step\n",
      "Epoch 846/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0019 - 706ms/epoch - 3ms/step\n",
      "Epoch 847/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0017 - 712ms/epoch - 3ms/step\n",
      "Epoch 848/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0017 - 714ms/epoch - 3ms/step\n",
      "Epoch 849/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0017 - 715ms/epoch - 3ms/step\n",
      "Epoch 850/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0017 - 717ms/epoch - 3ms/step\n",
      "Epoch 851/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0017 - 695ms/epoch - 2ms/step\n",
      "Epoch 852/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0018 - 686ms/epoch - 2ms/step\n",
      "Epoch 853/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0017 - 676ms/epoch - 2ms/step\n",
      "Epoch 854/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0019 - 670ms/epoch - 2ms/step\n",
      "Epoch 855/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0017 - 687ms/epoch - 2ms/step\n",
      "Epoch 856/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0018 - 676ms/epoch - 2ms/step\n",
      "Epoch 857/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0017 - 685ms/epoch - 2ms/step\n",
      "Epoch 858/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0018 - 717ms/epoch - 3ms/step\n",
      "Epoch 859/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0017 - 707ms/epoch - 3ms/step\n",
      "Epoch 860/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0017 - 678ms/epoch - 2ms/step\n",
      "Epoch 861/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0018 - 677ms/epoch - 2ms/step\n",
      "Epoch 862/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0017 - 669ms/epoch - 2ms/step\n",
      "Epoch 863/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0018 - 678ms/epoch - 2ms/step\n",
      "Epoch 864/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0017 - 680ms/epoch - 2ms/step\n",
      "Epoch 865/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0017 - 670ms/epoch - 2ms/step\n",
      "Epoch 866/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0020 - 677ms/epoch - 2ms/step\n",
      "Epoch 867/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0017 - 673ms/epoch - 2ms/step\n",
      "Epoch 868/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0017 - 672ms/epoch - 2ms/step\n",
      "Epoch 869/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0017 - 680ms/epoch - 2ms/step\n",
      "Epoch 870/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0018 - 677ms/epoch - 2ms/step\n",
      "Epoch 871/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0018 - 670ms/epoch - 2ms/step\n",
      "Epoch 872/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0018 - 684ms/epoch - 2ms/step\n",
      "Epoch 873/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0017 - 674ms/epoch - 2ms/step\n",
      "Epoch 874/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0017 - 672ms/epoch - 2ms/step\n",
      "Epoch 875/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0017 - 679ms/epoch - 2ms/step\n",
      "Epoch 876/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0019 - 677ms/epoch - 2ms/step\n",
      "Epoch 877/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0018 - 670ms/epoch - 2ms/step\n",
      "Epoch 878/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0019 - 680ms/epoch - 2ms/step\n",
      "Epoch 879/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0017 - 680ms/epoch - 2ms/step\n",
      "Epoch 880/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0017 - 671ms/epoch - 2ms/step\n",
      "Epoch 881/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0018 - 675ms/epoch - 2ms/step\n",
      "Epoch 882/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0019 - 678ms/epoch - 2ms/step\n",
      "Epoch 883/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0018 - 677ms/epoch - 2ms/step\n",
      "Epoch 884/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0017 - 674ms/epoch - 2ms/step\n",
      "Epoch 885/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0017 - 672ms/epoch - 2ms/step\n",
      "Epoch 886/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0017 - 680ms/epoch - 2ms/step\n",
      "Epoch 887/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0017 - 679ms/epoch - 2ms/step\n",
      "Epoch 888/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0018 - 675ms/epoch - 2ms/step\n",
      "Epoch 889/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0017 - 661ms/epoch - 2ms/step\n",
      "Epoch 890/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0017 - 679ms/epoch - 2ms/step\n",
      "Epoch 891/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0017 - 674ms/epoch - 2ms/step\n",
      "Epoch 892/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0019 - 718ms/epoch - 3ms/step\n",
      "Epoch 893/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0017 - 783ms/epoch - 3ms/step\n",
      "Epoch 894/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0017 - 799ms/epoch - 3ms/step\n",
      "Epoch 895/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0017 - 711ms/epoch - 3ms/step\n",
      "Epoch 896/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0018 - 693ms/epoch - 2ms/step\n",
      "Epoch 897/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0018 - 701ms/epoch - 2ms/step\n",
      "Epoch 898/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0018 - 686ms/epoch - 2ms/step\n",
      "Epoch 899/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0016 - 705ms/epoch - 2ms/step\n",
      "Epoch 900/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0018 - 702ms/epoch - 2ms/step\n",
      "Epoch 901/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0018 - 678ms/epoch - 2ms/step\n",
      "Epoch 902/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0017 - 685ms/epoch - 2ms/step\n",
      "Epoch 903/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0017 - 717ms/epoch - 3ms/step\n",
      "Epoch 904/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0017 - 705ms/epoch - 2ms/step\n",
      "Epoch 905/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0017 - 675ms/epoch - 2ms/step\n",
      "Epoch 906/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0020 - 679ms/epoch - 2ms/step\n",
      "Epoch 907/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0017 - 672ms/epoch - 2ms/step\n",
      "Epoch 908/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0017 - 762ms/epoch - 3ms/step\n",
      "Epoch 909/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0017 - 730ms/epoch - 3ms/step\n",
      "Epoch 910/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0017 - 773ms/epoch - 3ms/step\n",
      "Epoch 911/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0017 - 768ms/epoch - 3ms/step\n",
      "Epoch 912/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0018 - 698ms/epoch - 2ms/step\n",
      "Epoch 913/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0017 - 691ms/epoch - 2ms/step\n",
      "Epoch 914/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0017 - 672ms/epoch - 2ms/step\n",
      "Epoch 915/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0017 - 687ms/epoch - 2ms/step\n",
      "Epoch 916/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0018 - 676ms/epoch - 2ms/step\n",
      "Epoch 917/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0017 - 672ms/epoch - 2ms/step\n",
      "Epoch 918/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0018 - 689ms/epoch - 2ms/step\n",
      "Epoch 919/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0018 - 672ms/epoch - 2ms/step\n",
      "Epoch 920/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0017 - 682ms/epoch - 2ms/step\n",
      "Epoch 921/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0018 - 676ms/epoch - 2ms/step\n",
      "Epoch 922/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0017 - 670ms/epoch - 2ms/step\n",
      "Epoch 923/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0017 - 667ms/epoch - 2ms/step\n",
      "Epoch 924/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0020 - 675ms/epoch - 2ms/step\n",
      "Epoch 925/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0016 - 673ms/epoch - 2ms/step\n",
      "Epoch 926/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0017 - 678ms/epoch - 2ms/step\n",
      "Epoch 927/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0018 - 681ms/epoch - 2ms/step\n",
      "Epoch 928/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0017 - 673ms/epoch - 2ms/step\n",
      "Epoch 929/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0018 - 677ms/epoch - 2ms/step\n",
      "Epoch 930/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0018 - 683ms/epoch - 2ms/step\n",
      "Epoch 931/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0016 - 671ms/epoch - 2ms/step\n",
      "Epoch 932/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0018 - 676ms/epoch - 2ms/step\n",
      "Epoch 933/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0019 - 683ms/epoch - 2ms/step\n",
      "Epoch 934/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0017 - 671ms/epoch - 2ms/step\n",
      "Epoch 935/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0017 - 683ms/epoch - 2ms/step\n",
      "Epoch 936/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0018 - 685ms/epoch - 2ms/step\n",
      "Epoch 937/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0019 - 680ms/epoch - 2ms/step\n",
      "Epoch 938/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0017 - 678ms/epoch - 2ms/step\n",
      "Epoch 939/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0018 - 675ms/epoch - 2ms/step\n",
      "Epoch 940/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0018 - 669ms/epoch - 2ms/step\n",
      "Epoch 941/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0017 - 685ms/epoch - 2ms/step\n",
      "Epoch 942/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0017 - 726ms/epoch - 3ms/step\n",
      "Epoch 943/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0017 - 779ms/epoch - 3ms/step\n",
      "Epoch 944/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0019 - 716ms/epoch - 3ms/step\n",
      "Epoch 945/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0017 - 694ms/epoch - 2ms/step\n",
      "Epoch 946/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0017 - 686ms/epoch - 2ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 947/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0018 - 698ms/epoch - 2ms/step\n",
      "Epoch 948/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0017 - 702ms/epoch - 2ms/step\n",
      "Epoch 949/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0017 - 707ms/epoch - 3ms/step\n",
      "Epoch 950/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0017 - 706ms/epoch - 3ms/step\n",
      "Epoch 951/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0018 - 693ms/epoch - 2ms/step\n",
      "Epoch 952/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0018 - 693ms/epoch - 2ms/step\n",
      "Epoch 953/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0017 - 709ms/epoch - 3ms/step\n",
      "Epoch 954/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0018 - 727ms/epoch - 3ms/step\n",
      "Epoch 955/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0017 - 731ms/epoch - 3ms/step\n",
      "Epoch 956/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0018 - 685ms/epoch - 2ms/step\n",
      "Epoch 957/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0017 - 721ms/epoch - 3ms/step\n",
      "Epoch 958/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0018 - 689ms/epoch - 2ms/step\n",
      "Epoch 959/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0019 - 737ms/epoch - 3ms/step\n",
      "Epoch 960/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0017 - 711ms/epoch - 3ms/step\n",
      "Epoch 961/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0017 - 680ms/epoch - 2ms/step\n",
      "Epoch 962/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0018 - 677ms/epoch - 2ms/step\n",
      "Epoch 963/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0017 - 677ms/epoch - 2ms/step\n",
      "Epoch 964/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0018 - 672ms/epoch - 2ms/step\n",
      "Epoch 965/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0017 - 680ms/epoch - 2ms/step\n",
      "Epoch 966/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0017 - 712ms/epoch - 3ms/step\n",
      "Epoch 967/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0019 - 677ms/epoch - 2ms/step\n",
      "Epoch 968/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0017 - 684ms/epoch - 2ms/step\n",
      "Epoch 969/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0018 - 692ms/epoch - 2ms/step\n",
      "Epoch 970/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0017 - 672ms/epoch - 2ms/step\n",
      "Epoch 971/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0018 - 682ms/epoch - 2ms/step\n",
      "Epoch 972/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0017 - 677ms/epoch - 2ms/step\n",
      "Epoch 973/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0017 - 678ms/epoch - 2ms/step\n",
      "Epoch 974/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0018 - 679ms/epoch - 2ms/step\n",
      "Epoch 975/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0017 - 711ms/epoch - 3ms/step\n",
      "Epoch 976/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0018 - 675ms/epoch - 2ms/step\n",
      "Epoch 977/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0018 - 686ms/epoch - 2ms/step\n",
      "Epoch 978/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0017 - 681ms/epoch - 2ms/step\n",
      "Epoch 979/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0017 - 675ms/epoch - 2ms/step\n",
      "Epoch 980/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0018 - 687ms/epoch - 2ms/step\n",
      "Epoch 981/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0017 - 697ms/epoch - 2ms/step\n",
      "Epoch 982/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0018 - 672ms/epoch - 2ms/step\n",
      "Epoch 983/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0018 - 674ms/epoch - 2ms/step\n",
      "Epoch 984/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0018 - 685ms/epoch - 2ms/step\n",
      "Epoch 985/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0017 - 674ms/epoch - 2ms/step\n",
      "Epoch 986/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0017 - 692ms/epoch - 2ms/step\n",
      "Epoch 987/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0017 - 714ms/epoch - 3ms/step\n",
      "Epoch 988/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0017 - 739ms/epoch - 3ms/step\n",
      "Epoch 989/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0018 - 654ms/epoch - 2ms/step\n",
      "Epoch 990/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0017 - 695ms/epoch - 2ms/step\n",
      "Epoch 991/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0018 - 670ms/epoch - 2ms/step\n",
      "Epoch 992/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0018 - 675ms/epoch - 2ms/step\n",
      "Epoch 993/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0018 - 681ms/epoch - 2ms/step\n",
      "Epoch 994/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0017 - 671ms/epoch - 2ms/step\n",
      "Epoch 995/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0018 - 678ms/epoch - 2ms/step\n",
      "Epoch 996/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0017 - 682ms/epoch - 2ms/step\n",
      "Epoch 997/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0018 - 742ms/epoch - 3ms/step\n",
      "Epoch 998/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0018 - 760ms/epoch - 3ms/step\n",
      "Epoch 999/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0018 - 747ms/epoch - 3ms/step\n",
      "Epoch 1000/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0017 - 675ms/epoch - 2ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f28a060e9a0>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##Create and train the neural network\n",
    "from keras import callbacks, optimizers\n",
    "from keras.layers import (LSTM, BatchNormalization, Dense, Dropout, Flatten,\n",
    "                          TimeDistributed)\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
    "from keras.models import Sequential, load_model, model_from_json\n",
    "from IPython.display import clear_output\n",
    "from matplotlib import pyplot as plt\n",
    "model = Sequential()\n",
    "model.add(Conv2D(filters=10, kernel_size=1, activation='relu', input_shape=(8,8,12)))\n",
    "model.add(MaxPooling2D(pool_size=2, strides=None))\n",
    "model.add(Flatten())\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(1,activation = 'sigmoid'))\n",
    "model.compile(optimizer = 'Adam',loss='mse')\n",
    "h5 = 'chess' + '_best_model' + '.h5'\n",
    "checkpoint = callbacks.ModelCheckpoint(h5,\n",
    "                                           monitor='val_loss',\n",
    "                                           verbose=0,\n",
    "                                           save_best_only=True,\n",
    "                                           save_weights_only=True,\n",
    "                                           mode='auto',\n",
    "                                           period=1)\n",
    "es = callbacks.EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=5000/10)\n",
    "callback = [checkpoint,es]\n",
    "json = 'chess' + '_best_model' + '.json'\n",
    "model_json = model.to_json()\n",
    "with open(json, \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "print('Training Network...')\n",
    "test = 1000\n",
    "X = np.array(X)\n",
    "X_train = X[test:]\n",
    "y_train = y[test:]\n",
    "X_test = X[:test]\n",
    "y_test = y[:test]\n",
    "model.fit(X_train,y_train,epochs = 1000,verbose = 2,validation_data = (X_test,y_test),callbacks = callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "00c51271",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-17 07:04:07.727195: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-12-17 07:04:43.825567: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-12-17 07:04:43.825676: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2022-12-17 07:04:44.565897: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2022-12-17 07:05:14.862312: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2022-12-17 07:05:14.863567: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2022-12-17 07:05:14.863659: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "2022-12-17 07:05:55.490103: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2022-12-17 07:05:55.549583: W tensorflow/stream_executor/cuda/cuda_driver.cc:263] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-12-17 07:05:55.549742: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (LAPTOP-DBN1AV7C): /proc/driver/nvidia/version does not exist\n",
      "2022-12-17 07:05:55.805996: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Training Network...\n",
      "Epoch 1/1000\n",
      "282/282 - 6s - loss: 0.0195 - val_loss: 0.0047 - 6s/epoch - 20ms/step\n",
      "Epoch 2/1000\n",
      "282/282 - 1s - loss: 0.0040 - val_loss: 0.0039 - 768ms/epoch - 3ms/step\n",
      "Epoch 3/1000\n",
      "282/282 - 1s - loss: 0.0029 - val_loss: 0.0031 - 822ms/epoch - 3ms/step\n",
      "Epoch 4/1000\n",
      "282/282 - 1s - loss: 0.0026 - val_loss: 0.0028 - 828ms/epoch - 3ms/step\n",
      "Epoch 5/1000\n",
      "282/282 - 1s - loss: 0.0025 - val_loss: 0.0026 - 812ms/epoch - 3ms/step\n",
      "Epoch 6/1000\n",
      "282/282 - 1s - loss: 0.0023 - val_loss: 0.0024 - 681ms/epoch - 2ms/step\n",
      "Epoch 7/1000\n",
      "282/282 - 1s - loss: 0.0023 - val_loss: 0.0021 - 747ms/epoch - 3ms/step\n",
      "Epoch 8/1000\n",
      "282/282 - 1s - loss: 0.0023 - val_loss: 0.0023 - 734ms/epoch - 3ms/step\n",
      "Epoch 9/1000\n",
      "282/282 - 1s - loss: 0.0023 - val_loss: 0.0026 - 732ms/epoch - 3ms/step\n",
      "Epoch 10/1000\n",
      "282/282 - 1s - loss: 0.0023 - val_loss: 0.0024 - 648ms/epoch - 2ms/step\n",
      "Epoch 11/1000\n",
      "282/282 - 1s - loss: 0.0022 - val_loss: 0.0025 - 739ms/epoch - 3ms/step\n",
      "Epoch 12/1000\n",
      "282/282 - 1s - loss: 0.0023 - val_loss: 0.0026 - 674ms/epoch - 2ms/step\n",
      "Epoch 13/1000\n",
      "282/282 - 1s - loss: 0.0022 - val_loss: 0.0025 - 659ms/epoch - 2ms/step\n",
      "Epoch 14/1000\n",
      "282/282 - 1s - loss: 0.0022 - val_loss: 0.0025 - 740ms/epoch - 3ms/step\n",
      "Epoch 15/1000\n",
      "282/282 - 1s - loss: 0.0022 - val_loss: 0.0025 - 703ms/epoch - 2ms/step\n",
      "Epoch 16/1000\n",
      "282/282 - 1s - loss: 0.0022 - val_loss: 0.0022 - 743ms/epoch - 3ms/step\n",
      "Epoch 17/1000\n",
      "282/282 - 1s - loss: 0.0022 - val_loss: 0.0027 - 709ms/epoch - 3ms/step\n",
      "Epoch 18/1000\n",
      "282/282 - 1s - loss: 0.0022 - val_loss: 0.0024 - 702ms/epoch - 2ms/step\n",
      "Epoch 19/1000\n",
      "282/282 - 1s - loss: 0.0022 - val_loss: 0.0026 - 721ms/epoch - 3ms/step\n",
      "Epoch 20/1000\n",
      "282/282 - 1s - loss: 0.0022 - val_loss: 0.0025 - 706ms/epoch - 3ms/step\n",
      "Epoch 21/1000\n",
      "282/282 - 1s - loss: 0.0022 - val_loss: 0.0025 - 702ms/epoch - 2ms/step\n",
      "Epoch 22/1000\n",
      "282/282 - 1s - loss: 0.0022 - val_loss: 0.0025 - 676ms/epoch - 2ms/step\n",
      "Epoch 23/1000\n",
      "282/282 - 1s - loss: 0.0022 - val_loss: 0.0025 - 701ms/epoch - 2ms/step\n",
      "Epoch 24/1000\n",
      "282/282 - 1s - loss: 0.0022 - val_loss: 0.0023 - 773ms/epoch - 3ms/step\n",
      "Epoch 25/1000\n",
      "282/282 - 1s - loss: 0.0022 - val_loss: 0.0021 - 772ms/epoch - 3ms/step\n",
      "Epoch 26/1000\n",
      "282/282 - 1s - loss: 0.0022 - val_loss: 0.0023 - 687ms/epoch - 2ms/step\n",
      "Epoch 27/1000\n",
      "282/282 - 1s - loss: 0.0022 - val_loss: 0.0026 - 700ms/epoch - 2ms/step\n",
      "Epoch 28/1000\n",
      "282/282 - 1s - loss: 0.0022 - val_loss: 0.0025 - 687ms/epoch - 2ms/step\n",
      "Epoch 29/1000\n",
      "282/282 - 1s - loss: 0.0022 - val_loss: 0.0025 - 697ms/epoch - 2ms/step\n",
      "Epoch 30/1000\n",
      "282/282 - 1s - loss: 0.0021 - val_loss: 0.0025 - 706ms/epoch - 3ms/step\n",
      "Epoch 31/1000\n",
      "282/282 - 1s - loss: 0.0021 - val_loss: 0.0024 - 742ms/epoch - 3ms/step\n",
      "Epoch 32/1000\n",
      "282/282 - 1s - loss: 0.0021 - val_loss: 0.0025 - 714ms/epoch - 3ms/step\n",
      "Epoch 33/1000\n",
      "282/282 - 1s - loss: 0.0021 - val_loss: 0.0024 - 705ms/epoch - 2ms/step\n",
      "Epoch 34/1000\n",
      "282/282 - 1s - loss: 0.0021 - val_loss: 0.0025 - 713ms/epoch - 3ms/step\n",
      "Epoch 35/1000\n",
      "282/282 - 1s - loss: 0.0021 - val_loss: 0.0024 - 710ms/epoch - 3ms/step\n",
      "Epoch 36/1000\n",
      "282/282 - 1s - loss: 0.0021 - val_loss: 0.0023 - 693ms/epoch - 2ms/step\n",
      "Epoch 37/1000\n",
      "282/282 - 1s - loss: 0.0021 - val_loss: 0.0026 - 676ms/epoch - 2ms/step\n",
      "Epoch 38/1000\n",
      "282/282 - 1s - loss: 0.0021 - val_loss: 0.0021 - 671ms/epoch - 2ms/step\n",
      "Epoch 39/1000\n",
      "282/282 - 1s - loss: 0.0021 - val_loss: 0.0024 - 705ms/epoch - 2ms/step\n",
      "Epoch 40/1000\n",
      "282/282 - 1s - loss: 0.0021 - val_loss: 0.0024 - 652ms/epoch - 2ms/step\n",
      "Epoch 41/1000\n",
      "282/282 - 1s - loss: 0.0021 - val_loss: 0.0024 - 697ms/epoch - 2ms/step\n",
      "Epoch 42/1000\n",
      "282/282 - 1s - loss: 0.0021 - val_loss: 0.0019 - 750ms/epoch - 3ms/step\n",
      "Epoch 43/1000\n",
      "282/282 - 1s - loss: 0.0021 - val_loss: 0.0023 - 694ms/epoch - 2ms/step\n",
      "Epoch 44/1000\n",
      "282/282 - 1s - loss: 0.0021 - val_loss: 0.0023 - 711ms/epoch - 3ms/step\n",
      "Epoch 45/1000\n",
      "282/282 - 1s - loss: 0.0021 - val_loss: 0.0023 - 674ms/epoch - 2ms/step\n",
      "Epoch 46/1000\n",
      "282/282 - 1s - loss: 0.0021 - val_loss: 0.0025 - 671ms/epoch - 2ms/step\n",
      "Epoch 47/1000\n",
      "282/282 - 1s - loss: 0.0021 - val_loss: 0.0022 - 675ms/epoch - 2ms/step\n",
      "Epoch 48/1000\n",
      "282/282 - 1s - loss: 0.0021 - val_loss: 0.0024 - 681ms/epoch - 2ms/step\n",
      "Epoch 49/1000\n",
      "282/282 - 1s - loss: 0.0021 - val_loss: 0.0022 - 673ms/epoch - 2ms/step\n",
      "Epoch 50/1000\n",
      "282/282 - 1s - loss: 0.0021 - val_loss: 0.0027 - 682ms/epoch - 2ms/step\n",
      "Epoch 51/1000\n",
      "282/282 - 1s - loss: 0.0021 - val_loss: 0.0022 - 717ms/epoch - 3ms/step\n",
      "Epoch 52/1000\n",
      "282/282 - 1s - loss: 0.0021 - val_loss: 0.0024 - 692ms/epoch - 2ms/step\n",
      "Epoch 53/1000\n",
      "282/282 - 1s - loss: 0.0021 - val_loss: 0.0021 - 685ms/epoch - 2ms/step\n",
      "Epoch 54/1000\n",
      "282/282 - 1s - loss: 0.0021 - val_loss: 0.0024 - 679ms/epoch - 2ms/step\n",
      "Epoch 55/1000\n",
      "282/282 - 1s - loss: 0.0021 - val_loss: 0.0024 - 698ms/epoch - 2ms/step\n",
      "Epoch 56/1000\n",
      "282/282 - 1s - loss: 0.0021 - val_loss: 0.0022 - 678ms/epoch - 2ms/step\n",
      "Epoch 57/1000\n",
      "282/282 - 1s - loss: 0.0021 - val_loss: 0.0023 - 693ms/epoch - 2ms/step\n",
      "Epoch 58/1000\n",
      "282/282 - 1s - loss: 0.0021 - val_loss: 0.0024 - 671ms/epoch - 2ms/step\n",
      "Epoch 59/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0021 - 667ms/epoch - 2ms/step\n",
      "Epoch 60/1000\n",
      "282/282 - 1s - loss: 0.0021 - val_loss: 0.0028 - 712ms/epoch - 3ms/step\n",
      "Epoch 61/1000\n",
      "282/282 - 1s - loss: 0.0021 - val_loss: 0.0023 - 658ms/epoch - 2ms/step\n",
      "Epoch 62/1000\n",
      "282/282 - 1s - loss: 0.0021 - val_loss: 0.0023 - 842ms/epoch - 3ms/step\n",
      "Epoch 63/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0022 - 662ms/epoch - 2ms/step\n",
      "Epoch 64/1000\n",
      "282/282 - 1s - loss: 0.0021 - val_loss: 0.0024 - 668ms/epoch - 2ms/step\n",
      "Epoch 65/1000\n",
      "282/282 - 1s - loss: 0.0021 - val_loss: 0.0022 - 685ms/epoch - 2ms/step\n",
      "Epoch 66/1000\n",
      "282/282 - 1s - loss: 0.0021 - val_loss: 0.0023 - 696ms/epoch - 2ms/step\n",
      "Epoch 67/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0023 - 685ms/epoch - 2ms/step\n",
      "Epoch 68/1000\n",
      "282/282 - 1s - loss: 0.0021 - val_loss: 0.0024 - 680ms/epoch - 2ms/step\n",
      "Epoch 69/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0025 - 690ms/epoch - 2ms/step\n",
      "Epoch 70/1000\n",
      "282/282 - 1s - loss: 0.0021 - val_loss: 0.0024 - 676ms/epoch - 2ms/step\n",
      "Epoch 71/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0023 - 678ms/epoch - 2ms/step\n",
      "Epoch 72/1000\n",
      "282/282 - 1s - loss: 0.0021 - val_loss: 0.0021 - 684ms/epoch - 2ms/step\n",
      "Epoch 73/1000\n",
      "282/282 - 1s - loss: 0.0021 - val_loss: 0.0021 - 698ms/epoch - 2ms/step\n",
      "Epoch 74/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0023 - 676ms/epoch - 2ms/step\n",
      "Epoch 75/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0021 - 725ms/epoch - 3ms/step\n",
      "Epoch 76/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0024 - 685ms/epoch - 2ms/step\n",
      "Epoch 77/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0025 - 684ms/epoch - 2ms/step\n",
      "Epoch 78/1000\n",
      "282/282 - 1s - loss: 0.0021 - val_loss: 0.0023 - 714ms/epoch - 3ms/step\n",
      "Epoch 79/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0024 - 696ms/epoch - 2ms/step\n",
      "Epoch 80/1000\n",
      "282/282 - 1s - loss: 0.0021 - val_loss: 0.0025 - 703ms/epoch - 2ms/step\n",
      "Epoch 81/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0027 - 670ms/epoch - 2ms/step\n",
      "Epoch 82/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0023 - 675ms/epoch - 2ms/step\n",
      "Epoch 83/1000\n",
      "282/282 - 1s - loss: 0.0021 - val_loss: 0.0023 - 686ms/epoch - 2ms/step\n",
      "Epoch 84/1000\n",
      "282/282 - 1s - loss: 0.0021 - val_loss: 0.0024 - 695ms/epoch - 2ms/step\n",
      "Epoch 85/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0024 - 674ms/epoch - 2ms/step\n",
      "Epoch 86/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0026 - 684ms/epoch - 2ms/step\n",
      "Epoch 87/1000\n",
      "282/282 - 1s - loss: 0.0021 - val_loss: 0.0024 - 704ms/epoch - 2ms/step\n",
      "Epoch 88/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0021 - 681ms/epoch - 2ms/step\n",
      "Epoch 89/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0025 - 712ms/epoch - 3ms/step\n",
      "Epoch 90/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0024 - 707ms/epoch - 3ms/step\n",
      "Epoch 91/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0023 - 702ms/epoch - 2ms/step\n",
      "Epoch 92/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0023 - 677ms/epoch - 2ms/step\n",
      "Epoch 93/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0025 - 666ms/epoch - 2ms/step\n",
      "Epoch 94/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0024 - 664ms/epoch - 2ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 95/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0024 - 704ms/epoch - 2ms/step\n",
      "Epoch 96/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0023 - 694ms/epoch - 2ms/step\n",
      "Epoch 97/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0024 - 681ms/epoch - 2ms/step\n",
      "Epoch 98/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0024 - 700ms/epoch - 2ms/step\n",
      "Epoch 99/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0025 - 701ms/epoch - 2ms/step\n",
      "Epoch 100/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0024 - 697ms/epoch - 2ms/step\n",
      "Epoch 101/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0023 - 763ms/epoch - 3ms/step\n",
      "Epoch 102/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0024 - 715ms/epoch - 3ms/step\n",
      "Epoch 103/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0022 - 755ms/epoch - 3ms/step\n",
      "Epoch 104/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0024 - 704ms/epoch - 2ms/step\n",
      "Epoch 105/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0024 - 762ms/epoch - 3ms/step\n",
      "Epoch 106/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0024 - 755ms/epoch - 3ms/step\n",
      "Epoch 107/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0025 - 702ms/epoch - 2ms/step\n",
      "Epoch 108/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0022 - 747ms/epoch - 3ms/step\n",
      "Epoch 109/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0023 - 750ms/epoch - 3ms/step\n",
      "Epoch 110/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0024 - 761ms/epoch - 3ms/step\n",
      "Epoch 111/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0023 - 715ms/epoch - 3ms/step\n",
      "Epoch 112/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0024 - 726ms/epoch - 3ms/step\n",
      "Epoch 113/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0022 - 722ms/epoch - 3ms/step\n",
      "Epoch 114/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0022 - 769ms/epoch - 3ms/step\n",
      "Epoch 115/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0024 - 729ms/epoch - 3ms/step\n",
      "Epoch 116/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0022 - 747ms/epoch - 3ms/step\n",
      "Epoch 117/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0025 - 748ms/epoch - 3ms/step\n",
      "Epoch 118/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0025 - 686ms/epoch - 2ms/step\n",
      "Epoch 119/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0024 - 705ms/epoch - 3ms/step\n",
      "Epoch 120/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0022 - 680ms/epoch - 2ms/step\n",
      "Epoch 121/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0024 - 720ms/epoch - 3ms/step\n",
      "Epoch 122/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0025 - 743ms/epoch - 3ms/step\n",
      "Epoch 123/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0026 - 722ms/epoch - 3ms/step\n",
      "Epoch 124/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0022 - 676ms/epoch - 2ms/step\n",
      "Epoch 125/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0024 - 712ms/epoch - 3ms/step\n",
      "Epoch 126/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0023 - 698ms/epoch - 2ms/step\n",
      "Epoch 127/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0024 - 697ms/epoch - 2ms/step\n",
      "Epoch 128/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0023 - 740ms/epoch - 3ms/step\n",
      "Epoch 129/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0024 - 682ms/epoch - 2ms/step\n",
      "Epoch 130/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0024 - 700ms/epoch - 2ms/step\n",
      "Epoch 131/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0025 - 753ms/epoch - 3ms/step\n",
      "Epoch 132/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0023 - 708ms/epoch - 3ms/step\n",
      "Epoch 133/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0022 - 670ms/epoch - 2ms/step\n",
      "Epoch 134/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0025 - 676ms/epoch - 2ms/step\n",
      "Epoch 135/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0023 - 670ms/epoch - 2ms/step\n",
      "Epoch 136/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0021 - 675ms/epoch - 2ms/step\n",
      "Epoch 137/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0023 - 678ms/epoch - 2ms/step\n",
      "Epoch 138/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0024 - 686ms/epoch - 2ms/step\n",
      "Epoch 139/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0023 - 701ms/epoch - 2ms/step\n",
      "Epoch 140/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0023 - 679ms/epoch - 2ms/step\n",
      "Epoch 141/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0022 - 666ms/epoch - 2ms/step\n",
      "Epoch 142/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0022 - 669ms/epoch - 2ms/step\n",
      "Epoch 143/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0025 - 707ms/epoch - 3ms/step\n",
      "Epoch 144/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0026 - 751ms/epoch - 3ms/step\n",
      "Epoch 145/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0022 - 781ms/epoch - 3ms/step\n",
      "Epoch 146/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0023 - 720ms/epoch - 3ms/step\n",
      "Epoch 147/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0024 - 650ms/epoch - 2ms/step\n",
      "Epoch 148/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0025 - 652ms/epoch - 2ms/step\n",
      "Epoch 149/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0022 - 669ms/epoch - 2ms/step\n",
      "Epoch 150/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0023 - 689ms/epoch - 2ms/step\n",
      "Epoch 151/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0023 - 725ms/epoch - 3ms/step\n",
      "Epoch 152/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0027 - 722ms/epoch - 3ms/step\n",
      "Epoch 153/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0025 - 720ms/epoch - 3ms/step\n",
      "Epoch 154/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0024 - 682ms/epoch - 2ms/step\n",
      "Epoch 155/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0027 - 697ms/epoch - 2ms/step\n",
      "Epoch 156/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0024 - 708ms/epoch - 3ms/step\n",
      "Epoch 157/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0024 - 652ms/epoch - 2ms/step\n",
      "Epoch 158/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0024 - 647ms/epoch - 2ms/step\n",
      "Epoch 159/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0022 - 665ms/epoch - 2ms/step\n",
      "Epoch 160/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0024 - 673ms/epoch - 2ms/step\n",
      "Epoch 161/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0024 - 673ms/epoch - 2ms/step\n",
      "Epoch 162/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0026 - 663ms/epoch - 2ms/step\n",
      "Epoch 163/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0023 - 659ms/epoch - 2ms/step\n",
      "Epoch 164/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0026 - 669ms/epoch - 2ms/step\n",
      "Epoch 165/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0025 - 663ms/epoch - 2ms/step\n",
      "Epoch 166/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0025 - 667ms/epoch - 2ms/step\n",
      "Epoch 167/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0025 - 667ms/epoch - 2ms/step\n",
      "Epoch 168/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0022 - 692ms/epoch - 2ms/step\n",
      "Epoch 169/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0024 - 685ms/epoch - 2ms/step\n",
      "Epoch 170/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0023 - 674ms/epoch - 2ms/step\n",
      "Epoch 171/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0022 - 646ms/epoch - 2ms/step\n",
      "Epoch 172/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0024 - 671ms/epoch - 2ms/step\n",
      "Epoch 173/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0025 - 667ms/epoch - 2ms/step\n",
      "Epoch 174/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0023 - 667ms/epoch - 2ms/step\n",
      "Epoch 175/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0025 - 694ms/epoch - 2ms/step\n",
      "Epoch 176/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0026 - 702ms/epoch - 2ms/step\n",
      "Epoch 177/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0025 - 699ms/epoch - 2ms/step\n",
      "Epoch 178/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0023 - 685ms/epoch - 2ms/step\n",
      "Epoch 179/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0027 - 667ms/epoch - 2ms/step\n",
      "Epoch 180/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0025 - 667ms/epoch - 2ms/step\n",
      "Epoch 181/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0022 - 675ms/epoch - 2ms/step\n",
      "Epoch 182/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0023 - 671ms/epoch - 2ms/step\n",
      "Epoch 183/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0022 - 677ms/epoch - 2ms/step\n",
      "Epoch 184/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0024 - 668ms/epoch - 2ms/step\n",
      "Epoch 185/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0027 - 767ms/epoch - 3ms/step\n",
      "Epoch 186/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0023 - 781ms/epoch - 3ms/step\n",
      "Epoch 187/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0025 - 745ms/epoch - 3ms/step\n",
      "Epoch 188/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0023 - 665ms/epoch - 2ms/step\n",
      "Epoch 189/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0025 - 659ms/epoch - 2ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 190/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0026 - 668ms/epoch - 2ms/step\n",
      "Epoch 191/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0025 - 663ms/epoch - 2ms/step\n",
      "Epoch 192/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0024 - 670ms/epoch - 2ms/step\n",
      "Epoch 193/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0023 - 670ms/epoch - 2ms/step\n",
      "Epoch 194/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0026 - 692ms/epoch - 2ms/step\n",
      "Epoch 195/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0024 - 696ms/epoch - 2ms/step\n",
      "Epoch 196/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0024 - 708ms/epoch - 3ms/step\n",
      "Epoch 197/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0022 - 662ms/epoch - 2ms/step\n",
      "Epoch 198/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0025 - 665ms/epoch - 2ms/step\n",
      "Epoch 199/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0022 - 668ms/epoch - 2ms/step\n",
      "Epoch 200/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0025 - 662ms/epoch - 2ms/step\n",
      "Epoch 201/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0025 - 670ms/epoch - 2ms/step\n",
      "Epoch 202/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0022 - 666ms/epoch - 2ms/step\n",
      "Epoch 203/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0024 - 656ms/epoch - 2ms/step\n",
      "Epoch 204/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0025 - 669ms/epoch - 2ms/step\n",
      "Epoch 205/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0023 - 669ms/epoch - 2ms/step\n",
      "Epoch 206/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0023 - 664ms/epoch - 2ms/step\n",
      "Epoch 207/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0024 - 676ms/epoch - 2ms/step\n",
      "Epoch 208/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0026 - 660ms/epoch - 2ms/step\n",
      "Epoch 209/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0024 - 663ms/epoch - 2ms/step\n",
      "Epoch 210/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0027 - 668ms/epoch - 2ms/step\n",
      "Epoch 211/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0026 - 668ms/epoch - 2ms/step\n",
      "Epoch 212/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0024 - 698ms/epoch - 2ms/step\n",
      "Epoch 213/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0023 - 721ms/epoch - 3ms/step\n",
      "Epoch 214/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0024 - 647ms/epoch - 2ms/step\n",
      "Epoch 215/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0023 - 687ms/epoch - 2ms/step\n",
      "Epoch 216/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0026 - 670ms/epoch - 2ms/step\n",
      "Epoch 217/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0026 - 666ms/epoch - 2ms/step\n",
      "Epoch 218/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0024 - 668ms/epoch - 2ms/step\n",
      "Epoch 219/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0022 - 666ms/epoch - 2ms/step\n",
      "Epoch 220/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0026 - 666ms/epoch - 2ms/step\n",
      "Epoch 221/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0023 - 678ms/epoch - 2ms/step\n",
      "Epoch 222/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0025 - 674ms/epoch - 2ms/step\n",
      "Epoch 223/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0024 - 661ms/epoch - 2ms/step\n",
      "Epoch 224/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0023 - 665ms/epoch - 2ms/step\n",
      "Epoch 225/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0025 - 667ms/epoch - 2ms/step\n",
      "Epoch 226/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0023 - 665ms/epoch - 2ms/step\n",
      "Epoch 227/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0024 - 663ms/epoch - 2ms/step\n",
      "Epoch 228/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0026 - 675ms/epoch - 2ms/step\n",
      "Epoch 229/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0026 - 705ms/epoch - 2ms/step\n",
      "Epoch 230/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0026 - 692ms/epoch - 2ms/step\n",
      "Epoch 231/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0027 - 695ms/epoch - 2ms/step\n",
      "Epoch 232/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0025 - 676ms/epoch - 2ms/step\n",
      "Epoch 233/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0027 - 666ms/epoch - 2ms/step\n",
      "Epoch 234/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0023 - 664ms/epoch - 2ms/step\n",
      "Epoch 235/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0026 - 670ms/epoch - 2ms/step\n",
      "Epoch 236/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0027 - 673ms/epoch - 2ms/step\n",
      "Epoch 237/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0025 - 667ms/epoch - 2ms/step\n",
      "Epoch 238/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0027 - 669ms/epoch - 2ms/step\n",
      "Epoch 239/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0025 - 670ms/epoch - 2ms/step\n",
      "Epoch 240/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0026 - 689ms/epoch - 2ms/step\n",
      "Epoch 241/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0025 - 672ms/epoch - 2ms/step\n",
      "Epoch 242/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0027 - 665ms/epoch - 2ms/step\n",
      "Epoch 243/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0024 - 660ms/epoch - 2ms/step\n",
      "Epoch 244/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0026 - 686ms/epoch - 2ms/step\n",
      "Epoch 245/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0027 - 648ms/epoch - 2ms/step\n",
      "Epoch 246/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0027 - 635ms/epoch - 2ms/step\n",
      "Epoch 247/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0024 - 669ms/epoch - 2ms/step\n",
      "Epoch 248/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0025 - 670ms/epoch - 2ms/step\n",
      "Epoch 249/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0026 - 666ms/epoch - 2ms/step\n",
      "Epoch 250/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0027 - 671ms/epoch - 2ms/step\n",
      "Epoch 251/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0025 - 662ms/epoch - 2ms/step\n",
      "Epoch 252/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0027 - 669ms/epoch - 2ms/step\n",
      "Epoch 253/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0024 - 666ms/epoch - 2ms/step\n",
      "Epoch 254/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0026 - 661ms/epoch - 2ms/step\n",
      "Epoch 255/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0027 - 669ms/epoch - 2ms/step\n",
      "Epoch 256/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0025 - 666ms/epoch - 2ms/step\n",
      "Epoch 257/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0027 - 665ms/epoch - 2ms/step\n",
      "Epoch 258/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0026 - 664ms/epoch - 2ms/step\n",
      "Epoch 259/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0027 - 673ms/epoch - 2ms/step\n",
      "Epoch 260/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0025 - 665ms/epoch - 2ms/step\n",
      "Epoch 261/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0029 - 667ms/epoch - 2ms/step\n",
      "Epoch 262/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0024 - 667ms/epoch - 2ms/step\n",
      "Epoch 263/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0027 - 667ms/epoch - 2ms/step\n",
      "Epoch 264/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0026 - 669ms/epoch - 2ms/step\n",
      "Epoch 265/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0027 - 663ms/epoch - 2ms/step\n",
      "Epoch 266/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0027 - 669ms/epoch - 2ms/step\n",
      "Epoch 267/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0026 - 672ms/epoch - 2ms/step\n",
      "Epoch 268/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0028 - 661ms/epoch - 2ms/step\n",
      "Epoch 269/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0027 - 670ms/epoch - 2ms/step\n",
      "Epoch 270/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0024 - 667ms/epoch - 2ms/step\n",
      "Epoch 271/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0024 - 662ms/epoch - 2ms/step\n",
      "Epoch 272/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0026 - 672ms/epoch - 2ms/step\n",
      "Epoch 273/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0028 - 669ms/epoch - 2ms/step\n",
      "Epoch 274/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0026 - 699ms/epoch - 2ms/step\n",
      "Epoch 275/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0024 - 683ms/epoch - 2ms/step\n",
      "Epoch 276/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0027 - 676ms/epoch - 2ms/step\n",
      "Epoch 277/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0025 - 667ms/epoch - 2ms/step\n",
      "Epoch 278/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0026 - 694ms/epoch - 2ms/step\n",
      "Epoch 279/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0025 - 712ms/epoch - 3ms/step\n",
      "Epoch 280/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0025 - 779ms/epoch - 3ms/step\n",
      "Epoch 281/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0024 - 814ms/epoch - 3ms/step\n",
      "Epoch 282/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0025 - 728ms/epoch - 3ms/step\n",
      "Epoch 283/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0025 - 683ms/epoch - 2ms/step\n",
      "Epoch 284/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0026 - 709ms/epoch - 3ms/step\n",
      "Epoch 285/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0025 - 710ms/epoch - 3ms/step\n",
      "Epoch 286/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0027 - 687ms/epoch - 2ms/step\n",
      "Epoch 287/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0025 - 703ms/epoch - 2ms/step\n",
      "Epoch 288/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0025 - 694ms/epoch - 2ms/step\n",
      "Epoch 289/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0026 - 685ms/epoch - 2ms/step\n",
      "Epoch 290/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0029 - 700ms/epoch - 2ms/step\n",
      "Epoch 291/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0024 - 710ms/epoch - 3ms/step\n",
      "Epoch 292/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0025 - 696ms/epoch - 2ms/step\n",
      "Epoch 293/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0024 - 706ms/epoch - 3ms/step\n",
      "Epoch 294/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0026 - 714ms/epoch - 3ms/step\n",
      "Epoch 295/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0023 - 699ms/epoch - 2ms/step\n",
      "Epoch 296/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0030 - 703ms/epoch - 2ms/step\n",
      "Epoch 297/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0024 - 699ms/epoch - 2ms/step\n",
      "Epoch 298/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0025 - 703ms/epoch - 2ms/step\n",
      "Epoch 299/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0028 - 660ms/epoch - 2ms/step\n",
      "Epoch 300/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0025 - 722ms/epoch - 3ms/step\n",
      "Epoch 301/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0026 - 724ms/epoch - 3ms/step\n",
      "Epoch 302/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0026 - 701ms/epoch - 2ms/step\n",
      "Epoch 303/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0025 - 720ms/epoch - 3ms/step\n",
      "Epoch 304/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0022 - 740ms/epoch - 3ms/step\n",
      "Epoch 305/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0027 - 694ms/epoch - 2ms/step\n",
      "Epoch 306/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0026 - 798ms/epoch - 3ms/step\n",
      "Epoch 307/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0023 - 710ms/epoch - 3ms/step\n",
      "Epoch 308/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0025 - 725ms/epoch - 3ms/step\n",
      "Epoch 309/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0029 - 695ms/epoch - 2ms/step\n",
      "Epoch 310/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0025 - 724ms/epoch - 3ms/step\n",
      "Epoch 311/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0030 - 722ms/epoch - 3ms/step\n",
      "Epoch 312/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0026 - 728ms/epoch - 3ms/step\n",
      "Epoch 313/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0025 - 751ms/epoch - 3ms/step\n",
      "Epoch 314/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0022 - 714ms/epoch - 3ms/step\n",
      "Epoch 315/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0028 - 717ms/epoch - 3ms/step\n",
      "Epoch 316/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0028 - 798ms/epoch - 3ms/step\n",
      "Epoch 317/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0026 - 709ms/epoch - 3ms/step\n",
      "Epoch 318/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0027 - 681ms/epoch - 2ms/step\n",
      "Epoch 319/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0029 - 674ms/epoch - 2ms/step\n",
      "Epoch 320/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0025 - 695ms/epoch - 2ms/step\n",
      "Epoch 321/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0028 - 704ms/epoch - 2ms/step\n",
      "Epoch 322/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0027 - 689ms/epoch - 2ms/step\n",
      "Epoch 323/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0025 - 670ms/epoch - 2ms/step\n",
      "Epoch 324/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0024 - 678ms/epoch - 2ms/step\n",
      "Epoch 325/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0025 - 682ms/epoch - 2ms/step\n",
      "Epoch 326/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0024 - 689ms/epoch - 2ms/step\n",
      "Epoch 327/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0027 - 684ms/epoch - 2ms/step\n",
      "Epoch 328/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0028 - 667ms/epoch - 2ms/step\n",
      "Epoch 329/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0027 - 723ms/epoch - 3ms/step\n",
      "Epoch 330/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0026 - 730ms/epoch - 3ms/step\n",
      "Epoch 331/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0024 - 656ms/epoch - 2ms/step\n",
      "Epoch 332/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0024 - 675ms/epoch - 2ms/step\n",
      "Epoch 333/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0024 - 671ms/epoch - 2ms/step\n",
      "Epoch 334/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0023 - 678ms/epoch - 2ms/step\n",
      "Epoch 335/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0027 - 681ms/epoch - 2ms/step\n",
      "Epoch 336/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0029 - 677ms/epoch - 2ms/step\n",
      "Epoch 337/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0030 - 704ms/epoch - 2ms/step\n",
      "Epoch 338/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0026 - 727ms/epoch - 3ms/step\n",
      "Epoch 339/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0027 - 675ms/epoch - 2ms/step\n",
      "Epoch 340/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0024 - 703ms/epoch - 2ms/step\n",
      "Epoch 341/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0024 - 716ms/epoch - 3ms/step\n",
      "Epoch 342/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0026 - 683ms/epoch - 2ms/step\n",
      "Epoch 343/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0024 - 704ms/epoch - 2ms/step\n",
      "Epoch 344/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0024 - 714ms/epoch - 3ms/step\n",
      "Epoch 345/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0025 - 686ms/epoch - 2ms/step\n",
      "Epoch 346/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0026 - 713ms/epoch - 3ms/step\n",
      "Epoch 347/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0026 - 702ms/epoch - 2ms/step\n",
      "Epoch 348/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0026 - 711ms/epoch - 3ms/step\n",
      "Epoch 349/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0028 - 721ms/epoch - 3ms/step\n",
      "Epoch 350/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0027 - 714ms/epoch - 3ms/step\n",
      "Epoch 351/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0025 - 676ms/epoch - 2ms/step\n",
      "Epoch 352/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0026 - 664ms/epoch - 2ms/step\n",
      "Epoch 353/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0029 - 669ms/epoch - 2ms/step\n",
      "Epoch 354/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0024 - 695ms/epoch - 2ms/step\n",
      "Epoch 355/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0026 - 688ms/epoch - 2ms/step\n",
      "Epoch 356/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0028 - 694ms/epoch - 2ms/step\n",
      "Epoch 357/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0025 - 698ms/epoch - 2ms/step\n",
      "Epoch 358/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0030 - 687ms/epoch - 2ms/step\n",
      "Epoch 359/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0028 - 696ms/epoch - 2ms/step\n",
      "Epoch 360/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0027 - 698ms/epoch - 2ms/step\n",
      "Epoch 361/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0022 - 690ms/epoch - 2ms/step\n",
      "Epoch 362/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0029 - 704ms/epoch - 2ms/step\n",
      "Epoch 363/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0030 - 703ms/epoch - 2ms/step\n",
      "Epoch 364/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0025 - 701ms/epoch - 2ms/step\n",
      "Epoch 365/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0030 - 715ms/epoch - 3ms/step\n",
      "Epoch 366/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0027 - 996ms/epoch - 4ms/step\n",
      "Epoch 367/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0027 - 726ms/epoch - 3ms/step\n",
      "Epoch 368/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0027 - 736ms/epoch - 3ms/step\n",
      "Epoch 369/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0024 - 758ms/epoch - 3ms/step\n",
      "Epoch 370/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0027 - 781ms/epoch - 3ms/step\n",
      "Epoch 371/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0026 - 757ms/epoch - 3ms/step\n",
      "Epoch 372/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0027 - 712ms/epoch - 3ms/step\n",
      "Epoch 373/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0024 - 716ms/epoch - 3ms/step\n",
      "Epoch 374/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0025 - 728ms/epoch - 3ms/step\n",
      "Epoch 375/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0022 - 708ms/epoch - 3ms/step\n",
      "Epoch 376/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0030 - 771ms/epoch - 3ms/step\n",
      "Epoch 377/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0026 - 737ms/epoch - 3ms/step\n",
      "Epoch 378/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0028 - 730ms/epoch - 3ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 379/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0027 - 716ms/epoch - 3ms/step\n",
      "Epoch 380/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0025 - 752ms/epoch - 3ms/step\n",
      "Epoch 381/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0025 - 755ms/epoch - 3ms/step\n",
      "Epoch 382/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0024 - 734ms/epoch - 3ms/step\n",
      "Epoch 383/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0025 - 767ms/epoch - 3ms/step\n",
      "Epoch 384/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0026 - 724ms/epoch - 3ms/step\n",
      "Epoch 385/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0026 - 777ms/epoch - 3ms/step\n",
      "Epoch 386/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0028 - 728ms/epoch - 3ms/step\n",
      "Epoch 387/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0024 - 753ms/epoch - 3ms/step\n",
      "Epoch 388/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0028 - 747ms/epoch - 3ms/step\n",
      "Epoch 389/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0026 - 737ms/epoch - 3ms/step\n",
      "Epoch 390/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0027 - 745ms/epoch - 3ms/step\n",
      "Epoch 391/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0026 - 747ms/epoch - 3ms/step\n",
      "Epoch 392/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0027 - 742ms/epoch - 3ms/step\n",
      "Epoch 393/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0028 - 727ms/epoch - 3ms/step\n",
      "Epoch 394/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0025 - 748ms/epoch - 3ms/step\n",
      "Epoch 395/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0024 - 745ms/epoch - 3ms/step\n",
      "Epoch 396/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0025 - 738ms/epoch - 3ms/step\n",
      "Epoch 397/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0025 - 741ms/epoch - 3ms/step\n",
      "Epoch 398/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0027 - 741ms/epoch - 3ms/step\n",
      "Epoch 399/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0023 - 748ms/epoch - 3ms/step\n",
      "Epoch 400/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0027 - 739ms/epoch - 3ms/step\n",
      "Epoch 401/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0023 - 756ms/epoch - 3ms/step\n",
      "Epoch 402/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0028 - 747ms/epoch - 3ms/step\n",
      "Epoch 403/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0027 - 744ms/epoch - 3ms/step\n",
      "Epoch 404/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0026 - 749ms/epoch - 3ms/step\n",
      "Epoch 405/1000\n",
      "282/282 - 1s - loss: 0.0019 - val_loss: 0.0026 - 743ms/epoch - 3ms/step\n",
      "Epoch 406/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0028 - 753ms/epoch - 3ms/step\n",
      "Epoch 407/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0025 - 747ms/epoch - 3ms/step\n",
      "Epoch 408/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0026 - 730ms/epoch - 3ms/step\n",
      "Epoch 409/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0027 - 736ms/epoch - 3ms/step\n",
      "Epoch 410/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0028 - 725ms/epoch - 3ms/step\n",
      "Epoch 411/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0025 - 751ms/epoch - 3ms/step\n",
      "Epoch 412/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0026 - 781ms/epoch - 3ms/step\n",
      "Epoch 413/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0026 - 806ms/epoch - 3ms/step\n",
      "Epoch 414/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0024 - 765ms/epoch - 3ms/step\n",
      "Epoch 415/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0030 - 789ms/epoch - 3ms/step\n",
      "Epoch 416/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0028 - 824ms/epoch - 3ms/step\n",
      "Epoch 417/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0026 - 771ms/epoch - 3ms/step\n",
      "Epoch 418/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0026 - 761ms/epoch - 3ms/step\n",
      "Epoch 419/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0026 - 742ms/epoch - 3ms/step\n",
      "Epoch 420/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0028 - 724ms/epoch - 3ms/step\n",
      "Epoch 421/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0027 - 732ms/epoch - 3ms/step\n",
      "Epoch 422/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0025 - 732ms/epoch - 3ms/step\n",
      "Epoch 423/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0023 - 733ms/epoch - 3ms/step\n",
      "Epoch 424/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0027 - 730ms/epoch - 3ms/step\n",
      "Epoch 425/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0028 - 704ms/epoch - 2ms/step\n",
      "Epoch 426/1000\n",
      "282/282 - 1s - loss: 0.0019 - val_loss: 0.0024 - 729ms/epoch - 3ms/step\n",
      "Epoch 427/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0028 - 736ms/epoch - 3ms/step\n",
      "Epoch 428/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0030 - 733ms/epoch - 3ms/step\n",
      "Epoch 429/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0022 - 733ms/epoch - 3ms/step\n",
      "Epoch 430/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0024 - 722ms/epoch - 3ms/step\n",
      "Epoch 431/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0023 - 737ms/epoch - 3ms/step\n",
      "Epoch 432/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0030 - 714ms/epoch - 3ms/step\n",
      "Epoch 433/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0025 - 717ms/epoch - 3ms/step\n",
      "Epoch 434/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0026 - 717ms/epoch - 3ms/step\n",
      "Epoch 435/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0025 - 715ms/epoch - 3ms/step\n",
      "Epoch 436/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0028 - 731ms/epoch - 3ms/step\n",
      "Epoch 437/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0025 - 732ms/epoch - 3ms/step\n",
      "Epoch 438/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0025 - 725ms/epoch - 3ms/step\n",
      "Epoch 439/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0032 - 733ms/epoch - 3ms/step\n",
      "Epoch 440/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0024 - 732ms/epoch - 3ms/step\n",
      "Epoch 441/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0024 - 725ms/epoch - 3ms/step\n",
      "Epoch 442/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0030 - 736ms/epoch - 3ms/step\n",
      "Epoch 443/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0025 - 730ms/epoch - 3ms/step\n",
      "Epoch 444/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0024 - 727ms/epoch - 3ms/step\n",
      "Epoch 445/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0028 - 723ms/epoch - 3ms/step\n",
      "Epoch 446/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0028 - 747ms/epoch - 3ms/step\n",
      "Epoch 447/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0026 - 732ms/epoch - 3ms/step\n",
      "Epoch 448/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0024 - 735ms/epoch - 3ms/step\n",
      "Epoch 449/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0029 - 733ms/epoch - 3ms/step\n",
      "Epoch 450/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0029 - 748ms/epoch - 3ms/step\n",
      "Epoch 451/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0027 - 726ms/epoch - 3ms/step\n",
      "Epoch 452/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0027 - 710ms/epoch - 3ms/step\n",
      "Epoch 453/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0032 - 741ms/epoch - 3ms/step\n",
      "Epoch 454/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0027 - 747ms/epoch - 3ms/step\n",
      "Epoch 455/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0026 - 740ms/epoch - 3ms/step\n",
      "Epoch 456/1000\n",
      "282/282 - 1s - loss: 0.0019 - val_loss: 0.0027 - 745ms/epoch - 3ms/step\n",
      "Epoch 457/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0030 - 749ms/epoch - 3ms/step\n",
      "Epoch 458/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0030 - 743ms/epoch - 3ms/step\n",
      "Epoch 459/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0028 - 729ms/epoch - 3ms/step\n",
      "Epoch 460/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0032 - 722ms/epoch - 3ms/step\n",
      "Epoch 461/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0028 - 735ms/epoch - 3ms/step\n",
      "Epoch 462/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0024 - 728ms/epoch - 3ms/step\n",
      "Epoch 463/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0027 - 730ms/epoch - 3ms/step\n",
      "Epoch 464/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0027 - 731ms/epoch - 3ms/step\n",
      "Epoch 465/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0023 - 725ms/epoch - 3ms/step\n",
      "Epoch 466/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0024 - 720ms/epoch - 3ms/step\n",
      "Epoch 467/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0028 - 753ms/epoch - 3ms/step\n",
      "Epoch 468/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0028 - 748ms/epoch - 3ms/step\n",
      "Epoch 469/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0025 - 748ms/epoch - 3ms/step\n",
      "Epoch 470/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0027 - 744ms/epoch - 3ms/step\n",
      "Epoch 471/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0028 - 739ms/epoch - 3ms/step\n",
      "Epoch 472/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0025 - 743ms/epoch - 3ms/step\n",
      "Epoch 473/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0024 - 714ms/epoch - 3ms/step\n",
      "Epoch 474/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0028 - 742ms/epoch - 3ms/step\n",
      "Epoch 475/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0025 - 754ms/epoch - 3ms/step\n",
      "Epoch 476/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0027 - 746ms/epoch - 3ms/step\n",
      "Epoch 477/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0023 - 739ms/epoch - 3ms/step\n",
      "Epoch 478/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0025 - 737ms/epoch - 3ms/step\n",
      "Epoch 479/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0027 - 736ms/epoch - 3ms/step\n",
      "Epoch 480/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0029 - 721ms/epoch - 3ms/step\n",
      "Epoch 481/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0026 - 736ms/epoch - 3ms/step\n",
      "Epoch 482/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0026 - 738ms/epoch - 3ms/step\n",
      "Epoch 483/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0029 - 708ms/epoch - 3ms/step\n",
      "Epoch 484/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0025 - 738ms/epoch - 3ms/step\n",
      "Epoch 485/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0029 - 740ms/epoch - 3ms/step\n",
      "Epoch 486/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0030 - 734ms/epoch - 3ms/step\n",
      "Epoch 487/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0031 - 735ms/epoch - 3ms/step\n",
      "Epoch 488/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0026 - 733ms/epoch - 3ms/step\n",
      "Epoch 489/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0025 - 746ms/epoch - 3ms/step\n",
      "Epoch 490/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0022 - 746ms/epoch - 3ms/step\n",
      "Epoch 491/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0026 - 739ms/epoch - 3ms/step\n",
      "Epoch 492/1000\n",
      "282/282 - 1s - loss: 0.0019 - val_loss: 0.0028 - 755ms/epoch - 3ms/step\n",
      "Epoch 493/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0027 - 738ms/epoch - 3ms/step\n",
      "Epoch 494/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0033 - 743ms/epoch - 3ms/step\n",
      "Epoch 495/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0026 - 739ms/epoch - 3ms/step\n",
      "Epoch 496/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0030 - 742ms/epoch - 3ms/step\n",
      "Epoch 497/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0023 - 734ms/epoch - 3ms/step\n",
      "Epoch 498/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0028 - 751ms/epoch - 3ms/step\n",
      "Epoch 499/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0027 - 738ms/epoch - 3ms/step\n",
      "Epoch 500/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0025 - 727ms/epoch - 3ms/step\n",
      "Epoch 501/1000\n",
      "282/282 - 1s - loss: 0.0019 - val_loss: 0.0023 - 741ms/epoch - 3ms/step\n",
      "Epoch 502/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0027 - 739ms/epoch - 3ms/step\n",
      "Epoch 503/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0027 - 755ms/epoch - 3ms/step\n",
      "Epoch 504/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0026 - 712ms/epoch - 3ms/step\n",
      "Epoch 505/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0027 - 768ms/epoch - 3ms/step\n",
      "Epoch 506/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0031 - 718ms/epoch - 3ms/step\n",
      "Epoch 507/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0029 - 726ms/epoch - 3ms/step\n",
      "Epoch 508/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0028 - 729ms/epoch - 3ms/step\n",
      "Epoch 509/1000\n",
      "282/282 - 1s - loss: 0.0019 - val_loss: 0.0028 - 726ms/epoch - 3ms/step\n",
      "Epoch 510/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0026 - 730ms/epoch - 3ms/step\n",
      "Epoch 511/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0028 - 735ms/epoch - 3ms/step\n",
      "Epoch 512/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0026 - 729ms/epoch - 3ms/step\n",
      "Epoch 513/1000\n",
      "282/282 - 1s - loss: 0.0019 - val_loss: 0.0029 - 731ms/epoch - 3ms/step\n",
      "Epoch 514/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0027 - 725ms/epoch - 3ms/step\n",
      "Epoch 515/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0026 - 729ms/epoch - 3ms/step\n",
      "Epoch 516/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0028 - 726ms/epoch - 3ms/step\n",
      "Epoch 517/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0027 - 726ms/epoch - 3ms/step\n",
      "Epoch 518/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0028 - 732ms/epoch - 3ms/step\n",
      "Epoch 519/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0024 - 731ms/epoch - 3ms/step\n",
      "Epoch 520/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0024 - 727ms/epoch - 3ms/step\n",
      "Epoch 521/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0025 - 731ms/epoch - 3ms/step\n",
      "Epoch 522/1000\n",
      "282/282 - 1s - loss: 0.0019 - val_loss: 0.0028 - 815ms/epoch - 3ms/step\n",
      "Epoch 523/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0029 - 863ms/epoch - 3ms/step\n",
      "Epoch 524/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0025 - 868ms/epoch - 3ms/step\n",
      "Epoch 525/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0028 - 857ms/epoch - 3ms/step\n",
      "Epoch 526/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0028 - 731ms/epoch - 3ms/step\n",
      "Epoch 527/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0024 - 713ms/epoch - 3ms/step\n",
      "Epoch 528/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0025 - 708ms/epoch - 3ms/step\n",
      "Epoch 529/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0027 - 704ms/epoch - 2ms/step\n",
      "Epoch 530/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0028 - 718ms/epoch - 3ms/step\n",
      "Epoch 531/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0027 - 750ms/epoch - 3ms/step\n",
      "Epoch 532/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0027 - 704ms/epoch - 2ms/step\n",
      "Epoch 533/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0025 - 742ms/epoch - 3ms/step\n",
      "Epoch 534/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0027 - 742ms/epoch - 3ms/step\n",
      "Epoch 535/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0031 - 732ms/epoch - 3ms/step\n",
      "Epoch 536/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0025 - 747ms/epoch - 3ms/step\n",
      "Epoch 537/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0027 - 746ms/epoch - 3ms/step\n",
      "Epoch 538/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0024 - 742ms/epoch - 3ms/step\n",
      "Epoch 539/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0024 - 814ms/epoch - 3ms/step\n",
      "Epoch 540/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0029 - 790ms/epoch - 3ms/step\n",
      "Epoch 541/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0026 - 771ms/epoch - 3ms/step\n",
      "Epoch 542/1000\n",
      "282/282 - 1s - loss: 0.0020 - val_loss: 0.0029 - 771ms/epoch - 3ms/step\n",
      "Epoch 542: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f020c133610>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##Create and train the neural network\n",
    "from keras import callbacks, optimizers\n",
    "from keras.layers import (LSTM, BatchNormalization, Dense, Dropout, Flatten,\n",
    "                          TimeDistributed)\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
    "from keras.models import Sequential, load_model, model_from_json\n",
    "from IPython.display import clear_output\n",
    "from matplotlib import pyplot as plt\n",
    "model = Sequential()\n",
    "model.add(Conv2D(filters=10, kernel_size=1, activation='relu', input_shape=(8,8,12)))\n",
    "model.add(MaxPooling2D(pool_size=2, strides=None))\n",
    "model.add(Flatten())\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(1,activation = 'sigmoid'))\n",
    "model.compile(optimizer = 'Adam',loss='mse')\n",
    "h5 = 'chess' + '_best_model' + '.h5'\n",
    "checkpoint = callbacks.ModelCheckpoint(h5,\n",
    "                                           monitor='val_loss',\n",
    "                                           verbose=0,\n",
    "                                           save_best_only=True,\n",
    "                                           save_weights_only=True,\n",
    "                                           mode='auto',\n",
    "                                           period=1)\n",
    "es = callbacks.EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=5000/10)\n",
    "callback = [checkpoint,es]\n",
    "json = 'chess' + '_best_model' + '.json'\n",
    "model_json = model.to_json()\n",
    "with open(json, \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "print('Training Network...')\n",
    "test = 1000\n",
    "X = np.array(X)\n",
    "X_train = X[test:]\n",
    "y_train = y[test:]\n",
    "X_test = X[:test]\n",
    "y_test = y[:test]\n",
    "model.fit(X_train,y_train,epochs = 1000,verbose = 2,validation_data = (X_test,y_test),callbacks = callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e6de48c5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#load model\n",
    "from keras.models import Sequential, load_model, model_from_json\n",
    "def load_keras_model(dataset,loss,optimizer):\n",
    "        json_file = open(dataset+'_best_model'+'.json', 'r')\n",
    "        loaded_model_json = json_file.read()\n",
    "        json_file.close()\n",
    "        model = model_from_json(loaded_model_json)\n",
    "        model.compile(optimizer=optimizer, loss=loss, metrics = None)\n",
    "        model.load_weights(dataset+'_best_model'+'.h5')\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "236ad712",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 132ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "Epoch 1/100\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "Epoch 100/100\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import chess\n",
    "board = chess.Board()\n",
    "moves = []\n",
    "model = load_keras_model('chess','mse','Adam')\n",
    "def calculate_move1(depth,board,epochs):\n",
    "    first_legal_moves = [board.san(i) for i in list(board.legal_moves)]\n",
    "    #first_legal_moves = str(board.legal_moves)[38:-2].replace(',','').split()\n",
    "    scores = [[0]] * len(first_legal_moves)\n",
    "    for epoch in range(epochs):\n",
    "        for first_move in range(len(first_legal_moves)):\n",
    "            play_board = board.copy()\n",
    "            play_board.push_san(first_legal_moves[first_move])\n",
    "            for _ in range(depth):\n",
    "                legal_moves = str(play_board.legal_moves)[38:-2].replace(',','').split()\n",
    "                try:\n",
    "                    move = random.choice(legal_moves)\n",
    "                except:\n",
    "                    scores[first_move] *= 1000\n",
    "            matrix = make_matrix(play_board.copy())\n",
    "            translated = np.array(translate(matrix,chess_dict))\n",
    "            scores[first_move] += model.predict(translated.reshape(1,8,8,12))*(maximum-minimum)+minimum\n",
    "        print('Epoch',str(epoch+1)+'/'+str(epochs))\n",
    "    return first_legal_moves[scores.index(max(scores))]\n",
    "move= calculate_move1(10,chess.Board(),100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4ec4b4cf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . p\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      "r . . . . . . .\n",
      ". k r . . . . .\n",
      ". . . . . . . K\n",
      "['(Kg1']\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "Interrupted by user",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_42/2830290120.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mboard\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mboard\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegal_moves\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m38\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m','\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mmove\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Which move do you want to Play?'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mboard\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpush_san\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmove\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mboard\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m   1175\u001b[0m                 \u001b[0;34m\"raw_input was called, but this frontend does not support input requests.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1176\u001b[0m             )\n\u001b[0;32m-> 1177\u001b[0;31m         return self._input_request(\n\u001b[0m\u001b[1;32m   1178\u001b[0m             \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"shell\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m   1217\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1218\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1219\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Interrupted by user\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1220\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1221\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid Message:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
     ]
    }
   ],
   "source": [
    "#checking nn code\n",
    "while True:\n",
    "    \n",
    "    legal_moves = str(board.legal_moves)[38:-2].replace(',','').split()\n",
    "    print(board)\n",
    "    print(str(board.legal_moves)[38:-2].replace(',','').split())\n",
    "    move = input('Which move do you want to Play?')\n",
    "    board.push_san(move)\n",
    "    print(board)\n",
    "    matrix = make_matrix(board.copy())\n",
    "    translated = np.array(translate(matrix,chess_dict))\n",
    "    print(model.predict(translated.reshape(1,8,8,12)))\n",
    "    clear_output()\n",
    "    move = calculate_move1(10,board,100)\n",
    "    board.push_san(move)\n",
    "    clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "faa3ee4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/sroy15/anaconda3/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3457, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/tmp/ipykernel_42/3800455257.py\", line 5, in <module>\n",
      "    model = load_keras_model('chess','mse','Adam')\n",
      "  File \"/tmp/ipykernel_42/1158987986.py\", line 7, in load_keras_model\n",
      "    model = model_from_json(loaded_model_json)\n",
      "  File \"/home/sroy15/anaconda3/lib/python3.9/site-packages/keras/saving/model_config.py\", line 109, in model_from_json\n",
      "    return deserialize_from_json(json_string, custom_objects=custom_objects)\n",
      "  File \"/home/sroy15/anaconda3/lib/python3.9/site-packages/keras/layers/serialization.py\", line 272, in deserialize_from_json\n",
      "    return deserialize(config, custom_objects)\n",
      "  File \"/home/sroy15/anaconda3/lib/python3.9/site-packages/keras/layers/serialization.py\", line 249, in deserialize\n",
      "    return generic_utils.deserialize_keras_object(\n",
      "  File \"/home/sroy15/anaconda3/lib/python3.9/site-packages/keras/utils/generic_utils.py\", line 734, in deserialize_keras_object\n",
      "    deserialized_obj = cls.from_config(\n",
      "  File \"/home/sroy15/anaconda3/lib/python3.9/site-packages/keras/engine/sequential.py\", line 475, in from_config\n",
      "    model.add(layer)\n",
      "  File \"/home/sroy15/anaconda3/lib/python3.9/site-packages/tensorflow/python/trackable/base.py\", line 205, in _method_wrapper\n",
      "    result = method(self, *args, **kwargs)\n",
      "  File \"/home/sroy15/anaconda3/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/home/sroy15/anaconda3/lib/python3.9/site-packages/keras/engine/sequential.py\", line 234, in add\n",
      "    output_tensor = layer(self.outputs[0])\n",
      "  File \"/home/sroy15/anaconda3/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/home/sroy15/anaconda3/lib/python3.9/site-packages/keras/engine/base_layer.py\", line 1011, in __call__\n",
      "    return self._functional_construction_call(\n",
      "  File \"/home/sroy15/anaconda3/lib/python3.9/site-packages/keras/engine/base_layer.py\", line 2498, in _functional_construction_call\n",
      "    outputs = self._keras_tensor_symbolic_call(\n",
      "  File \"/home/sroy15/anaconda3/lib/python3.9/site-packages/keras/engine/base_layer.py\", line 2345, in _keras_tensor_symbolic_call\n",
      "    return self._infer_output_signature(\n",
      "  File \"/home/sroy15/anaconda3/lib/python3.9/site-packages/keras/engine/base_layer.py\", line 2404, in _infer_output_signature\n",
      "    outputs = call_fn(inputs, *args, **kwargs)\n",
      "  File \"/home/sroy15/anaconda3/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 96, in error_handler\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/home/sroy15/anaconda3/lib/python3.9/site-packages/keras/layers/normalization/batch_normalization.py\", line 1029, in call\n",
      "    outputs = tf.nn.batch_normalization(\n",
      "  File \"/home/sroy15/anaconda3/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py\", line 150, in error_handler\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/home/sroy15/anaconda3/lib/python3.9/site-packages/tensorflow/python/util/dispatch.py\", line 1176, in op_dispatch_handler\n",
      "    return dispatch_target(*args, **kwargs)\n",
      "  File \"/home/sroy15/anaconda3/lib/python3.9/site-packages/tensorflow/python/ops/nn_impl.py\", line 1588, in batch_normalization\n",
      "    inv = math_ops.rsqrt(variance + variance_epsilon)\n",
      "  File \"/home/sroy15/anaconda3/lib/python3.9/site-packages/tensorflow/python/ops/variables.py\", line 1074, in _run_op\n",
      "    return tensor_oper(a.value(), *args, **kwargs)\n",
      "  File \"/home/sroy15/anaconda3/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py\", line 150, in error_handler\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/home/sroy15/anaconda3/lib/python3.9/site-packages/tensorflow/python/ops/math_ops.py\", line 1407, in binary_op_wrapper\n",
      "    return func(x, y, name=name)\n",
      "  File \"/home/sroy15/anaconda3/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py\", line 150, in error_handler\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/home/sroy15/anaconda3/lib/python3.9/site-packages/tensorflow/python/util/dispatch.py\", line 1176, in op_dispatch_handler\n",
      "    return dispatch_target(*args, **kwargs)\n",
      "  File \"/home/sroy15/anaconda3/lib/python3.9/site-packages/tensorflow/python/ops/math_ops.py\", line 1757, in _add_dispatch\n",
      "    return gen_math_ops.add_v2(x, y, name=name)\n",
      "  File \"/home/sroy15/anaconda3/lib/python3.9/site-packages/tensorflow/python/ops/gen_math_ops.py\", line 475, in add_v2\n",
      "    _, _, _op, _outputs = _op_def_library._apply_op_helper(\n",
      "  File \"/home/sroy15/anaconda3/lib/python3.9/site-packages/tensorflow/python/framework/op_def_library.py\", line 797, in _apply_op_helper\n",
      "    op = g._create_op_internal(op_type_name, inputs, dtypes=None,\n",
      "  File \"/home/sroy15/anaconda3/lib/python3.9/site-packages/tensorflow/python/framework/func_graph.py\", line 735, in _create_op_internal\n",
      "    return super(FuncGraph, self)._create_op_internal(  # pylint: disable=protected-access\n",
      "  File \"/home/sroy15/anaconda3/lib/python3.9/site-packages/tensorflow/python/framework/ops.py\", line 3800, in _create_op_internal\n",
      "    ret = Operation(\n",
      "  File \"/home/sroy15/anaconda3/lib/python3.9/site-packages/tensorflow/python/framework/ops.py\", line 2108, in __init__\n",
      "    c_op = _create_c_op(g, node_def, inputs, control_input_ops, op_def=op_def)\n",
      "  File \"/home/sroy15/anaconda3/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py\", line 150, in error_handler\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/home/sroy15/anaconda3/lib/python3.9/site-packages/tensorflow/python/framework/ops.py\", line 1966, in _create_c_op\n",
      "    c_op = pywrap_tf_session.TF_FinishOperation(op_desc)\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/sroy15/anaconda3/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 2077, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/sroy15/anaconda3/lib/python3.9/site-packages/IPython/core/ultratb.py\", line 1101, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/home/sroy15/anaconda3/lib/python3.9/site-packages/IPython/core/ultratb.py\", line 248, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/home/sroy15/anaconda3/lib/python3.9/site-packages/IPython/core/ultratb.py\", line 281, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/home/sroy15/anaconda3/lib/python3.9/inspect.py\", line 1543, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"/home/sroy15/anaconda3/lib/python3.9/inspect.py\", line 1505, in getframeinfo\n",
      "    lines, lnum = findsource(frame)\n",
      "  File \"/home/sroy15/anaconda3/lib/python3.9/site-packages/IPython/core/ultratb.py\", line 182, in findsource\n",
      "    lines = linecache.getlines(file, globals_dict)\n",
      "  File \"/home/sroy15/anaconda3/lib/python3.9/linecache.py\", line 46, in getlines\n",
      "    return updatecache(filename, module_globals)\n",
      "  File \"/home/sroy15/anaconda3/lib/python3.9/linecache.py\", line 136, in updatecache\n",
      "    with tokenize.open(fullname) as fp:\n",
      "  File \"/home/sroy15/anaconda3/lib/python3.9/tokenize.py\", line 392, in open\n",
      "    buffer = _builtin_open(filename, 'rb')\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import chess\n",
    "board = chess.Board()\n",
    "moves = []\n",
    "model = load_keras_model('chess','mse','Adam')\n",
    "def calculate_move(depth,board,epochs):\n",
    "    first_legal_moves = [board.san(i) for i in list(board.legal_moves)]\n",
    "    #first_legal_moves = str(board.legal_moves)[38:-2].replace(',','').split()\n",
    "    scores = [[0]] * len(first_legal_moves)\n",
    "    for epoch in range(epochs):\n",
    "        for first_move in range(len(first_legal_moves)):\n",
    "            play_board = board.copy()\n",
    "            play_board.push_san(first_legal_moves[first_move])\n",
    "            for _ in range(depth):\n",
    "                legal_moves = [play_board.san(i) for i in list(play_board.legal_moves)]\n",
    "                #legal_moves = str(play_board.legal_moves)[38:-2].replace(',','').split()\n",
    "                try:\n",
    "                    move = random.choice(legal_moves)\n",
    "                except:\n",
    "                    scores[first_move] *= 1000\n",
    "            matrix = make_matrix(play_board.copy())\n",
    "            translated = np.array(translate(matrix,chess_dict))\n",
    "            scores[first_move] += model.predict(translated.reshape(1,8,8,12))*(maximum-minimum)+minimum\n",
    "        #print('Epoch',str(epoch+1)+'/'+str(epochs))\n",
    "    return first_legal_moves[scores.index(max(scores))]\n",
    "#move= calculate_move1(10,chess.Board(),100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1f8dfd0d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We want an input from you to arrange the board. We have randomized the pieces position with different numbers.Can you choose one from the following pieces you want in the board?\n",
      "p or P or Q or R or q or b . Only write the letter \n",
      "p\n",
      "select which problem instance board you want\n",
      " b1:  8/8/7p/8/8/r7/1kr5/7K \n",
      " b2: 8/8/8/8/8/r6p/1kr5/7K \n",
      " b3:  full board \n",
      " b4: 8//1kr5/7p/8/8/r7/7K/8 \n",
      " b5:  8/7k/p1p2p2p/7p/8/r7/1K1n4/8\n",
      "Write b1 or b2 or b3 or b4 or b5b1\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . p\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      "r . . . . . . .\n",
      ". k r . . . . .\n",
      ". . . . . . . K\n",
      "Do you want 1. AI-AI game or 2.Human-AI game or 3.Baseline tree-AI tree game or 4. tree vs tree or 5.AI-NN game ?\n",
      " write 1 or 2 or 3 or 4 or 5= 4\n",
      "time taken to iteration 0 14.49280309677124\n",
      "score for  WHITE =  -6.689480750222919\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . p\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      "r . . . . . . .\n",
      ". k r . . . . .\n",
      ". . . . . . K .\n",
      "-----------move done-----------\n",
      "time taken to iteration 1 0.8959293365478516\n",
      "score for  BLACK =  107.93950714581908\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . p\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". k r . . . . .\n",
      "r . . . . . K .\n",
      "-----------move done-----------\n",
      "Kg1 Ra1#\n",
      "\n",
      "0-1\n"
     ]
    }
   ],
   "source": [
    "#This method is for game that can be customized by the user\n",
    "\n",
    "#customizing problem size\n",
    "#to randomize the starting position we can customize the board. for now I am using a random board setup\n",
    "#board = chess.Board(\"r1bqkb1r/pppp1Qpp/2n2n2/4p3/2B1P3/8/PPPP1PPP/RNB1K1NR\")\n",
    "print(\"We want an input from you to arrange the board. We have randomized the pieces position with different numbers.Can you choose one from the following pieces you want in the board?\")\n",
    "s = input(\"p or P or Q or R or q or b . Only write the letter \\n\")\n",
    "b1 = \"8/8/7\"+s+\"/8/8/r7/1kr5/7K\"\n",
    "b2 = \"8/8/8/8/8/r6\"+s+\"/1kr5/7K\"\n",
    "b3 = \"full board\"\n",
    "b4 = \"8//1kr5/7\"+s+\"/8/8/r7/7K/8\"\n",
    "b5 = \"8/7k/p1p2p2p/7\"+s+\"/8/r7/1K1n4/8\"\n",
    "#b6= \"8/8/8/8/8/8/7Q/5k1K\"\n",
    "print(\"select which problem instance board you want\\n b1: \",b1,\"\\n b2:\",b2,\"\\n b3: \",b3,\"\\n b4:\",b4,\"\\n b5: \",b5)\n",
    "b6 = input(\"Write b1 or b2 or b3 or b4 or b5\")\n",
    "if(b6==\"b1\"):\n",
    "    board = chess.Board(b1)\n",
    "elif(b6==\"b2\"):\n",
    "    board = chess.Board(b2) \n",
    "elif(b6==\"b3\"):\n",
    "    board = chess.Board()\n",
    "elif(b6==\"b4\"):\n",
    "    board = chess.Board(b4)\n",
    "else:\n",
    "    board = chess.Board(b6)\n",
    "score=0\n",
    "\n",
    "#to let the pc choose random positions\n",
    "#board = chess.Board.from_chess960_pos(random.randint(0, 959))\n",
    "#board = chess.Board()\n",
    "print(board)\n",
    "#display_board(board)\n",
    "choice=int(input(\"Do you want 1. AI-AI game or 2.Human-AI game or 3.Baseline tree-AI tree game or 4. tree vs tree or 5.AI-NN game ?\\n write 1 or 2 or 3 or 4 or 5= \"))\n",
    "base1=\"AI\"\n",
    "base2=\"AI\"\n",
    "white = 1\n",
    "\n",
    "if(choice==3):\n",
    "    base1 = \"Tree\"\n",
    "\n",
    "elif (choice==5):\n",
    "    base2=\"NN\"\n",
    "    white=0\n",
    "elif(choice==4):\n",
    "    base1=\"Tree\"\n",
    "    base2 = \"Tree\"\n",
    "moves = 0\n",
    "pgn = []\n",
    "game = chess.pgn.Game()\n",
    "evaluations = []\n",
    "sm = 0\n",
    "cnt = 0\n",
    "#curve  = [ [0]*1000 for i in range(2)]\n",
    "# curve = np.zeros((5,100,1000,2))\n",
    "\n",
    "j=0\n",
    "while((not board.is_game_over())):\n",
    "    all_moves = [board.san(i) for i in list(board.legal_moves)]\n",
    "    start = time.time()\n",
    "    if(white==1 and choice!=5):\n",
    "        root = node(board)\n",
    "        root.state = board\n",
    "        result = mcts_pred(board,root,board.is_game_over(),white,choice,base1,base2)\n",
    "        print(\"time taken to iteration\",j,(time.time()-start))\n",
    "    elif(choice==2 and white==0):\n",
    "        print(\"input format should be something like a2, b6, g3, first one is row, second one is colum\")\n",
    "        print(\"row is a to h and colum is 1 to 8. if you are second player your pieces are small letter , otherwise capital\")\n",
    "        to=input(\"Write where you want to go = \")\n",
    "        frm = input(\"write from where you want to move = \")\n",
    "        result=frm+to\n",
    "    elif(choice==5 and white==1):\n",
    "        start = time.time()\n",
    "        matrix = make_matrix(board.copy())\n",
    "        translated = np.array(translate(matrix,chess_dict))\n",
    "        #print(model.predict(translated.reshape(1,8,8,12)))\n",
    "        #clear_output()\n",
    "        move = calculate_move(5,board,10)\n",
    "        #print(\"time taken for nn in iteration \",j,(time.time()-start))\n",
    "    else:\n",
    "        root = node(board)\n",
    "        root.state = board\n",
    "        result = mcts_pred(board,root,board.is_game_over(),white,choice,base1,base2)\n",
    "        print(\"time taken to iteration\",j,(time.time()-start))\n",
    "    try:\n",
    "        board.push_san(result)\n",
    "\n",
    "    except:\n",
    "        print(result)\n",
    "        print(\"invalid move. game over\")\n",
    "        break\n",
    "    #print(result)\n",
    "    score = staticAnalysis(board,white)\n",
    "    col=\"BLACK\"\n",
    "    if(white):\n",
    "        col=\"WHITE\"\n",
    "    print(\"score for \",col,\"= \",score)\n",
    "    if(score<0):\n",
    "        score*=-1\n",
    "    #curve[white].append(score)\n",
    "    pgn.append(result)\n",
    "    white ^= 1\n",
    "    j+=1\n",
    "\n",
    "    moves+=1\n",
    "    #info = engine.analyse(board, chess.engine.Limit(depth=24))\n",
    "    #evaluat += info['score'].white()\n",
    "    print(board)\n",
    "\n",
    "    print(\"-----------move done-----------\")\n",
    "\n",
    "print(\" \".join(pgn))\n",
    "print()\n",
    "#{'string': 'NNUE evaluation using nn-ad9b42354671.nnue enabled', 'depth': 24, 'seldepth': 24, 'multipv': 1, 'score': PovScore(Cp(0), WHITE), 'nodes': 103968, 'nps': 4725818, 'hashfull': 7, 'tbhits': 0, 'time': 0.022, 'pv': [Move.from_uci('h1g2'), Move.from_uci('b4b5'), Move.from_uci('g2g3'), Move.from_uci('b5c5'), Move.from_uci('g3f4'), Move.from_uci('c5b4'), Move.from_uci('f4f5'), Move.from_uci('b4c5')]}\n",
    "\n",
    "#print(info)\n",
    "#print(evaluations)\n",
    "#We are showing score for each player after each move, so in final result the score is only based on the winner.\n",
    "#If player 1 wins, it should show 1-0 , if there is a draw it will show 1/2-1/2 and 0-1 otherwise.\n",
    "print(board.result())\n",
    "\n",
    "game.headers[\"Result\"] = board.result()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "b9fcf968",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We want an input from you to arrange the board. We have randomized the pieces position with different numbers.Can you choose one from the following pieces you want in the board?\n",
      "p or P or Q or R or q or b . Only write the letter \n",
      "Q\n",
      "select which problem instance board you want\n",
      " b1:  8/8/7Q/8/8/r7/1kr5/7K \n",
      " b2: 8/8/8/8/B7/b6Q/1kp5/7K \n",
      " b3:  full board \n",
      " b4: 8/1kr5/7Q/8/8/r7/7K/8 \n",
      " b5:  8/7k/p1p2p2p/7Q/8/r7/1K1n4/8\n",
      "Write b1 or b2 or b3 or b4 or b5b4\n",
      ". . . . . . . .\n",
      ". k r . . . . .\n",
      ". . . . . . . Q\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      "r . . . . . . .\n",
      ". . . . . . . K\n",
      ". . . . . . . .\n",
      "Do you want 1. AI-AI game or 2.Human-AI game or 3.Baseline tree-AI tree game or 4. tree vs tree or 5.AI-NN game ?\n",
      " write 1 or 2 or 3 or 4 or 5= 3\n",
      "time taken to iteration 0 3.0035457611083984\n",
      "score for  WHITE =  4.420406609579958\n",
      ". . . . . . . .\n",
      ". k r . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      "r . . . . . . .\n",
      ". . . Q . . . K\n",
      ". . . . . . . .\n",
      "-----------move done-----------\n",
      "time taken to iteration 1 2.266759157180786\n",
      "score for  BLACK =  -3.9902583646801357\n",
      ". . . . . . . .\n",
      ". k r . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . Q . . . K\n",
      "r . . . . . . .\n",
      "-----------move done-----------\n",
      "time taken to iteration 2 2.744370222091675\n",
      "score for  WHITE =  4.944467032414577\n",
      ". . . . . . . .\n",
      ". k r . . . . .\n",
      ". . . . . . . .\n",
      ". . . Q . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . K\n",
      "r . . . . . . .\n",
      "-----------move done-----------\n",
      "time taken to iteration 3 3.3132266998291016\n",
      "score for  BLACK =  -3.605338421092199\n",
      ". . . . . . . .\n",
      ". . r . . . . .\n",
      "k . . . . . . .\n",
      ". . . Q . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . K\n",
      "r . . . . . . .\n",
      "-----------move done-----------\n",
      "time taken to iteration 4 3.788890838623047\n",
      "score for  WHITE =  4.573356382834454\n",
      ". . . . . . . .\n",
      ". . r . . . . .\n",
      "k . . . Q . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . K\n",
      "r . . . . . . .\n",
      "-----------move done-----------\n",
      "time taken to iteration 5 2.1445200443267822\n",
      "score for  BLACK =  -3.9193208395438646\n",
      ". . . . . . . .\n",
      ". . r . . . . .\n",
      ". . . . Q . . .\n",
      "k . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . K\n",
      "r . . . . . . .\n",
      "-----------move done-----------\n",
      "time taken to iteration 6 2.395432472229004\n",
      "score for  WHITE =  4.377787083426073\n",
      ". . . . . . . .\n",
      ". . r . . . . .\n",
      ". Q . . . . . .\n",
      "k . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . K\n",
      "r . . . . . . .\n",
      "-----------move done-----------\n",
      "time taken to iteration 7 3.066316843032837\n",
      "score for  BLACK =  6.3683864030870305\n",
      ". . . . . . . .\n",
      ". . r . . . . .\n",
      ". k . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . K\n",
      "r . . . . . . .\n",
      "-----------move done-----------\n",
      "time taken to iteration 8 1.9386436939239502\n",
      "score for  WHITE =  -5.99285257700017\n",
      ". . . . . . . .\n",
      ". . r . . . . .\n",
      ". k . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . K .\n",
      "r . . . . . . .\n",
      "-----------move done-----------\n",
      "time taken to iteration 9 2.6376771926879883\n",
      "score for  BLACK =  6.110280564295019\n",
      ". . . . . . . .\n",
      ". . r . . . . .\n",
      ". k . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      "r . . . . . . .\n",
      ". . . . . . K .\n",
      ". . . . . . . .\n",
      "-----------move done-----------\n",
      "time taken to iteration 10 2.4229366779327393\n",
      "score for  WHITE =  -5.795214776564725\n",
      ". . . . . . . .\n",
      ". . r . . . . .\n",
      ". k . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      "r . . . . . . .\n",
      ". . . . . . . K\n",
      ". . . . . . . .\n",
      "-----------move done-----------\n",
      "time taken to iteration 11 2.049119234085083\n",
      "score for  BLACK =  6.853404663296809\n",
      ". . . . . . . .\n",
      "k . r . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      "r . . . . . . .\n",
      ". . . . . . . K\n",
      ". . . . . . . .\n",
      "-----------move done-----------\n",
      "time taken to iteration 12 2.1579177379608154\n",
      "score for  WHITE =  -5.315729477569346\n",
      ". . . . . . . .\n",
      "k . r . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      "r . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . K\n",
      "-----------move done-----------\n",
      "time taken to iteration 13 2.1840169429779053\n",
      "score for  BLACK =  6.252846293867558\n",
      ". . . . . . . .\n",
      "k . r . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . r . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . K\n",
      "-----------move done-----------\n",
      "time taken to iteration 14 3.744863510131836\n",
      "score for  WHITE =  -5.803144198238465\n",
      ". . . . . . . .\n",
      "k . r . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . r . . . .\n",
      ". . . . . . . K\n",
      ". . . . . . . .\n",
      "-----------move done-----------\n",
      "time taken to iteration 15 3.681180000305176\n",
      "score for  BLACK =  6.733571598319985\n",
      ". . . . . . . .\n",
      "k . r . . . . .\n",
      ". . . r . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . K\n",
      ". . . . . . . .\n",
      "-----------move done-----------\n",
      "time taken to iteration 16 2.357370138168335\n",
      "score for  WHITE =  -5.481509824982581\n",
      ". . . . . . . .\n",
      "k . r . . . . .\n",
      ". . . r . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . K\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      "-----------move done-----------\n",
      "time taken to iteration 17 1.9327945709228516\n",
      "score for  BLACK =  6.717311040129532\n",
      "k . . . . . . .\n",
      ". . r . . . . .\n",
      ". . . r . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . K\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      "-----------move done-----------\n",
      "time taken to iteration 18 2.0271902084350586\n",
      "score for  WHITE =  -5.7832399320085095\n",
      "k . . . . . . .\n",
      ". . r . . . . .\n",
      ". . . r . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . K\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      "-----------move done-----------\n",
      "time taken to iteration 19 2.6363162994384766\n",
      "score for  BLACK =  6.581018719295127\n",
      "k . . . . . . .\n",
      "r . . . . . . .\n",
      ". . . r . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . K\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      "-----------move done-----------\n",
      "time taken to iteration 20 2.32882022857666\n",
      "score for  WHITE =  -5.796498356968627\n",
      "k . . . . . . .\n",
      "r . . . . . . .\n",
      ". . . r . . . .\n",
      ". . . . . . . K\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      "-----------move done-----------\n",
      "time taken to iteration 21 2.3998873233795166\n",
      "score for  BLACK =  6.768316559219039\n",
      "k . . . . . . .\n",
      ". r . . . . . .\n",
      ". . . r . . . .\n",
      ". . . . . . . K\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      "-----------move done-----------\n",
      "time taken to iteration 22 3.496202230453491\n",
      "score for  WHITE =  -5.456762324476982\n",
      "k . . . . . . .\n",
      ". r . . . . . .\n",
      ". . . r . . . .\n",
      ". . . . . . K .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      "-----------move done-----------\n",
      "time taken to iteration 23 2.9980921745300293\n",
      "score for  BLACK =  6.617206284544614\n",
      "k . . . . . . .\n",
      ". r . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . K .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . r . . . .\n",
      "-----------move done-----------\n",
      "time taken to iteration 24 2.784177303314209\n",
      "score for  WHITE =  -5.362079384358579\n",
      "k . . . . . . .\n",
      ". r . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . K .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . r . . . .\n",
      "-----------move done-----------\n",
      "time taken to iteration 25 2.2130303382873535\n",
      "score for  BLACK =  6.294511103392601\n",
      "k . . . . . . .\n",
      ". r . r . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . K .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      "-----------move done-----------\n",
      "time taken to iteration 26 2.427565574645996\n",
      "score for  WHITE =  -5.812638216488509\n",
      "k . . . . . . .\n",
      ". r . r . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . K\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      "-----------move done-----------\n",
      "time taken to iteration 27 2.476989984512329\n",
      "score for  BLACK =  6.359735514637862\n",
      "k . . . . . . .\n",
      ". r . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . K\n",
      ". . . r . . . .\n",
      ". . . . . . . .\n",
      "-----------move done-----------\n",
      "time taken to iteration 28 3.1719629764556885\n",
      "score for  WHITE =  -5.861979993274517\n",
      "k . . . . . . .\n",
      ". r . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . K\n",
      ". . . . . . . .\n",
      ". . . r . . . .\n",
      ". . . . . . . .\n",
      "-----------move done-----------\n",
      "time taken to iteration 29 2.829019069671631\n",
      "score for  BLACK =  6.992009205874929\n",
      "k . . . . . . .\n",
      ". r . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . K\n",
      ". . . . . . . .\n",
      "r . . . . . . .\n",
      ". . . . . . . .\n",
      "-----------move done-----------\n",
      "time taken to iteration 30 2.875821590423584\n",
      "score for  WHITE =  -5.790987894655972\n",
      "k . . . . . . .\n",
      ". r . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . K\n",
      "r . . . . . . .\n",
      ". . . . . . . .\n",
      "-----------move done-----------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time taken to iteration 31 3.7190375328063965\n",
      "score for  BLACK =  6.7407708158273305\n",
      "k r . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . K\n",
      "r . . . . . . .\n",
      ". . . . . . . .\n",
      "-----------move done-----------\n",
      "time taken to iteration 32 1.7938134670257568\n",
      "score for  WHITE =  -5.657576814403542\n",
      "k r . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . K\n",
      ". . . . . . . .\n",
      "r . . . . . . .\n",
      ". . . . . . . .\n",
      "-----------move done-----------\n",
      "time taken to iteration 33 2.8308351039886475\n",
      "score for  BLACK =  6.578658714186614\n",
      "k . r . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . K\n",
      ". . . . . . . .\n",
      "r . . . . . . .\n",
      ". . . . . . . .\n",
      "-----------move done-----------\n",
      "time taken to iteration 34 2.726945161819458\n",
      "score for  WHITE =  -5.585729091991083\n",
      "k . r . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . K\n",
      "r . . . . . . .\n",
      ". . . . . . . .\n",
      "-----------move done-----------\n",
      "time taken to iteration 35 3.0109846591949463\n",
      "score for  BLACK =  6.313638400933121\n",
      "k . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . K\n",
      "r . r . . . . .\n",
      ". . . . . . . .\n",
      "-----------move done-----------\n",
      "time taken to iteration 36 3.194075107574463\n",
      "score for  WHITE =  -5.142448570161578\n",
      "k . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . K .\n",
      ". . . . . . . .\n",
      "r . r . . . . .\n",
      ". . . . . . . .\n",
      "-----------move done-----------\n",
      "time taken to iteration 37 1.887843132019043\n",
      "score for  BLACK =  6.542395032423749\n",
      "k . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . K .\n",
      ". . . . . . . .\n",
      ". r r . . . . .\n",
      ". . . . . . . .\n",
      "-----------move done-----------\n",
      "time taken to iteration 38 2.956904649734497\n",
      "score for  WHITE =  -5.443566135106356\n",
      "k . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . K\n",
      ". r r . . . . .\n",
      ". . . . . . . .\n",
      "-----------move done-----------\n",
      "time taken to iteration 39 3.143873691558838\n",
      "score for  BLACK =  6.185991174691903\n",
      ". k . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . K\n",
      ". r r . . . . .\n",
      ". . . . . . . .\n",
      "-----------move done-----------\n",
      "time taken to iteration 40 2.673769235610962\n",
      "score for  WHITE =  -5.197996898191789\n",
      ". k . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . K .\n",
      ". r r . . . . .\n",
      ". . . . . . . .\n",
      "-----------move done-----------\n",
      "time taken to iteration 41 2.157457113265991\n",
      "score for  BLACK =  6.5599087146495245\n",
      ". k . . . . . .\n",
      ". r . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . K .\n",
      ". . r . . . . .\n",
      ". . . . . . . .\n",
      "-----------move done-----------\n",
      "time taken to iteration 42 2.5188119411468506\n",
      "score for  WHITE =  -5.3973297507478595\n",
      ". k . . . . . .\n",
      ". r . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . K . .\n",
      ". . r . . . . .\n",
      ". . . . . . . .\n",
      "-----------move done-----------\n",
      "time taken to iteration 43 2.3553802967071533\n",
      "score for  BLACK =  6.216167855750989\n",
      ". k . . . . . .\n",
      ". . . . . . . .\n",
      ". r . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . K . .\n",
      ". . r . . . . .\n",
      ". . . . . . . .\n",
      "-----------move done-----------\n",
      "time taken to iteration 44 2.6130645275115967\n",
      "score for  WHITE =  -5.9453449430889505\n",
      ". k . . . . . .\n",
      ". . . . . . . .\n",
      ". r . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . K . . .\n",
      ". . . . . . . .\n",
      ". . r . . . . .\n",
      ". . . . . . . .\n",
      "-----------move done-----------\n",
      "time taken to iteration 45 1.886993408203125\n",
      "score for  BLACK =  6.747641268538681\n",
      ". k . . . . . .\n",
      ". . . . . . . .\n",
      ". r . . . . . .\n",
      ". . . . . . . .\n",
      ". . r . K . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      "-----------move done-----------\n",
      "time taken to iteration 46 2.019082546234131\n",
      "score for  WHITE =  -5.750675948475554\n",
      ". k . . . . . .\n",
      ". . . . . . . .\n",
      ". r . . . . . .\n",
      ". . . . K . . .\n",
      ". . r . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      "-----------move done-----------\n",
      "time taken to iteration 47 2.168654680252075\n",
      "score for  BLACK =  6.3347443929193386\n",
      ". k . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . K . . .\n",
      ". . r . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". r . . . . . .\n",
      "-----------move done-----------\n",
      "time taken to iteration 48 2.045149803161621\n",
      "score for  WHITE =  -5.298951575414843\n",
      ". k . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . K . . . .\n",
      ". . r . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". r . . . . . .\n",
      "-----------move done-----------\n",
      "time taken to iteration 49 1.9398839473724365\n",
      "score for  BLACK =  6.887719154861715\n",
      ". k . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". r . K . . . .\n",
      ". . r . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      "-----------move done-----------\n",
      "time taken to iteration 50 1.3029496669769287\n",
      "score for  WHITE =  -2.262508128495094\n",
      ". k . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". r . . . . . .\n",
      ". . K . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      "-----------move done-----------\n",
      "time taken to iteration 51 1.1016297340393066\n",
      "score for  BLACK =  3.7899976312977683\n",
      ". k . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". r K . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      "-----------move done-----------\n",
      "time taken to iteration 52 1.5250232219696045\n",
      "score for  WHITE =  -2.4214831512095065\n",
      ". k . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". r . . . . . .\n",
      ". . K . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      "-----------move done-----------\n",
      "time taken to iteration 53 1.2512333393096924\n",
      "score for  BLACK =  3.354709946717229\n",
      ". k . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . r . . . . .\n",
      ". . K . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      "-----------move done-----------\n",
      "time taken to iteration 54 0.9998815059661865\n",
      "score for  WHITE =  -2.984625474813943\n",
      ". k . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . r . . . . .\n",
      ". . . . . . . .\n",
      ". K . . . . . .\n",
      ". . . . . . . .\n",
      "-----------move done-----------\n",
      "time taken to iteration 55 1.67402982711792\n",
      "score for  BLACK =  3.2159935739960184\n",
      ". k . . . . . .\n",
      ". . r . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". K . . . . . .\n",
      ". . . . . . . .\n",
      "-----------move done-----------\n",
      "time taken to iteration 56 0.9581630229949951\n",
      "score for  WHITE =  -2.57298365759724\n",
      ". k . . . . . .\n",
      ". . r . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". K . . . . . .\n",
      "-----------move done-----------\n",
      "time taken to iteration 57 1.8863976001739502\n",
      "score for  BLACK =  3.7436467097028623\n",
      ". k . . . . . .\n",
      ". . . r . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". K . . . . . .\n",
      "-----------move done-----------\n",
      "time taken to iteration 58 2.035186767578125\n",
      "score for  WHITE =  -2.300215758544761\n",
      ". k . . . . . .\n",
      ". . . r . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . K . . . . .\n",
      ". . . . . . . .\n",
      "-----------move done-----------\n",
      "time taken to iteration 59 0.9914658069610596\n",
      "score for  BLACK =  3.2004069809040194\n",
      ". . . . . . . .\n",
      "k . . r . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . K . . . . .\n",
      ". . . . . . . .\n",
      "-----------move done-----------\n",
      "time taken to iteration 60 2.082563877105713\n",
      "score for  WHITE =  -2.7965631208861184\n",
      ". . . . . . . .\n",
      "k . . r . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". K . . . . . .\n",
      "-----------move done-----------\n",
      "time taken to iteration 61 1.1437644958496094\n",
      "score for  BLACK =  3.096467752338373\n",
      ". . . . . . . .\n",
      "k . r . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". K . . . . . .\n",
      "-----------move done-----------\n",
      "time taken to iteration 62 1.5052790641784668\n",
      "score for  WHITE =  -2.6327830090962987\n",
      ". . . . . . . .\n",
      "k . r . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". K . . . . . .\n",
      ". . . . . . . .\n",
      "-----------move done-----------\n",
      "time taken to iteration 63 1.424959421157837\n",
      "score for  BLACK =  3.7085307167869286\n",
      ". . . . . . . .\n",
      ". k r . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". K . . . . . .\n",
      ". . . . . . . .\n",
      "-----------move done-----------\n",
      "time taken to iteration 64 1.6683430671691895\n",
      "score for  WHITE =  -2.82271616636377\n",
      ". . . . . . . .\n",
      ". k r . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". K . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      "-----------move done-----------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time taken to iteration 65 0.8833699226379395\n",
      "score for  BLACK =  3.8024903607571874\n",
      ". . . . . . . .\n",
      ". . r . . . . .\n",
      ". . k . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". K . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      "-----------move done-----------\n",
      "time taken to iteration 66 1.5810737609863281\n",
      "score for  WHITE =  -2.8021577921068817\n",
      ". . . . . . . .\n",
      ". . r . . . . .\n",
      ". . k . . . . .\n",
      ". . . . . . . .\n",
      ". K . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      "-----------move done-----------\n",
      "time taken to iteration 67 1.2924995422363281\n",
      "score for  BLACK =  3.2924245835172856\n",
      ". . . . . . . .\n",
      ". . . . . r . .\n",
      ". . k . . . . .\n",
      ". . . . . . . .\n",
      ". K . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      "-----------move done-----------\n",
      "time taken to iteration 68 1.3698573112487793\n",
      "score for  WHITE =  -2.055301415970722\n",
      ". . . . . . . .\n",
      ". . . . . r . .\n",
      ". . k . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . K . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      "-----------move done-----------\n",
      "time taken to iteration 69 1.0018134117126465\n",
      "score for  BLACK =  3.466173426989624\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . k . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . K . . . . .\n",
      ". . . . . r . .\n",
      ". . . . . . . .\n",
      "-----------move done-----------\n",
      "time taken to iteration 70 1.6198327541351318\n",
      "score for  WHITE =  -2.168037131881742\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . k . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". K . . . . . .\n",
      ". . . . . r . .\n",
      ". . . . . . . .\n",
      "-----------move done-----------\n",
      "time taken to iteration 71 1.3263983726501465\n",
      "score for  BLACK =  3.0422551942514486\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". k . . . . . .\n",
      ". . . . . . . .\n",
      ". K . . . . . .\n",
      ". . . . . r . .\n",
      ". . . . . . . .\n",
      "-----------move done-----------\n",
      "time taken to iteration 72 0.5023901462554932\n",
      "score for  WHITE =  -2.0776101802587252\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". k . . . . . .\n",
      ". . . . . . . .\n",
      "K . . . . . . .\n",
      ". . . . . r . .\n",
      ". . . . . . . .\n",
      "-----------move done-----------\n",
      "time taken to iteration 73 1.2948601245880127\n",
      "score for  BLACK =  3.696542369079611\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". k . . . . . .\n",
      ". . . . . . . .\n",
      "K . . . . . . .\n",
      ". . . r . . . .\n",
      ". . . . . . . .\n",
      "-----------move done-----------\n",
      "time taken to iteration 74 1.6406049728393555\n",
      "score for  WHITE =  -2.2269361154440444\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". k . . . . . .\n",
      ". . . . . . . .\n",
      ". K . . . . . .\n",
      ". . . r . . . .\n",
      ". . . . . . . .\n",
      "-----------move done-----------\n",
      "time taken to iteration 75 0.9999654293060303\n",
      "score for  BLACK =  3.1315834215576555\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". k . . . . . .\n",
      ". . . . . . . .\n",
      ". K . . . . . .\n",
      ". . r . . . . .\n",
      ". . . . . . . .\n",
      "-----------move done-----------\n",
      "time taken to iteration 76 0.9867861270904541\n",
      "score for  WHITE =  -2.6700170693416294\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". k . . . . . .\n",
      ". . . . . . . .\n",
      "K . . . . . . .\n",
      ". . r . . . . .\n",
      ". . . . . . . .\n",
      "-----------move done-----------\n",
      "time taken to iteration 77 0.92226243019104\n",
      "score for  BLACK =  3.2737237120941067\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . k . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      "K . . . . . . .\n",
      ". . r . . . . .\n",
      ". . . . . . . .\n",
      "-----------move done-----------\n",
      "time taken to iteration 78 0.8980467319488525\n",
      "score for  WHITE =  -2.414204218687441\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . k . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". K . . . . . .\n",
      ". . r . . . . .\n",
      ". . . . . . . .\n",
      "-----------move done-----------\n",
      "time taken to iteration 79 0.8662288188934326\n",
      "score for  BLACK =  3.485380289538245\n",
      ". . . . . . . .\n",
      ". . k . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". K . . . . . .\n",
      ". . r . . . . .\n",
      ". . . . . . . .\n",
      "-----------move done-----------\n",
      "time taken to iteration 80 1.304492712020874\n",
      "score for  WHITE =  -2.0790847279042737\n",
      ". . . . . . . .\n",
      ". . k . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      "K . . . . . . .\n",
      ". . . . . . . .\n",
      ". . r . . . . .\n",
      ". . . . . . . .\n",
      "-----------move done-----------\n",
      "time taken to iteration 81 1.8558671474456787\n",
      "score for  BLACK =  3.815343053303243\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . k . . . .\n",
      ". . . . . . . .\n",
      "K . . . . . . .\n",
      ". . . . . . . .\n",
      ". . r . . . . .\n",
      ". . . . . . . .\n",
      "-----------move done-----------\n",
      "time taken to iteration 82 1.6745059490203857\n",
      "score for  WHITE =  -2.720558526771883\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . k . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". K . . . . . .\n",
      ". . r . . . . .\n",
      ". . . . . . . .\n",
      "-----------move done-----------\n",
      "time taken to iteration 83 1.2435665130615234\n",
      "score for  BLACK =  3.767272840885161\n",
      ". . r . . . . .\n",
      ". . . . . . . .\n",
      ". . . k . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". K . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      "-----------move done-----------\n",
      "time taken to iteration 84 1.9910931587219238\n",
      "score for  WHITE =  -2.192722374679075\n",
      ". . r . . . . .\n",
      ". . . . . . . .\n",
      ". . . k . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". K . . . . . .\n",
      ". . . . . . . .\n",
      "-----------move done-----------\n",
      "time taken to iteration 85 1.2115402221679688\n",
      "score for  BLACK =  3.5276766174103695\n",
      ". . r . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . k . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". K . . . . . .\n",
      ". . . . . . . .\n",
      "-----------move done-----------\n",
      "time taken to iteration 86 1.1415643692016602\n",
      "score for  WHITE =  -2.3746653251674905\n",
      ". . r . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . k . . .\n",
      ". . . . . . . .\n",
      ". K . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      "-----------move done-----------\n",
      "time taken to iteration 87 1.088165044784546\n",
      "score for  BLACK =  3.526694127677991\n",
      ". . . . . r . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . k . . .\n",
      ". . . . . . . .\n",
      ". K . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      "-----------move done-----------\n",
      "time taken to iteration 88 1.191676378250122\n",
      "score for  WHITE =  -2.7169812203383907\n",
      ". . . . . r . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . k . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". K . . . . . .\n",
      ". . . . . . . .\n",
      "-----------move done-----------\n",
      "time taken to iteration 89 1.4386942386627197\n",
      "score for  BLACK =  3.077419158761815\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . r . .\n",
      ". . . . k . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". K . . . . . .\n",
      ". . . . . . . .\n",
      "-----------move done-----------\n",
      "time taken to iteration 90 1.458583116531372\n",
      "score for  WHITE =  -2.2247530521933467\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . r . .\n",
      ". . . . k . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      "K . . . . . . .\n",
      "-----------move done-----------\n",
      "time taken to iteration 91 1.3434057235717773\n",
      "score for  BLACK =  3.1484336731273275\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". r . . . . . .\n",
      ". . . . k . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      "K . . . . . . .\n",
      "-----------move done-----------\n",
      "time taken to iteration 92 1.5163547992706299\n",
      "score for  WHITE =  -2.851285677857035\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". r . . . . . .\n",
      ". . . . k . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      "K . . . . . . .\n",
      ". . . . . . . .\n",
      "-----------move done-----------\n",
      "time taken to iteration 93 0.6372110843658447\n",
      "score for  BLACK =  3.555886015874039\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . r .\n",
      ". . . . k . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      "K . . . . . . .\n",
      ". . . . . . . .\n",
      "-----------move done-----------\n",
      "time taken to iteration 94 1.1422462463378906\n",
      "score for  WHITE =  -2.5181773984654314\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . r .\n",
      ". . . . k . . .\n",
      ". . . . . . . .\n",
      "K . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      "-----------move done-----------\n",
      "time taken to iteration 95 1.1313726902008057\n",
      "score for  BLACK =  3.8389634662507213\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . k . r .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      "K . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      "-----------move done-----------\n",
      "time taken to iteration 96 0.8190913200378418\n",
      "score for  WHITE =  -2.4536771933728514\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . k . r .\n",
      ". . . . . . . .\n",
      "K . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      "-----------move done-----------\n",
      "time taken to iteration 97 1.1782853603363037\n",
      "score for  BLACK =  3.9016555920110543\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . r .\n",
      ". . . . . k . .\n",
      "K . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      "-----------move done-----------\n",
      "time taken to iteration 98 1.1300628185272217\n",
      "score for  WHITE =  -2.336517651689504\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . r .\n",
      ". . . . . k . .\n",
      ". . . . . . . .\n",
      ". K . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      "-----------move done-----------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time taken to iteration 99 1.4822800159454346\n",
      "score for  BLACK =  3.952391555376542\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . k . .\n",
      ". . . . . . . .\n",
      ". K . . . . r .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      "-----------move done-----------\n",
      "time taken to iteration 100 1.2767534255981445\n",
      "score for  WHITE =  -2.1236537620218536\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . k . .\n",
      ". K . . . . . .\n",
      ". . . . . . r .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      "-----------move done-----------\n",
      "time taken to iteration 101 0.8529434204101562\n",
      "score for  BLACK =  3.729086727605912\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . k . . .\n",
      ". . . . . . . .\n",
      ". K . . . . . .\n",
      ". . . . . . r .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      "-----------move done-----------\n",
      "time taken to iteration 102 1.4374964237213135\n",
      "score for  WHITE =  -2.5629721851429568\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . k . . .\n",
      ". K . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . r .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      "-----------move done-----------\n",
      "time taken to iteration 103 1.0996978282928467\n",
      "score for  BLACK =  3.6211172745528586\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . k . . .\n",
      ". K . . . . . .\n",
      ". . . . . . . .\n",
      ". . . r . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      "-----------move done-----------\n",
      "time taken to iteration 104 1.1227331161499023\n",
      "score for  WHITE =  -2.2657158420145858\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . K . k . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . r . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      "-----------move done-----------\n",
      "time taken to iteration 105 1.2796852588653564\n",
      "score for  BLACK =  3.0215007389302557\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . K r k . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      "-----------move done-----------\n",
      "time taken to iteration 106 0.7572312355041504\n",
      "score for  WHITE =  -2.328114761996057\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . r k . . .\n",
      ". . K . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      "-----------move done-----------\n",
      "time taken to iteration 107 0.7847800254821777\n",
      "score for  BLACK =  3.723186918288114\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". r . . k . . .\n",
      ". . K . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      "-----------move done-----------\n",
      "time taken to iteration 108 0.9774158000946045\n",
      "score for  WHITE =  -2.0613666340995715\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". r . . k . . .\n",
      ". . . . . . . .\n",
      ". . . K . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      "-----------move done-----------\n",
      "time taken to iteration 109 1.1804001331329346\n",
      "score for  BLACK =  3.653949349988543\n",
      ". r . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . k . . .\n",
      ". . . . . . . .\n",
      ". . . K . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      "-----------move done-----------\n",
      "time taken to iteration 110 1.285963773727417\n",
      "score for  WHITE =  -2.4953899929322962\n",
      ". r . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . k . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . K . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      "-----------move done-----------\n",
      "time taken to iteration 111 1.4069797992706299\n",
      "score for  BLACK =  3.177065198905367\n",
      ". r . . . . . .\n",
      ". . . . k . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . K . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      "-----------move done-----------\n",
      "time taken to iteration 112 0.9804515838623047\n",
      "score for  WHITE =  -2.4928653321349787\n",
      ". r . . . . . .\n",
      ". . . . k . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . K . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      "-----------move done-----------\n",
      "time taken to iteration 113 0.9069652557373047\n",
      "score for  BLACK =  3.2946623420333925\n",
      ". . . . . . . .\n",
      ". . . . k . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . K . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". r . . . . . .\n",
      "-----------move done-----------\n",
      "time taken to iteration 114 1.7204227447509766\n",
      "score for  WHITE =  -2.6583393678054\n",
      ". . . . . . . .\n",
      ". . . . k . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . K . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". r . . . . . .\n",
      "-----------move done-----------\n",
      "time taken to iteration 115 0.8418593406677246\n",
      "score for  BLACK =  3.420395172889715\n",
      ". . . . . . . .\n",
      ". . . . k . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". r . . K . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      "-----------move done-----------\n",
      "time taken to iteration 116 1.3756976127624512\n",
      "score for  WHITE =  -2.8593618384559925\n",
      ". . . . . . . .\n",
      ". . . . k . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". r . . . . . .\n",
      ". . . . K . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      "-----------move done-----------\n",
      "time taken to iteration 117 1.4165992736816406\n",
      "score for  BLACK =  3.216359557959553\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . k . . .\n",
      ". . . . . . . .\n",
      ". r . . . . . .\n",
      ". . . . K . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      "-----------move done-----------\n",
      "time taken to iteration 118 1.0304908752441406\n",
      "score for  WHITE =  -2.155756137891\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . k . . .\n",
      ". . . . . . . .\n",
      ". r . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . K . . .\n",
      ". . . . . . . .\n",
      "-----------move done-----------\n",
      "time taken to iteration 119 1.0541751384735107\n",
      "score for  BLACK =  3.45039351268705\n",
      ". . . . . . . .\n",
      ". . . . k . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". r . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . K . . .\n",
      ". . . . . . . .\n",
      "-----------move done-----------\n",
      "time taken to iteration 120 1.1354882717132568\n",
      "score for  WHITE =  -2.8726266699959218\n",
      ". . . . . . . .\n",
      ". . . . k . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". r . . . . . .\n",
      ". . . . . . . .\n",
      ". . . K . . . .\n",
      ". . . . . . . .\n",
      "-----------move done-----------\n",
      "time taken to iteration 121 1.2046856880187988\n",
      "score for  BLACK =  3.1199381083304436\n",
      ". . . . . . . .\n",
      ". . . . k . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". r . K . . . .\n",
      ". . . . . . . .\n",
      "-----------move done-----------\n",
      "time taken to iteration 122 1.1682765483856201\n",
      "score for  WHITE =  -2.28461476583788\n",
      ". . . . . . . .\n",
      ". . . . k . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . K . . .\n",
      ". r . . . . . .\n",
      ". . . . . . . .\n",
      "-----------move done-----------\n",
      "time taken to iteration 123 1.0681347846984863\n",
      "score for  BLACK =  3.1005200031595757\n",
      ". . . k . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . K . . .\n",
      ". r . . . . . .\n",
      ". . . . . . . .\n",
      "-----------move done-----------\n",
      "time taken to iteration 124 0.9201996326446533\n",
      "score for  WHITE =  -2.2215043209002\n",
      ". . . k . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . K . .\n",
      ". r . . . . . .\n",
      ". . . . . . . .\n",
      "-----------move done-----------\n",
      "time taken to iteration 125 0.857388973236084\n",
      "score for  BLACK =  3.013297324795199\n",
      ". . . k . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". r . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . K . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      "-----------move done-----------\n",
      "time taken to iteration 126 0.9065048694610596\n",
      "score for  WHITE =  -2.644334478676801\n",
      ". . . k . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". r . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . K . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      "-----------move done-----------\n",
      "time taken to iteration 127 0.8998534679412842\n",
      "score for  BLACK =  3.530397907583785\n",
      ". . . k . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . K . . .\n",
      ". . . . . . . .\n",
      ". r . . . . . .\n",
      "-----------move done-----------\n",
      "time taken to iteration 128 1.0780870914459229\n",
      "score for  WHITE =  -2.691714801711325\n",
      ". . . k . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . K . . . .\n",
      ". . . . . . . .\n",
      ". r . . . . . .\n",
      "-----------move done-----------\n",
      "time taken to iteration 129 1.4827961921691895\n",
      "score for  BLACK =  3.6430531577649017\n",
      ". . . k . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . K . . . .\n",
      ". . . . . . . .\n",
      ". . . . r . . .\n",
      "-----------move done-----------\n",
      "time taken to iteration 130 0.6374187469482422\n",
      "score for  WHITE =  -2.8796492800151485\n",
      ". . . k . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . K . . . . .\n",
      ". . . . r . . .\n",
      "-----------move done-----------\n",
      "time taken to iteration 131 0.5938625335693359\n",
      "score for  BLACK =  3.8145055645576216\n",
      ". . . . . . . .\n",
      ". . k . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . K . . . . .\n",
      ". . . . r . . .\n",
      "-----------move done-----------\n",
      "time taken to iteration 132 0.8252692222595215\n",
      "score for  WHITE =  -2.53305284541695\n",
      ". . . . . . . .\n",
      ". . k . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . K . . . .\n",
      ". . . . . . . .\n",
      ". . . . r . . .\n",
      "-----------move done-----------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time taken to iteration 133 0.8430306911468506\n",
      "score for  BLACK =  3.286476848527392\n",
      ". . . . . . . .\n",
      ". . k . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . K . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . r .\n",
      "-----------move done-----------\n",
      "time taken to iteration 134 1.2536416053771973\n",
      "score for  WHITE =  -2.3036026375093783\n",
      ". . . . . . . .\n",
      ". . k . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . K . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . r .\n",
      "-----------move done-----------\n",
      "time taken to iteration 135 1.2272076606750488\n",
      "score for  BLACK =  3.0252851759225887\n",
      ". . . . . . . .\n",
      ". k . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . K . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . r .\n",
      "-----------move done-----------\n",
      "time taken to iteration 136 1.0609376430511475\n",
      "score for  WHITE =  -2.172835309773193\n",
      ". . . . . . . .\n",
      ". k . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . K . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . r .\n",
      "-----------move done-----------\n",
      "time taken to iteration 137 0.8961906433105469\n",
      "score for  BLACK =  3.193584765601494\n",
      ". . . . . . . .\n",
      ". k . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . K . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . r . . . . .\n",
      "-----------move done-----------\n",
      "time taken to iteration 138 0.729736328125\n",
      "score for  WHITE =  -2.4798467459472233\n",
      ". . . . . . . .\n",
      ". k . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". K . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . r . . . . .\n",
      "-----------move done-----------\n",
      "time taken to iteration 139 0.6658642292022705\n",
      "score for  BLACK =  3.7335987388120646\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". k . . . . . .\n",
      ". . . . . . . .\n",
      ". K . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . r . . . . .\n",
      "-----------move done-----------\n",
      "time taken to iteration 140 0.6890101432800293\n",
      "score for  WHITE =  -2.3896733159742602\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". k . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      "K . . . . . . .\n",
      ". . . . . . . .\n",
      ". . r . . . . .\n",
      "-----------move done-----------\n",
      "time taken to iteration 141 1.0096113681793213\n",
      "score for  BLACK =  3.389064927607664\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . k . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      "K . . . . . . .\n",
      ". . . . . . . .\n",
      ". . r . . . . .\n",
      "-----------move done-----------\n",
      "time taken to iteration 142 0.9071204662322998\n",
      "score for  WHITE =  -2.750251714105449\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . k . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". K . . . . . .\n",
      ". . . . . . . .\n",
      ". . r . . . . .\n",
      "-----------move done-----------\n",
      "time taken to iteration 143 0.994889497756958\n",
      "score for  BLACK =  3.900005522143729\n",
      ". . . . . . . .\n",
      ". . . k . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". K . . . . . .\n",
      ". . . . . . . .\n",
      ". . r . . . . .\n",
      "-----------move done-----------\n",
      "time taken to iteration 144 0.9047541618347168\n",
      "score for  WHITE =  -2.0227069233247947\n",
      ". . . . . . . .\n",
      ". . . k . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      "K . . . . . . .\n",
      ". . . . . . . .\n",
      ". . r . . . . .\n",
      "-----------move done-----------\n",
      "time taken to iteration 145 0.9086778163909912\n",
      "score for  BLACK =  3.9667978853218315\n",
      ". . . . . . . .\n",
      ". . k . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      "K . . . . . . .\n",
      ". . . . . . . .\n",
      ". . r . . . . .\n",
      "-----------move done-----------\n",
      "time taken to iteration 146 0.412778377532959\n",
      "score for  WHITE =  -2.4673957541329945\n",
      ". . . . . . . .\n",
      ". . k . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". K . . . . . .\n",
      ". . r . . . . .\n",
      "-----------move done-----------\n",
      "time taken to iteration 147 0.9337446689605713\n",
      "score for  BLACK =  3.3565748570886464\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". k . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". K . . . . . .\n",
      ". . r . . . . .\n",
      "-----------move done-----------\n",
      "time taken to iteration 148 0.7034940719604492\n",
      "score for  WHITE =  -2.0207446180354154\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". k . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". K . . . . . .\n",
      ". . . . . . . .\n",
      ". . r . . . . .\n",
      "-----------move done-----------\n",
      "time taken to iteration 149 0.9747757911682129\n",
      "score for  BLACK =  3.384080020008537\n",
      ". . r . . . . .\n",
      ". . . . . . . .\n",
      ". k . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". K . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      "-----------move done-----------\n",
      "time taken to iteration 150 0.626939058303833\n",
      "score for  WHITE =  -2.672748367372147\n",
      ". . r . . . . .\n",
      ". . . . . . . .\n",
      ". k . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". K . . . . . .\n",
      ". . . . . . . .\n",
      "-----------move done-----------\n",
      "time taken to iteration 151 0.735647439956665\n",
      "score for  BLACK =  3.9115121273485016\n",
      ". . r . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". k . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". K . . . . . .\n",
      ". . . . . . . .\n",
      "-----------move done-----------\n",
      "time taken to iteration 152 0.7420942783355713\n",
      "score for  WHITE =  -2.7081017167114476\n",
      ". . r . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". k . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      "K . . . . . . .\n",
      "-----------move done-----------\n",
      "time taken to iteration 153 0.7831206321716309\n",
      "score for  BLACK =  3.688859850081907\n",
      ". . . . r . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". k . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      "K . . . . . . .\n",
      "-----------move done-----------\n",
      "time taken to iteration 154 0.9111349582672119\n",
      "score for  WHITE =  -2.6879640381358394\n",
      ". . . . r . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". k . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      "K . . . . . . .\n",
      ". . . . . . . .\n",
      "-----------move done-----------\n",
      "time taken to iteration 155 0.9606151580810547\n",
      "score for  BLACK =  3.48660599551683\n",
      ". . . . r . . .\n",
      ". . . . . . . .\n",
      ". . k . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      "K . . . . . . .\n",
      ". . . . . . . .\n",
      "-----------move done-----------\n",
      "time taken to iteration 156 0.652824878692627\n",
      "score for  WHITE =  -2.380569079115526\n",
      ". . . . r . . .\n",
      ". . . . . . . .\n",
      ". . k . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      "K . . . . . . .\n",
      "-----------move done-----------\n",
      "time taken to iteration 157 0.697150468826294\n",
      "score for  BLACK =  3.7384088767052908\n",
      ". . r . . . . .\n",
      ". . . . . . . .\n",
      ". . k . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      "K . . . . . . .\n",
      "-----------move done-----------\n",
      "time taken to iteration 158 0.7850437164306641\n",
      "score for  WHITE =  -2.2547942525481863\n",
      ". . r . . . . .\n",
      ". . . . . . . .\n",
      ". . k . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". K . . . . . .\n",
      "-----------move done-----------\n",
      "time taken to iteration 159 0.662691593170166\n",
      "score for  BLACK =  3.4239529401399205\n",
      ". . r . . . . .\n",
      ". k . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". K . . . . . .\n",
      "-----------move done-----------\n",
      "time taken to iteration 160 0.737191915512085\n",
      "score for  WHITE =  -2.7969919619226222\n",
      ". . r . . . . .\n",
      ". k . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". K . . . . . .\n",
      ". . . . . . . .\n",
      "-----------move done-----------\n",
      "time taken to iteration 161 0.443925142288208\n",
      "score for  BLACK =  3.968135232912699\n",
      ". . . . . . . .\n",
      ". k . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . r . . . . .\n",
      ". . . . . . . .\n",
      ". K . . . . . .\n",
      ". . . . . . . .\n",
      "-----------move done-----------\n",
      "time taken to iteration 162 0.4556238651275635\n",
      "score for  WHITE =  -2.883924198540661\n",
      ". . . . . . . .\n",
      ". k . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . r . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". K . . . . . .\n",
      "-----------move done-----------\n",
      "time taken to iteration 163 0.5943896770477295\n",
      "score for  BLACK =  3.978464217853155\n",
      ". . . . . . . .\n",
      ". k . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . r\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". K . . . . . .\n",
      "-----------move done-----------\n",
      "time taken to iteration 164 0.5127055644989014\n",
      "score for  WHITE =  -2.865227779235957\n",
      ". . . . . . . .\n",
      ". k . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . r\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . K . . . . .\n",
      "-----------move done-----------\n",
      "time taken to iteration 165 0.5404829978942871\n",
      "score for  BLACK =  3.451844816709162\n",
      ". . . . . . . .\n",
      ". k . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . K . . . . r\n",
      "-----------move done-----------\n",
      "time taken to iteration 166 0.5601391792297363\n",
      "score for  WHITE =  -2.406857982425475\n",
      ". . . . . . . .\n",
      ". k . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". K . . . . . .\n",
      ". . . . . . . r\n",
      "-----------move done-----------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time taken to iteration 167 0.5469849109649658\n",
      "score for  BLACK =  3.860611646122731\n",
      ". . . . . . . r\n",
      ". k . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". K . . . . . .\n",
      ". . . . . . . .\n",
      "-----------move done-----------\n",
      "time taken to iteration 168 0.4748396873474121\n",
      "score for  WHITE =  -2.6846123898472785\n",
      ". . . . . . . r\n",
      ". k . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . K . . . . .\n",
      ". . . . . . . .\n",
      "-----------move done-----------\n",
      "time taken to iteration 169 0.5749356746673584\n",
      "score for  BLACK =  3.758103520837014\n",
      ". . . . . . . .\n",
      ". k . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . r\n",
      ". . K . . . . .\n",
      ". . . . . . . .\n",
      "-----------move done-----------\n",
      "time taken to iteration 170 0.3877992630004883\n",
      "score for  WHITE =  -2.207696440949789\n",
      ". . . . . . . .\n",
      ". k . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . r\n",
      ". . . . . . . .\n",
      ". K . . . . . .\n",
      "-----------move done-----------\n",
      "time taken to iteration 171 0.3890218734741211\n",
      "score for  BLACK =  3.1688096299780613\n",
      ". . . . . . . .\n",
      ". k . . . . . .\n",
      ". . . . . . . r\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". K . . . . . .\n",
      "-----------move done-----------\n",
      "time taken to iteration 172 0.5744681358337402\n",
      "score for  WHITE =  -2.5776158199145502\n",
      ". . . . . . . .\n",
      ". k . . . . . .\n",
      ". . . . . . . r\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      "K . . . . . . .\n",
      "-----------move done-----------\n",
      "time taken to iteration 173 0.4358506202697754\n",
      "score for  BLACK =  3.848850649689577\n",
      ". . . . . . . .\n",
      ". k . . . . . .\n",
      ". . . r . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      "K . . . . . . .\n",
      "-----------move done-----------\n",
      "time taken to iteration 174 0.3292539119720459\n",
      "score for  WHITE =  -2.950290689762869\n",
      ". . . . . . . .\n",
      ". k . . . . . .\n",
      ". . . r . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". K . . . . . .\n",
      "-----------move done-----------\n",
      "time taken to iteration 175 0.34230542182922363\n",
      "score for  BLACK =  3.598689601672162\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . k r . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". K . . . . . .\n",
      "-----------move done-----------\n",
      "time taken to iteration 176 0.5081028938293457\n",
      "score for  WHITE =  -2.841788895110802\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . k r . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      "K . . . . . . .\n",
      "-----------move done-----------\n",
      "time taken to iteration 177 0.3709428310394287\n",
      "score for  BLACK =  3.5726762220957404\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . k . . . . .\n",
      ". . . . . . . .\n",
      ". . . r . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      "K . . . . . . .\n",
      "-----------move done-----------\n",
      "time taken to iteration 178 0.36675381660461426\n",
      "score for  WHITE =  -2.9859774884629315\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . k . . . . .\n",
      ". . . . . . . .\n",
      ". . . r . . . .\n",
      ". . . . . . . .\n",
      "K . . . . . . .\n",
      ". . . . . . . .\n",
      "-----------move done-----------\n",
      "time taken to iteration 179 0.3722255229949951\n",
      "score for  BLACK =  3.7824812299938078\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . k . . . .\n",
      ". . . r . . . .\n",
      ". . . . . . . .\n",
      "K . . . . . . .\n",
      ". . . . . . . .\n",
      "-----------move done-----------\n",
      "time taken to iteration 180 0.4401559829711914\n",
      "score for  WHITE =  -2.0444498230521315\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . k . . . .\n",
      ". . . r . . . .\n",
      ". K . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      "-----------move done-----------\n",
      "time taken to iteration 181 0.39522361755371094\n",
      "score for  BLACK =  3.843860818006714\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . r k . . .\n",
      ". K . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      "-----------move done-----------\n",
      "time taken to iteration 182 0.34893250465393066\n",
      "score for  WHITE =  -2.4989372685886058\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . r k . . .\n",
      ". . . . . . . .\n",
      ". . K . . . . .\n",
      ". . . . . . . .\n",
      "-----------move done-----------\n",
      "time taken to iteration 183 0.3566007614135742\n",
      "score for  BLACK =  3.0422519716122505\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . k . . .\n",
      ". . . r . . . .\n",
      ". . . . . . . .\n",
      ". . K . . . . .\n",
      ". . . . . . . .\n",
      "-----------move done-----------\n",
      "time taken to iteration 184 0.29558706283569336\n",
      "score for  WHITE =  -2.949277407551527\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . k . . .\n",
      ". . . r . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . K . . . . .\n",
      "-----------move done-----------\n",
      "time taken to iteration 185 0.3208789825439453\n",
      "score for  BLACK =  3.1147190111823173\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . k . . .\n",
      ". . . . . . . .\n",
      ". . . r . . . .\n",
      ". . . . . . . .\n",
      ". . K . . . . .\n",
      "-----------move done-----------\n",
      "time taken to iteration 186 0.48784613609313965\n",
      "score for  WHITE =  -2.636584383056511\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . k . . .\n",
      ". . . . . . . .\n",
      ". . . r . . . .\n",
      ". . . . . . . .\n",
      ". K . . . . . .\n",
      "-----------move done-----------\n",
      "time taken to iteration 187 0.20341038703918457\n",
      "score for  BLACK =  3.8248790776617776\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . k . . . .\n",
      ". . . . . . . .\n",
      ". . . r . . . .\n",
      ". . . . . . . .\n",
      ". K . . . . . .\n",
      "-----------move done-----------\n",
      "time taken to iteration 188 0.1942591667175293\n",
      "score for  WHITE =  -2.9237676480598807\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . k . . . .\n",
      ". . . . . . . .\n",
      ". . . r . . . .\n",
      ". . . . . . . .\n",
      "K . . . . . . .\n",
      "-----------move done-----------\n",
      "time taken to iteration 189 0.26869893074035645\n",
      "score for  BLACK =  3.469662927845279\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . k . . .\n",
      ". . . . . . . .\n",
      ". . . r . . . .\n",
      ". . . . . . . .\n",
      "K . . . . . . .\n",
      "-----------move done-----------\n",
      "time taken to iteration 190 0.16900014877319336\n",
      "score for  WHITE =  -2.4009882102976117\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . k . . .\n",
      ". . . . . . . .\n",
      ". . . r . . . .\n",
      "K . . . . . . .\n",
      ". . . . . . . .\n",
      "-----------move done-----------\n",
      "time taken to iteration 191 0.15199661254882812\n",
      "score for  BLACK =  3.7245063407742407\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . k . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      "K . . . . . . .\n",
      ". . . r . . . .\n",
      "-----------move done-----------\n",
      "time taken to iteration 192 0.12616801261901855\n",
      "score for  WHITE =  -2.79443695525986\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . k . . .\n",
      ". . . . . . . .\n",
      ". K . . . . . .\n",
      ". . . . . . . .\n",
      ". . . r . . . .\n",
      "-----------move done-----------\n",
      "time taken to iteration 193 0.13521742820739746\n",
      "score for  BLACK =  3.4204734870724174\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . k . . .\n",
      ". . . . . . . .\n",
      ". K . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . r .\n",
      "-----------move done-----------\n",
      "time taken to iteration 194 0.27625584602355957\n",
      "score for  WHITE =  -2.6963150005255008\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . k . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". K . . . . . .\n",
      ". . . . . . r .\n",
      "-----------move done-----------\n",
      "time taken to iteration 195 0.10183024406433105\n",
      "score for  BLACK =  3.8059723287195806\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . k . r .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". K . . . . . .\n",
      ". . . . . . . .\n",
      "-----------move done-----------\n",
      "time taken to iteration 196 0.05270576477050781\n",
      "score for  WHITE =  -2.6776787705347793\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . k . r .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . K . . . . .\n",
      ". . . . . . . .\n",
      "-----------move done-----------\n",
      "time taken to iteration 197 0.05738329887390137\n",
      "score for  BLACK =  3.3251846719083535\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . k . . . .\n",
      ". . . . . . r .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . K . . . . .\n",
      ". . . . . . . .\n",
      "-----------move done-----------\n",
      "time taken to iteration 198 0.020743370056152344\n",
      "score for  WHITE =  -2.589902720936899\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . k . . . .\n",
      ". . . . . . r .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . K . . . .\n",
      ". . . . . . . .\n",
      "-----------move done-----------\n",
      "time taken to iteration 199 0.016460418701171875\n",
      "score for  BLACK =  3.975069031506867\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . k . . r .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . K . . . .\n",
      ". . . . . . . .\n",
      "-----------move done-----------\n",
      "time taken to iteration 200 0.002969980239868164\n",
      "score for  WHITE =  -2.0606448297956277\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . k . . r .\n",
      ". . . . . . . .\n",
      ". . K . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      "-----------move done-----------\n",
      "Qd2 Ra1 Qd5+ Ka6 Qe6+ Ka5 Qb6+ Kxb6 Kg2 Ra3 Kh2 Ka7 Kh1 Rd3 Kh2 Rd6 Kh3 Ka8 Kh4 Ra7 Kh5 Rb7 Kg5 Rd1 Kg4 Rdd7 Kh3 Rd2 Kh4 Ra2 Kh3 Rb8 Kh4 Rc8 Kh3 Rcc2 Kg4 Rab2 Kh3 Kb8 Kg3 Rb7 Kf3 Rb6 Ke4 Rc4+ Ke5 Rb1 Kd5 Rb5+ Kxc4 Rb4+ Kc3 Rc4+ Kb2 Rc7 Kb1 Rd7 Kc2 Ka7 Kb1 Rc7 Kb2 Kb7 Kb3 Kc6 Kb4 Rf7 Kc3 Rf2 Kb3 Kb5 Ka3 Rd2 Kb3 Rc2 Ka3 Kc6 Kb3 Kc7 Ka4 Kd6 Kb3 Rc8 Kb2 Ke5 Kb3 Rf8 Kb2 Rf6 Ka1 Rb6 Ka2 Rg6 Ka3 Ke6 Ka4 Kf5 Kb3 Rg3+ Kb4 Ke6 Kb5 Rd3 Kc6 Rd6+ Kc5 Rb6 Kd4 Rb8 Kd3 Ke7 Kd4 Rb1 Ke4 Rb4+ Ke3 Ke6 Ke2 Ke7 Kd2 Rb2+ Ke3 Kd8 Kf3 Rb5 Ke3 Rb1 Kd3 Re1 Kc2 Kc7 Kd3 Rg1 Kd4 Kb7 Kc4 Rc1+ Kb4 Kb6 Ka3 Kc6 Kb3 Kd7 Ka3 Kc7 Kb2 Kb6 Kb3 Rc8 Kb2 Kb5 Ka1 Re8 Ka2 Kc6 Ka1 Rc8 Kb1 Kb7 Kb2 Rc4 Kb1 Rh4 Kc1 Rh1+ Kb2 Rh8 Kc2 Rh3 Kb1 Rh6 Ka1 Rd6 Kb1 Kc6 Ka1 Rd4 Ka2 Kd5 Kb3 Ke4 Kc2 Ke5 Kc1 Rd3 Kb1 Kd5 Ka1 Ke5 Ka2 Rd1 Kb3 Rg1 Kb2 Rg5 Kc2 Kd6 Kd2 Kd5 Kc3\n",
      "\n",
      "1/2-1/2\n"
     ]
    }
   ],
   "source": [
    "#This method is for game that can be customized by the user\n",
    "\n",
    "#customizing problem size\n",
    "#to randomize the starting position we can customize the board. for now I am using a random board setup\n",
    "#board = chess.Board(\"r1bqkb1r/pppp1Qpp/2n2n2/4p3/2B1P3/8/PPPP1PPP/RNB1K1NR\")\n",
    "print(\"We want an input from you to arrange the board. We have randomized the pieces position with different numbers.Can you choose one from the following pieces you want in the board?\")\n",
    "s = input(\"p or P or Q or R or q or b . Only write the letter \\n\")\n",
    "b1 = \"8/8/7\"+s+\"/8/8/r7/1kr5/7K\"\n",
    "b2 = \"8/8/8/8/B7/b6\"+s+\"/1kp5/7K\"\n",
    "b3 = \"full board\"\n",
    "b4 = \"8/1kr5/7\"+s+\"/8/8/r7/7K/8\"\n",
    "b5 = \"8/7k/p1p2p2p/7\"+s+\"/8/r7/1K1n4/8\"\n",
    "#b6= \"8/8/8/8/8/8/7Q/5k1K\"\n",
    "print(\"select which problem instance board you want\\n b1: \",b1,\"\\n b2:\",b2,\"\\n b3: \",b3,\"\\n b4:\",b4,\"\\n b5: \",b5)\n",
    "b6 = input(\"Write b1 or b2 or b3 or b4 or b5\")\n",
    "if(b6==\"b1\"):\n",
    "    board = chess.Board(b1)\n",
    "elif(b6==\"b2\"):\n",
    "    board = chess.Board(b2) \n",
    "elif(b6==\"b3\"):\n",
    "    board = chess.Board()\n",
    "elif(b6==\"b4\"):\n",
    "    board = chess.Board(b4)\n",
    "else:\n",
    "    board = chess.Board(b6)\n",
    "score=0\n",
    "\n",
    "#to let the pc choose random positions\n",
    "#board = chess.Board.from_chess960_pos(random.randint(0, 959))\n",
    "#board = chess.Board()\n",
    "print(board)\n",
    "#display_board(board)\n",
    "choice=int(input(\"Do you want 1. AI-AI game or 2.Human-AI game or 3.Baseline tree-AI tree game or 4. tree vs tree or 5.AI-NN game ?\\n write 1 or 2 or 3 or 4 or 5= \"))\n",
    "base1=\"AI\"\n",
    "base2=\"AI\"\n",
    "white = 1\n",
    "\n",
    "if(choice==3):\n",
    "    base1 = \"Tree\"\n",
    "\n",
    "elif (choice==5):\n",
    "    base2=\"NN\"\n",
    "   # white=0\n",
    "elif(choice==4):\n",
    "    base1=\"Tree\"\n",
    "    base2 = \"Tree\"\n",
    "moves = 0\n",
    "pgn = []\n",
    "game = chess.pgn.Game()\n",
    "evaluations = []\n",
    "sm = 0\n",
    "cnt = 0\n",
    "curve  = [ [0]*2 for i in range(2)]\n",
    "# curve = np.zeros((5,100,1000,2))\n",
    "\n",
    "j=0\n",
    "while((not board.is_game_over())):\n",
    "    all_moves = [board.san(i) for i in list(board.legal_moves)]\n",
    "    start = time.time()\n",
    "    if(white==1):\n",
    "        root = node(board)\n",
    "        root.state = board\n",
    "        result = mcts_pred(board,root,board.is_game_over(),white,choice,base1,base2)\n",
    "        print(\"time taken to iteration\",j,(time.time()-start))\n",
    "    elif(choice==2 and white==0):\n",
    "        print(\"input format should be something like a2, b6, g3, first one is row, second one is colum\")\n",
    "        print(\"row is a to h and colum is 1 to 8. if you are second player your pieces are small letter , otherwise capital\")\n",
    "        to=input(\"Write where you want to go = \")\n",
    "        frm = input(\"write from where you want to move = \")\n",
    "        result=frm+to\n",
    "    elif(choice==5 and white==0):\n",
    "        start = time.time()\n",
    "        matrix = make_matrix(board.copy())\n",
    "        translated = np.array(translate(matrix,chess_dict))\n",
    "        print(model.predict(translated.reshape(1,8,8,12)))\n",
    "        clear_output()\n",
    "        move = calculate_move(15,board,10)\n",
    "        #print(\"time taken for nn in iteration \",j,(time.time()-start))\n",
    "    else:\n",
    "        root = node(board)\n",
    "        root.state = board\n",
    "        result = mcts_pred(board,root,board.is_game_over(),white,choice,base1,base2)\n",
    "        print(\"time taken to iteration\",j,(time.time()-start))\n",
    "    try:\n",
    "        board.push_san(result)\n",
    "\n",
    "    except:\n",
    "        print(result)\n",
    "        print(\"invalid move. game over\")\n",
    "        break\n",
    "    #print(result)\n",
    "    score = staticAnalysis(board,white)\n",
    "    col=\"BLACK\"\n",
    "    if(white):\n",
    "        col=\"WHITE\"\n",
    "    print(\"score for \",col,\"= \",score)\n",
    "\n",
    "    curve[white].append(score)\n",
    "    pgn.append(result)\n",
    "    white ^= 1\n",
    "    j+=1\n",
    "\n",
    "    moves+=1\n",
    "    #info = engine.analyse(board, chess.engine.Limit(depth=24))\n",
    "    #evaluat += info['score'].white()\n",
    "    print(board)\n",
    "\n",
    "    print(\"-----------move done-----------\")\n",
    "\n",
    "print(\" \".join(pgn))\n",
    "print()\n",
    "#{'string': 'NNUE evaluation using nn-ad9b42354671.nnue enabled', 'depth': 24, 'seldepth': 24, 'multipv': 1, 'score': PovScore(Cp(0), WHITE), 'nodes': 103968, 'nps': 4725818, 'hashfull': 7, 'tbhits': 0, 'time': 0.022, 'pv': [Move.from_uci('h1g2'), Move.from_uci('b4b5'), Move.from_uci('g2g3'), Move.from_uci('b5c5'), Move.from_uci('g3f4'), Move.from_uci('c5b4'), Move.from_uci('f4f5'), Move.from_uci('b4c5')]}\n",
    "\n",
    "#print(info)\n",
    "#print(evaluations)\n",
    "#We are showing score for each player after each move, so in final result the score is only based on the winner.\n",
    "#If player 1 wins, it should show 1-0 , if there is a draw it will show 1/2-1/2 and 0-1 otherwise.\n",
    "print(board.result())\n",
    "\n",
    "game.headers[\"Result\"] = board.result()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "b87b89a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as pt\n",
    "\n",
    "\n",
    "# visualize learning curves on train/test data\n",
    "pt.plot(curve[0][0:j+1], 'b-')\n",
    "pt.plot(curve[1][0:j+1], 'r-')\n",
    "#pt.plot([0, len(curve[1])], [baseline_error, baseline_error], 'g-')\n",
    "pt.plot()\n",
    "pt.legend([\"AI\",\"Tree\"])\n",
    "pt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "46af4c55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We want an input from you to arrange the board. We have randomized the pieces position with different numbers.Can you choose one from the following pieces you want in the board?\n",
      "p or P or Q or R or q or b . Only write the letter \n",
      "p\n",
      "select which problem instance board you want\n",
      " b1:  8/8/7p/8/8/r7/1kr5/7K \n",
      " b2: 8/8/8/8/B7/b6p/1kp5/7K \n",
      " b3:  full board \n",
      " b4: 8/1kr5/7p/8/8/r7/7K/8 \n",
      " b5:  8/7k/p1p2p2p/7p/8/r7/1K1n4/8\n",
      "Write b1 or b2 or b3 or b4 or b5b1\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . p\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      "r . . . . . . .\n",
      ". k r . . . . .\n",
      ". . . . . . . K\n",
      "Do you want 1. AI-AI game or 2.Human-AI game or 3.Baseline tree-AI tree game or 4. tree vs tree or 5.AI-NN game ?\n",
      " write 1 or 2 or 3 or 4 or 5= 2\n",
      "time taken to iteration 0 2.4816973209381104\n",
      "score for  WHITE =  -6.160085488115614\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . p\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      "r . . . . . . .\n",
      ". k r . . . . .\n",
      ". . . . . . K .\n",
      "-----------move done-----------\n",
      "input format should be something like a2, b6, g3, first one is row, second one is colum\n",
      "row is a to h and colum is 1 to 8. if you are second player your pieces are small letter , otherwise capital\n",
      "Write where you want to go = d2\n",
      "write from where you want to move = c2\n",
      "score for  BLACK =  7.553195436275905\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . p\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      "r . . . . . . .\n",
      ". k . r . . . .\n",
      ". . . . . . K .\n",
      "-----------move done-----------\n",
      "time taken to iteration 2 1.9270424842834473\n",
      "score for  WHITE =  -6.824716054399389\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . p\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      "r . . . . . . .\n",
      ". k . r . . . .\n",
      ". . . . . K . .\n",
      "-----------move done-----------\n",
      "input format should be something like a2, b6, g3, first one is row, second one is colum\n",
      "row is a to h and colum is 1 to 8. if you are second player your pieces are small letter , otherwise capital\n",
      "Write where you want to go = c2\n",
      "write from where you want to move = d2\n",
      "score for  BLACK =  7.4779294446658575\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . p\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      "r . . . . . . .\n",
      ". k r . . . . .\n",
      ". . . . . K . .\n",
      "-----------move done-----------\n",
      "time taken to iteration 4 2.759963274002075\n",
      "score for  WHITE =  -6.857180406051329\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . p\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      "r . . . . . . .\n",
      ". k r . . . . .\n",
      ". . . . . . K .\n",
      "-----------move done-----------\n",
      "input format should be something like a2, b6, g3, first one is row, second one is colum\n",
      "row is a to h and colum is 1 to 8. if you are second player your pieces are small letter , otherwise capital\n",
      "Write where you want to go = d3\n",
      "write from where you want to move = a3\n",
      "score for  BLACK =  7.74830459468499\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . p\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . r . . . .\n",
      ". k r . . . . .\n",
      ". . . . . . K .\n",
      "-----------move done-----------\n",
      "time taken to iteration 6 4.2046873569488525\n",
      "score for  WHITE =  -6.834814578766524\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . p\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . r . . . .\n",
      ". k r . . . . .\n",
      ". . . . . . . K\n",
      "-----------move done-----------\n",
      "input format should be something like a2, b6, g3, first one is row, second one is colum\n",
      "row is a to h and colum is 1 to 8. if you are second player your pieces are small letter , otherwise capital\n",
      "Write where you want to go = d1\n",
      "write from where you want to move = d3\n",
      "score for  BLACK =  107.37250624070921\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . p\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". k r . . . . .\n",
      ". . . r . . . K\n",
      "-----------move done-----------\n",
      "Kg1 c2d2 Kf1 d2c2 Kg1 a3d3 Kh1 d3d1\n",
      "\n",
      "0-1\n"
     ]
    }
   ],
   "source": [
    "#This method is for game that can be customized by the user\n",
    "\n",
    "#customizing problem size\n",
    "#to randomize the starting position we can customize the board. for now I am using a random board setup\n",
    "#board = chess.Board(\"r1bqkb1r/pppp1Qpp/2n2n2/4p3/2B1P3/8/PPPP1PPP/RNB1K1NR\")\n",
    "print(\"We want an input from you to arrange the board. We have randomized the pieces position with different numbers.Can you choose one from the following pieces you want in the board?\")\n",
    "s = input(\"p or P or Q or R or q or b . Only write the letter \\n\")\n",
    "b1 = \"8/8/7\"+s+\"/8/8/r7/1kr5/7K\"\n",
    "b2 = \"8/8/8/8/B7/b6\"+s+\"/1kp5/7K\"\n",
    "b3 = \"full board\"\n",
    "b4 = \"8/1kr5/7\"+s+\"/8/8/r7/7K/8\"\n",
    "b5 = \"8/7k/p1p2p2p/7\"+s+\"/8/r7/1K1n4/8\"\n",
    "#b6= \"8/8/8/8/8/8/7Q/5k1K\"\n",
    "print(\"select which problem instance board you want\\n b1: \",b1,\"\\n b2:\",b2,\"\\n b3: \",b3,\"\\n b4:\",b4,\"\\n b5: \",b5)\n",
    "b6 = input(\"Write b1 or b2 or b3 or b4 or b5\")\n",
    "if(b6==\"b1\"):\n",
    "    board = chess.Board(b1)\n",
    "elif(b6==\"b2\"):\n",
    "    board = chess.Board(b2) \n",
    "elif(b6==\"b3\"):\n",
    "    board = chess.Board()\n",
    "elif(b6==\"b4\"):\n",
    "    board = chess.Board(b4)\n",
    "else:\n",
    "    board = chess.Board(b6)\n",
    "score=0\n",
    "\n",
    "#to let the pc choose random positions\n",
    "#board = chess.Board.from_chess960_pos(random.randint(0, 959))\n",
    "#board = chess.Board()\n",
    "print(board)\n",
    "#display_board(board)\n",
    "choice=int(input(\"Do you want 1. AI-AI game or 2.Human-AI game or 3.Baseline tree-AI tree game or 4. tree vs tree or 5.AI-NN game ?\\n write 1 or 2 or 3 or 4 or 5= \"))\n",
    "base1=\"AI\"\n",
    "base2=\"AI\"\n",
    "white = 1\n",
    "\n",
    "if(choice==3):\n",
    "    base1 = \"Tree\"\n",
    "\n",
    "elif (choice==5):\n",
    "    base2=\"NN\"\n",
    "   # white=0\n",
    "elif(choice==4):\n",
    "    base1=\"Tree\"\n",
    "    base2 = \"Tree\"\n",
    "moves = 0\n",
    "pgn = []\n",
    "game = chess.pgn.Game()\n",
    "evaluations = []\n",
    "sm = 0\n",
    "cnt = 0\n",
    "curve  = [ [0]*2 for i in range(2)]\n",
    "# curve = np.zeros((5,100,1000,2))\n",
    "\n",
    "j=0\n",
    "while((not board.is_game_over())):\n",
    "    all_moves = [board.san(i) for i in list(board.legal_moves)]\n",
    "    start = time.time()\n",
    "    if(white==1):\n",
    "        root = node(board)\n",
    "        root.state = board\n",
    "        result = mcts_pred(board,root,board.is_game_over(),white,choice,base1,base2)\n",
    "        print(\"time taken to iteration\",j,(time.time()-start))\n",
    "    elif(choice==2 and white==0):\n",
    "        print(\"input format should be something like a2, b6, g3, first one is row, second one is colum\")\n",
    "        print(\"row is a to h and colum is 1 to 8. if you are second player your pieces are small letter , otherwise capital\")\n",
    "        to=input(\"Write where you want to go = \")\n",
    "        frm = input(\"write from where you want to move = \")\n",
    "        result=frm+to\n",
    "    elif(choice==5 and white==0):\n",
    "        start = time.time()\n",
    "        matrix = make_matrix(board.copy())\n",
    "        translated = np.array(translate(matrix,chess_dict))\n",
    "        print(model.predict(translated.reshape(1,8,8,12)))\n",
    "        clear_output()\n",
    "        move = calculate_move(15,board,10)\n",
    "        #print(\"time taken for nn in iteration \",j,(time.time()-start))\n",
    "    else:\n",
    "        root = node(board)\n",
    "        root.state = board\n",
    "        result = mcts_pred(board,root,board.is_game_over(),white,choice,base1,base2)\n",
    "        print(\"time taken to iteration\",j,(time.time()-start))\n",
    "    try:\n",
    "        board.push_san(result)\n",
    "\n",
    "    except:\n",
    "        print(result)\n",
    "        print(\"invalid move. game over\")\n",
    "        break\n",
    "    #print(result)\n",
    "    score = staticAnalysis(board,white)\n",
    "    col=\"BLACK\"\n",
    "    if(white):\n",
    "        col=\"WHITE\"\n",
    "    print(\"score for \",col,\"= \",score)\n",
    "\n",
    "    curve[white].append(score)\n",
    "    pgn.append(result)\n",
    "    white ^= 1\n",
    "    j+=1\n",
    "\n",
    "    moves+=1\n",
    "    #info = engine.analyse(board, chess.engine.Limit(depth=24))\n",
    "    #evaluat += info['score'].white()\n",
    "    print(board)\n",
    "\n",
    "    print(\"-----------move done-----------\")\n",
    "\n",
    "print(\" \".join(pgn))\n",
    "print()\n",
    "#{'string': 'NNUE evaluation using nn-ad9b42354671.nnue enabled', 'depth': 24, 'seldepth': 24, 'multipv': 1, 'score': PovScore(Cp(0), WHITE), 'nodes': 103968, 'nps': 4725818, 'hashfull': 7, 'tbhits': 0, 'time': 0.022, 'pv': [Move.from_uci('h1g2'), Move.from_uci('b4b5'), Move.from_uci('g2g3'), Move.from_uci('b5c5'), Move.from_uci('g3f4'), Move.from_uci('c5b4'), Move.from_uci('f4f5'), Move.from_uci('b4c5')]}\n",
    "\n",
    "#print(info)\n",
    "#print(evaluations)\n",
    "#We are showing score for each player after each move, so in final result the score is only based on the winner.\n",
    "#If player 1 wins, it should show 1-0 , if there is a draw it will show 1/2-1/2 and 0-1 otherwise.\n",
    "print(board.result())\n",
    "\n",
    "game.headers[\"Result\"] = board.result()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "35aace5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as pt\n",
    "\n",
    "# visualize learning curves on train/test data\n",
    "pt.plot(curve[0][0:j], 'b-')\n",
    "pt.plot(curve[1][0:j], 'r-')\n",
    "#pt.plot([0, len(curve[1])], [baseline_error, baseline_error], 'g-')\n",
    "pt.plot()\n",
    "pt.legend([\"Human\",\"AI\"])\n",
    "pt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "82084cc1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in /home/sroy15/anaconda3/lib/python3.9/site-packages (2.10.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /home/sroy15/anaconda3/lib/python3.9/site-packages (from tensorflow) (0.27.0)\n",
      "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /home/sroy15/anaconda3/lib/python3.9/site-packages (from tensorflow) (3.19.6)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /home/sroy15/anaconda3/lib/python3.9/site-packages (from tensorflow) (14.0.6)\n",
      "Requirement already satisfied: flatbuffers>=2.0 in /home/sroy15/anaconda3/lib/python3.9/site-packages (from tensorflow) (22.10.26)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /home/sroy15/anaconda3/lib/python3.9/site-packages (from tensorflow) (0.4.0)\n",
      "Requirement already satisfied: tensorboard<2.11,>=2.10 in /home/sroy15/anaconda3/lib/python3.9/site-packages (from tensorflow) (2.10.1)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /home/sroy15/anaconda3/lib/python3.9/site-packages (from tensorflow) (1.3.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /home/sroy15/anaconda3/lib/python3.9/site-packages (from tensorflow) (1.14.1)\n",
      "Requirement already satisfied: keras<2.11,>=2.10.0 in /home/sroy15/anaconda3/lib/python3.9/site-packages (from tensorflow) (2.10.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.1 in /home/sroy15/anaconda3/lib/python3.9/site-packages (from tensorflow) (1.1.2)\n",
      "Requirement already satisfied: packaging in /home/sroy15/anaconda3/lib/python3.9/site-packages (from tensorflow) (21.3)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /home/sroy15/anaconda3/lib/python3.9/site-packages (from tensorflow) (2.1.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /home/sroy15/anaconda3/lib/python3.9/site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /home/sroy15/anaconda3/lib/python3.9/site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /home/sroy15/anaconda3/lib/python3.9/site-packages (from tensorflow) (4.3.0)\n",
      "Requirement already satisfied: numpy>=1.20 in /home/sroy15/anaconda3/lib/python3.9/site-packages (from tensorflow) (1.21.5)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /home/sroy15/anaconda3/lib/python3.9/site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /home/sroy15/anaconda3/lib/python3.9/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.11,>=2.10.0 in /home/sroy15/anaconda3/lib/python3.9/site-packages (from tensorflow) (2.10.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /home/sroy15/anaconda3/lib/python3.9/site-packages (from tensorflow) (3.7.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /home/sroy15/anaconda3/lib/python3.9/site-packages (from tensorflow) (1.42.0)\n",
      "Requirement already satisfied: setuptools in /home/sroy15/anaconda3/lib/python3.9/site-packages (from tensorflow) (65.5.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /home/sroy15/anaconda3/lib/python3.9/site-packages (from astunparse>=1.6.0->tensorflow) (0.37.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /home/sroy15/anaconda3/lib/python3.9/site-packages (from tensorboard<2.11,>=2.10->tensorflow) (2.0.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /home/sroy15/anaconda3/lib/python3.9/site-packages (from tensorboard<2.11,>=2.10->tensorflow) (2.28.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /home/sroy15/anaconda3/lib/python3.9/site-packages (from tensorboard<2.11,>=2.10->tensorflow) (1.8.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /home/sroy15/anaconda3/lib/python3.9/site-packages (from tensorboard<2.11,>=2.10->tensorflow) (0.4.6)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /home/sroy15/anaconda3/lib/python3.9/site-packages (from tensorboard<2.11,>=2.10->tensorflow) (0.6.1)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /home/sroy15/anaconda3/lib/python3.9/site-packages (from tensorboard<2.11,>=2.10->tensorflow) (2.6.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/sroy15/anaconda3/lib/python3.9/site-packages (from tensorboard<2.11,>=2.10->tensorflow) (3.3.4)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/sroy15/anaconda3/lib/python3.9/site-packages (from packaging->tensorflow) (3.0.9)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /home/sroy15/anaconda3/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow) (4.2.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /home/sroy15/anaconda3/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow) (4.7.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /home/sroy15/anaconda3/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /home/sroy15/anaconda3/lib/python3.9/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.11,>=2.10->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/sroy15/anaconda3/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/sroy15/anaconda3/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow) (2022.9.24)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /home/sroy15/anaconda3/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/sroy15/anaconda3/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow) (1.26.12)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /home/sroy15/anaconda3/lib/python3.9/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /home/sroy15/anaconda3/lib/python3.9/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.11,>=2.10->tensorflow) (3.2.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fd04517",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "567917bc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pip install tensorflow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db129671",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip uninstall eventlet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "548bea70",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This method is for game that can be customized by the user\n",
    "\n",
    "#customizing problem size\n",
    "#to randomize the starting position we can customize the board. for now I am using a random board setup\n",
    "#board = chess.Board(\"r1bqkb1r/pppp1Qpp/2n2n2/4p3/2B1P3/8/PPPP1PPP/RNB1K1NR\")\n",
    "print(\"We want an input from you to arrange the board. We have randomized the pieces position with different numbers.Can you choose one from the following pieces you want in the board?\")\n",
    "s = input(\"p or P or Q or R or q or b . Only write the letter \\n\")\n",
    "b1 = \"8/8/7\"+s+\"/8/8/r7/1kr5/7K\"\n",
    "b2 = \"8/8/8/8/B7/b6\"+s+\"/1kp5/7K\"\n",
    "b3 = \"full board\"\n",
    "b4 = \"8/1kr5/7\"+s+\"/8/8/r7/7K/8\"\n",
    "b5 = \"8/7k/p1p2p2p/7\"+s+\"/8/r7/1K1n4/8\"\n",
    "#b6= \"8/8/8/8/8/8/7Q/5k1K\"\n",
    "print(\"select which problem instance board you want\\n b1: \",b1,\"\\n b2:\",b2,\"\\n b3: \",b3,\"\\n b4:\",b4,\"\\n b5: \",b5)\n",
    "b6 = input(\"Write b1 or b2 or b3 or b4 or b5\")\n",
    "if(b6==\"b1\"):\n",
    "    board = chess.Board(b1)\n",
    "elif(b6==\"b2\"):\n",
    "    board = chess.Board(b2) \n",
    "elif(b6==\"b3\"):\n",
    "    board = chess.Board()\n",
    "elif(b6==\"b4\"):\n",
    "    board = chess.Board(b4)\n",
    "else:\n",
    "    board = chess.Board(b6)\n",
    "score=0\n",
    "\n",
    "#to let the pc choose random positions\n",
    "#board = chess.Board.from_chess960_pos(random.randint(0, 959))\n",
    "#board = chess.Board()\n",
    "print(board)\n",
    "#display_board(board)\n",
    "choice=int(input(\"Do you want 1. AI-AI game or 2.Human-AI game or 3.Baseline tree-AI tree game or 4. tree vs tree or 5.AI-NN game ?\\n write 1 or 2 or 3 or 4 or 5= \"))\n",
    "base1=\"Tree\"\n",
    "base2=\"Tree\"\n",
    "white = 1\n",
    "\n",
    "if(choice==3):\n",
    "    base1 = \"Tree\"\n",
    "\n",
    "elif (choice==5):\n",
    "    base2=\"NN\"\n",
    "    #white=0\n",
    "elif(choice==4):\n",
    "    base1=\"Tree\"\n",
    "    base2 = \"Tree\"\n",
    "moves = 0\n",
    "pgn = []\n",
    "game = chess.pgn.Game()\n",
    "evaluations = []\n",
    "sm = 0\n",
    "cnt = 0\n",
    "curve  = [ [0]*2 for i in range(2)]\n",
    "# curve = np.zeros((5,100,1000,2))\n",
    "\n",
    "j=0\n",
    "while((not board.is_game_over())):\n",
    "    all_moves = [board.san(i) for i in list(board.legal_moves)]\n",
    "    start = time.time()\n",
    "    if(white==1):\n",
    "        root = node(board)\n",
    "        root.state = board\n",
    "        result = mcts_pred(board,root,board.is_game_over(),white,choice,base1,base2)\n",
    "        print(\"time taken to iteration\",j,(time.time()-start))\n",
    "    elif(choice==2 and white==0):\n",
    "        print(\"input format should be something like a2, b6, g3, first one is row, second one is colum\")\n",
    "        print(\"row is a to h and colum is 1 to 8. if you are second player your pieces are small letter , otherwise capital\")\n",
    "        to=input(\"Write where you want to go = \")\n",
    "        frm = input(\"write from where you want to move = \")\n",
    "        result=frm+to\n",
    "    elif(choice==5 and white==0):\n",
    "        start = time.time()\n",
    "        #matrix = make_matrix(board.copy())\n",
    "        translated = np.array(translate(matrix,chess_dict))\n",
    "        #print(model.predict(translated.reshape(1,8,8,12)))\n",
    "        #clear_output()\n",
    "        #result = mcts_pred(board,root,board.is_game_over(),white,choice,base1,base2)\n",
    "        result = calculate_move(10,board,10)\n",
    "        #print(\"time taken for nn in iteration \",j,(time.time()-start))\n",
    "    else:\n",
    "        root = node(board)\n",
    "        root.state = board\n",
    "        result = mcts_pred(board,root,board.is_game_over(),white,choice,base1,base2)\n",
    "        print(\"time taken to iteration\",j,(time.time()-start))\n",
    "    try:\n",
    "        board.push_san(result)\n",
    "\n",
    "    except:\n",
    "        print(result)\n",
    "        print(\"invalid move. game over\")\n",
    "        break\n",
    "    #print(result)\n",
    "    score = staticAnalysis(board,white)\n",
    "    col=\"BLACK\"\n",
    "    if(white):\n",
    "        col=\"WHITE\"\n",
    "    print(\"score for \",col,\"= \",score)\n",
    "\n",
    "    curve[white].append(score)\n",
    "    pgn.append(result)\n",
    "    white ^= 1\n",
    "    j+=1\n",
    "\n",
    "    moves+=1\n",
    "    #info = engine.analyse(board, chess.engine.Limit(depth=24))\n",
    "    #evaluat += info['score'].white()\n",
    "    print(board)\n",
    "\n",
    "    print(\"-----------move done-----------\")\n",
    "\n",
    "print(\" \".join(pgn))\n",
    "print()\n",
    "#{'string': 'NNUE evaluation using nn-ad9b42354671.nnue enabled', 'depth': 24, 'seldepth': 24, 'multipv': 1, 'score': PovScore(Cp(0), WHITE), 'nodes': 103968, 'nps': 4725818, 'hashfull': 7, 'tbhits': 0, 'time': 0.022, 'pv': [Move.from_uci('h1g2'), Move.from_uci('b4b5'), Move.from_uci('g2g3'), Move.from_uci('b5c5'), Move.from_uci('g3f4'), Move.from_uci('c5b4'), Move.from_uci('f4f5'), Move.from_uci('b4c5')]}\n",
    "\n",
    "#print(info)\n",
    "#print(evaluations)\n",
    "#We are showing score for each player after each move, so in final result the score is only based on the winner.\n",
    "#If player 1 wins, it should show 1-0 , if there is a draw it will show 1/2-1/2 and 0-1 otherwise.\n",
    "print(board.result())\n",
    "\n",
    "game.headers[\"Result\"] = board.result()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41c9f784",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e68133ea",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
